{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6630819-7845-4bfb-b746-6a7e780e0540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ada/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import sqlite3\n",
    "import string\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#load the statistical libraries\n",
    "from statsmodels.stats import diagnostic\n",
    "from scipy import stats\n",
    "import ast\n",
    "\n",
    "#NLP libraries\n",
    "import spacy, nltk, gensim, sklearn\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "\n",
    "#Scikit imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1981b18-a20b-4b10-b585-0b15563a9d26",
   "metadata": {},
   "source": [
    "# General information Remark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9c90b-4fd4-4d09-8163-7c2b7021c9b3",
   "metadata": {},
   "source": [
    "### In the loading part we will recover data from 2015 to 2020, however, first visulation (part III) will only be on the data from 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b3b89-46e1-4377-96ab-830501273244",
   "metadata": {},
   "source": [
    "# I- Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edcfe19-c424-4435-86bd-b0eb11096498",
   "metadata": {},
   "source": [
    "### Load Quotebank data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6264bc75-8b74-44f3-9e45-c079a54bea3b",
   "metadata": {},
   "source": [
    "First, let's recover the quotations of interest : as our project is based on the caracterisation of the speaker, we decide to pre-select the quotations that are related to a speaker (i.e speaker value is different from 'None'). \n",
    "Moreover, we select the quotations whose subject is related to climate change : to do so we will recover a list of keyword related to climate subject by analyzing wwith NLP the dataset train_climate.tcsv. Then, we select quotes that contains at least one of these words(cf chunk_filtering method)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ee82b-a84e-4d40-ab45-136506d70769",
   "metadata": {},
   "source": [
    "> #### A/ Recovering of the keyword list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32930eb4-8b96-40a5-973f-a5f0531ae128",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('data/Wiki_train.tsv', sep='\\t')\n",
    "data2=pd.read_csv('data/train_1.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40bcd013-2233-44fe-84db-20398f37bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.drop(labels = ['id', 'paragraph', 'title'], axis=1, inplace=True)\n",
    "data2.drop(labels = ['id', 'paragraph', 'title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb439466-7a67-4d03-aee0-a5ac5f6ed6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdata = pd.concat([data1, data2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d119a-8b82-4e7b-b465-702a0318b573",
   "metadata": {},
   "source": [
    "> ##### Creation of our bag of word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a20ae06-31fe-499d-917e-3794919d1735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 6000\n",
      "Number of features: 75261\n",
      "(6000,)\n",
      "(6000, 75261)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words = 'english',ngram_range=(1, 2),lowercase=False)\n",
    "\n",
    "\n",
    "#create bag of words features\n",
    "X = vectorizer.fit_transform(subdata.sentence)\n",
    "\n",
    "\n",
    "print('Number of samples:',X.toarray().shape[0])\n",
    "print('Number of features:',X.toarray().shape[1])\n",
    "\n",
    "#mask and convert to int climate\n",
    "Y = np.array(subdata.label)\n",
    "\n",
    "\n",
    "\n",
    "print(Y.shape)\n",
    "print(X.shape)\n",
    "#shuffle the data\n",
    "\n",
    "X, Y = shuffle(X, Y, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "#split into training and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ffa172c-ac3f-45a8-bda2-ab3c1530d96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1200x75261 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 26161 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train)\n",
    "X_test_tfidf=tfidf_transformer.fit_transform(X_test)\n",
    "#transform the count matrix X_train to a normalized tf-idf representation\n",
    "X_train_tfidf.shape \n",
    "X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "258e00ae-4b2d-4a68-838b-8f8681d8565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [X_train, X_train_tfidf]\n",
    "test = [X_test, X_test_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43365c60-d65e-4f22-be91-708088660b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n",
      "Best Score:  0.9394273127753303\n",
      "Best Params:  {'C': 0.1}\n",
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n",
      "Best Score:  0.9443832599118943\n",
      "Best Params:  {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "C = [0.01, 0.1, 1, 10, 100, 1000, 10000] \n",
    "\n",
    "\n",
    "param_grid = dict(C=C) \n",
    "\n",
    "logistic = LogisticRegression(solver = 'lbfgs', penalty = 'l2') \n",
    "\n",
    "grid = GridSearchCV(estimator=logistic, param_grid=param_grid, scoring='roc_auc', verbose=1, n_jobs=-1, cv = 10) \n",
    "\n",
    "for features in (train) : \n",
    "    grid_result = grid.fit(features, Y_train) \n",
    "    print('Best Score: ', grid_result.best_score_) \n",
    "    print('Best Params: ', grid_result.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd1d1f70-d88e-42f8-84f1-aa10d9c31da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best Score:  0.9300830227041681\n",
      "Best Params:  {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000, 'n_jobs': -1, 'penalty': 'l2'}\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best Score:  0.9419518807184005\n",
      "Best Params:  {'alpha': 0.0001, 'loss': 'log', 'max_iter': 1000000.0, 'n_jobs': -1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "penalty = ['l1', 'l2', 'elasticnet'] \n",
    "alpha = [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 10]\n",
    "loss=['log', 'hinge']\n",
    "max_iter=[1000, 10000, 100000, 1e6]\n",
    "n_jobs = [-1]\n",
    "\n",
    "\n",
    "param_grid = dict(penalty=penalty, \n",
    "alpha=alpha,loss=loss,max_iter=max_iter, n_jobs=n_jobs) \n",
    "\n",
    "logistic = SGDClassifier() \n",
    "\n",
    "grid = GridSearchCV(estimator=logistic, param_grid=param_grid, scoring='roc_auc', verbose=1, n_jobs=-1, cv = 10) \n",
    "\n",
    "for features in (train) : \n",
    "    grid_result = grid.fit(features, Y_train) \n",
    "    print('Best Score: ', grid_result.best_score_) \n",
    "    print('Best Params: ', grid_result.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acfee99b-0708-41af-8c37-30ab0df9ab5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9508333333333333\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs',C = 10, penalty='l2').fit(X_train_tfidf, Y_train)\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "print('Accuracy:{}'.format(np.mean(predicted == Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcf6f2e2-b317-41aa-89ea-b2225e1e8fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gases' 'fuels' 'diesel' 'greenhouse gases' 'levels' 'increase' 'gas'\n",
      " 'warmer' 'carbon tax' '2010' 'climate change' 'precipitation' 'emission'\n",
      " 'change' 'glaciers' 'policy' 'GHG' 'global warming' 'global' 'greenhouse'\n",
      " 'cap' 'temperatures' 'Glacier' 'warming' 'increased' 'fuel' 'carbon'\n",
      " 'climate' 'Climate' 'emissions']\n"
     ]
    }
   ],
   "source": [
    "coefs=clf.coef_[0]\n",
    "top_three = np.argpartition(coefs, -30)[-30:]\n",
    "print(np.array(vectorizer.get_feature_names_out())[top_three])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6eda2d28-78b7-421a-8768-1e59aa003f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.95\n"
     ]
    }
   ],
   "source": [
    "clf_sdg = SGDClassifier(loss=\"log\", penalty=\"l2\", alpha = 0.0001,   max_iter=1e6, n_jobs=-1).fit(X_train_tfidf, Y_train)\n",
    "predicted = clf_sdg.predict(X_test_tfidf)\n",
    "print('Accuracy:{}'.format(np.mean(predicted == Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcb05b20-7ce8-4814-9a49-972bd42954f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['climate change' '2010' 'precipitation' 'CO' 'greenhouse gases' 'gases'\n",
      " 'temperature' 'global' 'policy' 'emission' 'fuel' 'levels' 'cap' 'fuels'\n",
      " 'GHG' 'increased' 'glaciers' 'temperatures' 'diesel' 'change' 'carbon'\n",
      " 'global warming' 'greenhouse' 'Glacier' 'gas' 'emissions' 'climate'\n",
      " 'Climate' 'warmer' 'warming']\n"
     ]
    }
   ],
   "source": [
    "coefs_sdg=clf_sdg.coef_[0]\n",
    "top_three_sdg = np.argpartition(coefs_sdg, -30)[-30:]\n",
    "\n",
    "print(np.array(vectorizer.get_feature_names_out())[top_three_sdg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90f3931d-329a-43da-9d41-c425d6d718ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = np.array(vectorizer.get_feature_names_out())[top_three]\n",
    "keywords=np.delete(keywords, [4, 5, 9, 15, 18, 24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28c9603d-1216-4489-ab78-13bfb242a152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gases', 'fuels', 'diesel', 'greenhouse gases', 'gas', 'warmer',\n",
       "       'carbon tax', 'climate change', 'precipitation', 'emission',\n",
       "       'change', 'glaciers', 'GHG', 'global warming', 'greenhouse', 'cap',\n",
       "       'temperatures', 'Glacier', 'warming', 'fuel', 'carbon', 'climate',\n",
       "       'Climate', 'emissions'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ada/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/ada/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cda5565-556e-48cc-b50a-e75d4015575e",
   "metadata": {},
   "source": [
    "> #### B/ Recover climate quotation from Quotebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b031381d-12de-49d0-beb2-11debbae3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_filtering(chunk, lst):\n",
    "    template=[] #Creation of an empty list :it's always cheaper to append to a list and create a DataFrame than append on a empty dataframe.\n",
    "    for i in lst: \n",
    "        template.append(chunk.loc[chunk[\"quotation\"].apply(lambda x : i in x) & \n",
    "                                  chunk[\"speaker\"].apply(lambda x: x!= \"None\")&\n",
    "                                  chunk[\"qids\"].apply(lambda x: len(np.array(x))==1)].drop(['phase'], axis=1))\n",
    "        #Select quotations with value in speaker column different from 'None' and quotations containing the key word and drop Phase column. \n",
    "        #As the speaker is identified by their name and not their QID, we select the ones that have a unique QID to facilitate our analysis.\n",
    "        \n",
    "    return (pd.concat(template, ignore_index=True))# return a dataframe with our data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fcbcd14-ca03-4df4-983f-ad2b844a5d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico={} #We create a dictonary to loop over our years. \n",
    "for date in [2020, 2019, 2018, 2017, 2016, 2015]:\n",
    "    dico[date] = pd.read_json(f'data/quotes-{date}.json.bz2', lines=True, compression='bz2', chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7904c1b3-2210-480c-9f6c-ee5576e8330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date, df in dico.items() : \n",
    "    for i, chunk in enumerate(df) : \n",
    "        chunk_clean=chunk_filtering(chunk, keywords) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf=f\"data/clean_quotes-{date}.bz2\",compression='bz2',header=header, mode=mode, index = False ) #Load to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139e7ea8-90f5-46df-9dbf-141297edba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_clean={} \n",
    "length = 0\n",
    "for date in [2020, 2019, 2018, 2017, 2016, 2015]:\n",
    "    dico_clean[date] = pd.read_csv(f'data/clean_quotes-{date}.bz2', compression='bz2')\n",
    "    length += len(dico_clean[date]) #The length is used here to obtain the total number of quotes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12781cd5-f83d-4297-b58a-1e06a212bca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " At result, we extracted 2324231 quotes fromes quotebank data\n"
     ]
    }
   ],
   "source": [
    "print(\" At result, we extracted {} quotes fromes quotebank data\".format(length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ebf7f-c01e-443b-980a-354e326d4b9c",
   "metadata": {},
   "source": [
    "Even with key_word selection we success to extract a satisfying quantity of data from the Quotebank data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a6a56-c643-4f00-8e53-72611156d0f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load additional data Relative to speakers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca79c6a1-b624-41a9-856b-5b5a014b9d0a",
   "metadata": {},
   "source": [
    "### Extracted labels from QID "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5adca85-ec46-4904-b3c5-0395e659767a",
   "metadata": {},
   "source": [
    "The provided speaker_attributes.parquet file contains attributes in terms of QIDs, thereby being uninterpretable by humans (df_qid).\n",
    "To map the QIDs to meaningful labels, we used the provided wikidata_labels_descriptions_quotebank.csv.bz2 containing the label and value for the respective QID containing the df_qid (df_label_qid).\n",
    "By combining the information of both we can obtained usefull information about speakers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914c57ef-174f-4975-a837-4833ad5eb0da",
   "metadata": {},
   "source": [
    "#### *Load parquet file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "280f0f07-1673-4e62-a70f-81296b7db81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading our speakers attribute dataset, and the dataset necessary to interpret our QIDs.\n",
    "df_qid = pd.read_parquet(\"speaker_attributes.parquet\",engine= \"pyarrow\" )\n",
    "df_label_qid = pd.read_csv('data/wikidata_labels_descriptions_quotebank.csv',index_col='QID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188fd90e-a183-4ade-aa7d-15ecb3026eb6",
   "metadata": {},
   "source": [
    "#### *Somes visualisation and sort of the parquet file*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6498a207-69dc-4988-82c2-7174093ea71f",
   "metadata": {},
   "source": [
    "First let's check if the identifier are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c2170ea-6bf9-4df5-81e8-59ece97ad890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qid.id.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2db133-e8c3-43aa-ae20-07ded9ad40a7",
   "metadata": {},
   "source": [
    "Before extract the label of QID, let's check which column we want to keep in frame with our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b98c8e-74a1-44c5-bc6e-395b22c4440b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aliases</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>lastrevid</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>US_congress_bio_ID</th>\n",
       "      <th>occupation</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>candidacy</th>\n",
       "      <th>type</th>\n",
       "      <th>religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Washington, President Washington, G. Washingt...</td>\n",
       "      <td>[+1732-02-22T00:00:00Z]</td>\n",
       "      <td>[Q161885, Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1395141751</td>\n",
       "      <td>None</td>\n",
       "      <td>W000178</td>\n",
       "      <td>[Q82955, Q189290, Q131512, Q1734662, Q294126, ...</td>\n",
       "      <td>[Q327591]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q23</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>[Q698073, Q697949]</td>\n",
       "      <td>item</td>\n",
       "      <td>[Q682443]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Douglas Noel Adams, Douglas Noël Adams, Dougl...</td>\n",
       "      <td>[+1952-03-11T00:00:00Z]</td>\n",
       "      <td>[Q145]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1395737157</td>\n",
       "      <td>[Q7994501]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q214917, Q28389, Q6625963, Q4853732, Q1884422...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q42</td>\n",
       "      <td>Douglas Adams</td>\n",
       "      <td>None</td>\n",
       "      <td>item</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Paul Marie Ghislain Otlet, Paul Marie Otlet]</td>\n",
       "      <td>[+1868-08-23T00:00:00Z]</td>\n",
       "      <td>[Q31]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1380367296</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q36180, Q40348, Q182436, Q1265807, Q205375, Q...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q1868</td>\n",
       "      <td>Paul Otlet</td>\n",
       "      <td>None</td>\n",
       "      <td>item</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             aliases            date_of_birth  \\\n",
       "0  [Washington, President Washington, G. Washingt...  [+1732-02-22T00:00:00Z]   \n",
       "1  [Douglas Noel Adams, Douglas Noël Adams, Dougl...  [+1952-03-11T00:00:00Z]   \n",
       "2      [Paul Marie Ghislain Otlet, Paul Marie Otlet]  [+1868-08-23T00:00:00Z]   \n",
       "\n",
       "      nationality      gender   lastrevid ethnic_group US_congress_bio_ID  \\\n",
       "0  [Q161885, Q30]  [Q6581097]  1395141751         None            W000178   \n",
       "1          [Q145]  [Q6581097]  1395737157   [Q7994501]               None   \n",
       "2           [Q31]  [Q6581097]  1380367296         None               None   \n",
       "\n",
       "                                          occupation      party  \\\n",
       "0  [Q82955, Q189290, Q131512, Q1734662, Q294126, ...  [Q327591]   \n",
       "1  [Q214917, Q28389, Q6625963, Q4853732, Q1884422...       None   \n",
       "2  [Q36180, Q40348, Q182436, Q1265807, Q205375, Q...       None   \n",
       "\n",
       "  academic_degree     id              label           candidacy  type  \\\n",
       "0            None    Q23  George Washington  [Q698073, Q697949]  item   \n",
       "1            None    Q42      Douglas Adams                None  item   \n",
       "2            None  Q1868         Paul Otlet                None  item   \n",
       "\n",
       "    religion  \n",
       "0  [Q682443]  \n",
       "1       None  \n",
       "2       None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qid.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a524d4e3-29a4-49eb-b646-c6fc63e54220",
   "metadata": {},
   "source": [
    "Let's verify that academic_degree has revelant values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "293730b9-06ea-4bfd-909e-ab8a7cb806a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's no academic degree revelant value ? False\n"
     ]
    }
   ],
   "source": [
    "print(\"There's no academic degree revelant value ? {}\".format(all(df_qid.academic_degree.isna())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573efeb6-dd9b-4121-8e10-d926f222795d",
   "metadata": {},
   "source": [
    "It seems that academic degree values are revelant, we decided to drop lastrevid, US_congress_bio_ID, type, Alisiase as they will not be used in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "677d65e5-50ff-480a-b5ae-6f7d18551117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qid.drop(['lastrevid', 'US_congress_bio_ID', 'type', 'aliases'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c49349-c401-4036-820d-3e11bcd30e56",
   "metadata": {},
   "source": [
    "#### *Transformation of the df_qid with the label value from df_label_qid*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cc78a55-e296-45f5-beb7-0bd02275b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We found that one of the QID was deleted from Wikidata. We will start by dropping this value, so that it does not distrurb our labelling. \n",
    "\n",
    "def transform(y):\n",
    "    if y is None: return None\n",
    "    x = set(y)\n",
    "    x.discard(\"Q99753484\")\n",
    "    return np.array(list(x))\n",
    "    \n",
    "df_qid['occupation']=df_qid['occupation'].apply(lambda y : transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93b693da-56ee-4eaa-91a8-b6cd1a5e4201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We found out that some of the QIDs used in the speaker attribute file are actually redirection from an original QID. \n",
    "#We will manulally add their corresponding information using the orginal QID. We found the corespondance manualy between the two. \n",
    "#Here, there are in order, respectively the redirection QID, and its corresponding original one. One of he QID was only present \n",
    "#as a redirection, so we manually added this one (Q3186984), and its corresponding info. \n",
    "\n",
    "redirect_QID=['Q3268166', 'Q11815360', 'Q12014399', 'Q16287483',\n",
    "              'Q20432251', 'Q21550646', 'Q13365117', 'Q13424794',\n",
    "             'Q1248362', 'Q6859927', 'Q15145782',\n",
    "             'Q15991263', 'Q12455619', 'Q5568256', \n",
    "             'Q6363085', 'Q11819457', 'Q12334852', 'Q15145783']\n",
    "actual_QID=['Q1113899', 'Q1919436', 'Q250867', 'Q6051619',\n",
    "             'Q26934816', 'Q18431816', 'Q12840545', 'Q5157338',\n",
    "            'Q3455803', 'Q715222', 'Q1052281',\n",
    "            'Q2743689', 'Q7019111', 'Q3738699', \n",
    "            'Q380075', 'Q3391743', 'Q476246', 'Q2449503']\n",
    "\n",
    "\n",
    "lst=[['Journalist', 'monthly magazine of the United Kingdom‘s National Union of Journalists (NUJ)']]\n",
    "indexes=['Q3186984']\n",
    "col=['Label', 'Description']\n",
    "for i in range(len(redirect_QID)):\n",
    "    lst.append([df_label_qid.loc[actual_QID[i]]['Label'], \n",
    "                df_label_qid.loc[actual_QID[i]]['Description']])\n",
    "    indexes.append(redirect_QID[i])\n",
    "\n",
    "additional_df= pd.DataFrame(lst, columns= col, index=indexes)\n",
    "df_label=df_label_qid.append(additional_df, ignore_index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c57de3a5-d299-46c2-b909-d7e2eda2a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the function to every column containing QIDs. \n",
    "cols=['nationality', 'gender', 'ethnic_group','occupation', 'party', 'academic_degree', 'candidacy', 'religion'] #List of columns \n",
    "#containing QID to be replace\n",
    "\n",
    "df_qid[cols] = df_qid[cols].applymap(lambda d: d if d is not None else []) #Replacing every None value with an empty list for futur analysis.\n",
    "df_qid[cols] = df_qid[cols].applymap(lambda y: [df_label.loc[Q].Label for Q in y]) #Replacing QIDs with their corresponding label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7983c6a-9c8e-4dce-b7a1-c1f64939199a",
   "metadata": {},
   "source": [
    "### Let's have additional data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeefadd-c452-4dae-b94d-b24b6aac0e9e",
   "metadata": {},
   "source": [
    "Now, we want to see which speakers said quotes that we consider as climate-related and climate change sceptical. We will match speaker from the df_qid with a value septic/climate. We will add two boolean columns to our dataframe df_qid: one for climate-related, and one for climate change sceptical. In order to do that, we will select every QID that appears in our list of climate-related-quotes and climat-change-sceptical quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515d461-71da-4470-aa9c-7f0ee0f14ad0",
   "metadata": {},
   "source": [
    "#### *Qid_climate list*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cb4094a-b48b-4837-a1f3-933d6dffa411",
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_climate=[]\n",
    "\n",
    "#iteration in the dico_clean containing extracted files for climate involved quotes\n",
    "for key, file in dico_clean.items() :\n",
    "    qid_climate.append(file.drop_duplicates(['qids'], keep='first')['qids'].map(lambda y : ast.literal_eval(y)[0]).tolist()) #add unique QIDs from each file\n",
    "qid_climate=set(item for sublist in qid_climate for item in sublist)#create a set with unique QIDs from each year/file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79aadf56-76c5-41ba-9401-2fa9515cb0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We extracted 255071 QIDs related to speakers that talk about climate.\n"
     ]
    }
   ],
   "source": [
    "print(\"We extracted {} QIDs related to speakers that talk about climate.\".format(len(qid_climate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb6384-8a23-48f0-8c8d-d52393c89c6a",
   "metadata": {},
   "source": [
    "#### *Add an additional column to df_qid*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6409500f-8ac6-4871-99e6-9aa6af44ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qid['climate']=0 #create a column named climate with value equals 0\n",
    "df_qid.loc[df_qid[pd.Index(df_qid.id.isin(pd.Index(qid_climate)))].index, 'climate']=1 #replace with 1 for speakers that appear in the climate-involved quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6abf7718-97e7-47ee-ac69-d0bee4705da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>occupation</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>candidacy</th>\n",
       "      <th>religion</th>\n",
       "      <th>climate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6260638</th>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[researcher]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q60398126</td>\n",
       "      <td>Tim Ryley</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686110</th>\n",
       "      <td>[+1811-00-00T00:00:00Z]</td>\n",
       "      <td>[Qing dynasty]</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[politician]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[jinshi]</td>\n",
       "      <td>Q15935968</td>\n",
       "      <td>Wenbin Gu</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822307</th>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[researcher]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q56380944</td>\n",
       "      <td>Guillem Bagaria</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638823</th>\n",
       "      <td>[+1809-03-06T00:00:00Z]</td>\n",
       "      <td>[Kingdom of Prussia]</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[teacher, high school teacher, classical philo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q21543832</td>\n",
       "      <td>Johann Karl August Goebel</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Protestantism]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334051</th>\n",
       "      <td>[+1979-09-20T00:00:00Z]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q95168269</td>\n",
       "      <td>Roman Drga</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7991459</th>\n",
       "      <td>[+1916-11-18T00:00:00Z, +1916-02-18T00:00:00Z]</td>\n",
       "      <td>[Spain]</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[association football player]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q2056018</td>\n",
       "      <td>José Bravo</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319796</th>\n",
       "      <td>[+1953-09-10T00:00:00Z]</td>\n",
       "      <td>[Germany]</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[painter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q1609211</td>\n",
       "      <td>Herbert Tomm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627926</th>\n",
       "      <td>[+1987-01-22T00:00:00Z]</td>\n",
       "      <td>[Israel]</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[singer-songwriter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q63203155</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156273</th>\n",
       "      <td>None</td>\n",
       "      <td>[Ming dynasty]</td>\n",
       "      <td>[male]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q45661023</td>\n",
       "      <td>Li Changtai</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038034</th>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[researcher]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q93104466</td>\n",
       "      <td>Howard L Parnes</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          date_of_birth           nationality  \\\n",
       "6260638                                            None                    []   \n",
       "3686110                         [+1811-00-00T00:00:00Z]        [Qing dynasty]   \n",
       "2822307                                            None                    []   \n",
       "2638823                         [+1809-03-06T00:00:00Z]  [Kingdom of Prussia]   \n",
       "4334051                         [+1979-09-20T00:00:00Z]                    []   \n",
       "7991459  [+1916-11-18T00:00:00Z, +1916-02-18T00:00:00Z]               [Spain]   \n",
       "2319796                         [+1953-09-10T00:00:00Z]             [Germany]   \n",
       "627926                          [+1987-01-22T00:00:00Z]              [Israel]   \n",
       "6156273                                            None        [Ming dynasty]   \n",
       "2038034                                            None                    []   \n",
       "\n",
       "         gender ethnic_group  \\\n",
       "6260638      []           []   \n",
       "3686110  [male]           []   \n",
       "2822307      []           []   \n",
       "2638823  [male]           []   \n",
       "4334051  [male]           []   \n",
       "7991459  [male]           []   \n",
       "2319796  [male]           []   \n",
       "627926   [male]           []   \n",
       "6156273  [male]           []   \n",
       "2038034      []           []   \n",
       "\n",
       "                                                occupation party  \\\n",
       "6260638                                       [researcher]    []   \n",
       "3686110                                       [politician]    []   \n",
       "2822307                                       [researcher]    []   \n",
       "2638823  [teacher, high school teacher, classical philo...    []   \n",
       "4334051                                                 []    []   \n",
       "7991459                      [association football player]    []   \n",
       "2319796                                          [painter]    []   \n",
       "627926                                 [singer-songwriter]    []   \n",
       "6156273                                                 []    []   \n",
       "2038034                                       [researcher]    []   \n",
       "\n",
       "        academic_degree         id                      label candidacy  \\\n",
       "6260638              []  Q60398126                  Tim Ryley        []   \n",
       "3686110        [jinshi]  Q15935968                  Wenbin Gu        []   \n",
       "2822307              []  Q56380944            Guillem Bagaria        []   \n",
       "2638823              []  Q21543832  Johann Karl August Goebel        []   \n",
       "4334051              []  Q95168269                 Roman Drga        []   \n",
       "7991459              []   Q2056018                 José Bravo        []   \n",
       "2319796              []   Q1609211               Herbert Tomm        []   \n",
       "627926               []  Q63203155                       None        []   \n",
       "6156273              []  Q45661023                Li Changtai        []   \n",
       "2038034              []  Q93104466            Howard L Parnes        []   \n",
       "\n",
       "                religion  climate  \n",
       "6260638               []        0  \n",
       "3686110               []        0  \n",
       "2822307               []        0  \n",
       "2638823  [Protestantism]        0  \n",
       "4334051               []        0  \n",
       "7991459               []        0  \n",
       "2319796               []        0  \n",
       "627926                []        0  \n",
       "6156273               []        0  \n",
       "2038034               []        0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qid.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1287ac-2d6a-4df4-b405-77866fda47bc",
   "metadata": {},
   "source": [
    "#### *Load resulting data into a csv compressed filled*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6792ede4-8efd-4481-a524-4e4d052299db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qid.to_csv(\"data/speaker_attribute.bz2\", compression = 'bz2', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8a1db0-542d-4b9f-a27b-c780e2a03267",
   "metadata": {},
   "source": [
    "# II- Filter the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1547a11-c37a-42a7-bc86-8abc812ef6e7",
   "metadata": {},
   "source": [
    "As a good data scientist, the first thing to do is to clean up the data. In order to do that, we will first check for missing rows. Then we will replace the date of birth by the year of birth. Lastly, we will filter our speakers in order to keep only the ones whose age is bewteen 12 and 100 . (As climate change is a relatively new topic, and we do not consider quotes from speakers that are younger then 12 years old)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b245cf94-a041-4d7a-8fd9-717b9cf6a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers=pd.read_csv(\"data/speaker_attribute.bz2\", compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8158b922-c0d0-40dc-9821-9e4a842a3209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>occupation</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>candidacy</th>\n",
       "      <th>religion</th>\n",
       "      <th>climate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['+1732-02-22T00:00:00Z']</td>\n",
       "      <td>['Great Britain', 'United States of America']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['military officer', 'engineer', 'land surveyo...</td>\n",
       "      <td>['independent politician']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q23</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>['1792 United States presidential election', '...</td>\n",
       "      <td>['Episcopal Church']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['+1952-03-11T00:00:00Z']</td>\n",
       "      <td>['United Kingdom']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['White British']</td>\n",
       "      <td>['novelist', 'science fiction writer', 'comedi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q42</td>\n",
       "      <td>Douglas Adams</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['+1868-08-23T00:00:00Z']</td>\n",
       "      <td>['Belgium']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['bibliographer', 'inventor', 'librarian', 'la...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q1868</td>\n",
       "      <td>Paul Otlet</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['+1946-07-06T00:00:00Z']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['autobiographer', 'military officer', 'rugby ...</td>\n",
       "      <td>['Republican Party']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q207</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>['2000 United States presidential election', '...</td>\n",
       "      <td>['United Methodist Church', 'Episcopal Church'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['+1599-06-06T00:00:00Z']</td>\n",
       "      <td>['Spain']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['painter']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q297</td>\n",
       "      <td>Diego Velázquez</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date_of_birth                                    nationality  \\\n",
       "0  ['+1732-02-22T00:00:00Z']  ['Great Britain', 'United States of America']   \n",
       "1  ['+1952-03-11T00:00:00Z']                             ['United Kingdom']   \n",
       "2  ['+1868-08-23T00:00:00Z']                                    ['Belgium']   \n",
       "3  ['+1946-07-06T00:00:00Z']                   ['United States of America']   \n",
       "4  ['+1599-06-06T00:00:00Z']                                      ['Spain']   \n",
       "\n",
       "     gender       ethnic_group  \\\n",
       "0  ['male']                 []   \n",
       "1  ['male']  ['White British']   \n",
       "2  ['male']                 []   \n",
       "3  ['male']                 []   \n",
       "4  ['male']                 []   \n",
       "\n",
       "                                          occupation  \\\n",
       "0  ['military officer', 'engineer', 'land surveyo...   \n",
       "1  ['novelist', 'science fiction writer', 'comedi...   \n",
       "2  ['bibliographer', 'inventor', 'librarian', 'la...   \n",
       "3  ['autobiographer', 'military officer', 'rugby ...   \n",
       "4                                        ['painter']   \n",
       "\n",
       "                        party academic_degree     id              label  \\\n",
       "0  ['independent politician']              []    Q23  George Washington   \n",
       "1                          []              []    Q42      Douglas Adams   \n",
       "2                          []              []  Q1868         Paul Otlet   \n",
       "3        ['Republican Party']              []   Q207     George W. Bush   \n",
       "4                          []              []   Q297    Diego Velázquez   \n",
       "\n",
       "                                           candidacy  \\\n",
       "0  ['1792 United States presidential election', '...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  ['2000 United States presidential election', '...   \n",
       "4                                                 []   \n",
       "\n",
       "                                            religion  climate  \n",
       "0                               ['Episcopal Church']        0  \n",
       "1                                                 []        0  \n",
       "2                                                 []        0  \n",
       "3  ['United Methodist Church', 'Episcopal Church'...        1  \n",
       "4                                                 []        0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534141a-105f-48ba-9e87-daa98425ca57",
   "metadata": {},
   "source": [
    "> ##### *check for missing row*\n",
    "We consider that a row is missing if we don't have information about speakers attributes (i.e other than label, qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a824dab5-3740-49b3-b29e-0f0b401546a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there some missing rows ? False \n"
     ]
    }
   ],
   "source": [
    "print(\"Is there some missing rows ? {} \".format(np.array([speakers.drop(columns=['label', 'id']).isnull().any(axis=1)]).all()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ed2c35-c9b6-4a22-8aba-55960c6662b5",
   "metadata": {},
   "source": [
    "> ##### *Clean and filter date of birth and speakers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "483de8d5-202b-48e4-97b6-decd7bf86c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers.date_of_birth=speakers.fillna(0).date_of_birth.map(lambda y : str(y).split(\"-\")[0][3:])#Keep only the year of birth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e01007a-48a9-4990-b3c3-20f095de6226",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers=speakers.loc[speakers['date_of_birth'].apply(lambda x: x!= '' and int(x)>1920 and int(x)< 2008)]#Keep only speakers born after 1920."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d349fc15-b1b1-4572-beab-84fb765eb5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers['date_of_birth']=speakers['date_of_birth'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "618c2c4f-197e-455d-9635-0988ff33a438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>occupation</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>candidacy</th>\n",
       "      <th>religion</th>\n",
       "      <th>climate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5477326</th>\n",
       "      <td>1968</td>\n",
       "      <td>[]</td>\n",
       "      <td>['female']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['painter', 'gallerist']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q95381476</td>\n",
       "      <td>Světlana Žalmánková</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594079</th>\n",
       "      <td>1961</td>\n",
       "      <td>['Kingdom of the Netherlands']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['sport cyclist', 'track cyclist']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q2054383</td>\n",
       "      <td>Rik Moorman</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3586970</th>\n",
       "      <td>1985</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['association football player']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q7035411</td>\n",
       "      <td>Niko Gkionis</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8133178</th>\n",
       "      <td>1993</td>\n",
       "      <td>['Thailand']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['association football player']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q7973111</td>\n",
       "      <td>Watchara Buathong</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4921551</th>\n",
       "      <td>1938</td>\n",
       "      <td>['Soviet Union', 'Russia']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['chemist']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Doktor Nauk in Chemistry']</td>\n",
       "      <td>Q24350882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date_of_birth                     nationality      gender  \\\n",
       "5477326           1968                              []  ['female']   \n",
       "4594079           1961  ['Kingdom of the Netherlands']    ['male']   \n",
       "3586970           1985    ['United States of America']    ['male']   \n",
       "8133178           1993                    ['Thailand']    ['male']   \n",
       "4921551           1938      ['Soviet Union', 'Russia']    ['male']   \n",
       "\n",
       "        ethnic_group                          occupation party  \\\n",
       "5477326           []            ['painter', 'gallerist']    []   \n",
       "4594079           []  ['sport cyclist', 'track cyclist']    []   \n",
       "3586970           []     ['association football player']    []   \n",
       "8133178           []     ['association football player']    []   \n",
       "4921551           []                         ['chemist']    []   \n",
       "\n",
       "                      academic_degree         id                label  \\\n",
       "5477326                            []  Q95381476  Světlana Žalmánková   \n",
       "4594079                            []   Q2054383          Rik Moorman   \n",
       "3586970                            []   Q7035411         Niko Gkionis   \n",
       "8133178                            []   Q7973111    Watchara Buathong   \n",
       "4921551  ['Doktor Nauk in Chemistry']  Q24350882                  NaN   \n",
       "\n",
       "        candidacy religion  climate  \n",
       "5477326        []       []        0  \n",
       "4594079        []       []        0  \n",
       "3586970        []       []        0  \n",
       "8133178        []       []        0  \n",
       "4921551        []       []        0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers.sample(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
