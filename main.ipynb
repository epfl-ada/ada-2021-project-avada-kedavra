{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6630819-7845-4bfb-b746-6a7e780e0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "#load the statistical libraries\n",
    "from statsmodels.stats import diagnostic\n",
    "from scipy import stats\n",
    "import ast\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "#NLP libraries\n",
    "import spacy, nltk, gensim, sklearn\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "\n",
    "#Scikit imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1981b18-a20b-4b10-b585-0b15563a9d26",
   "metadata": {
    "tags": []
   },
   "source": [
    "# General information Remark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9c90b-4fd4-4d09-8163-7c2b7021c9b3",
   "metadata": {},
   "source": [
    "### In the loading part we will recover data from 2015 to 2020, however, first visulation (part III) will only be on the data from 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b3b89-46e1-4377-96ab-830501273244",
   "metadata": {},
   "source": [
    "# I- Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edcfe19-c424-4435-86bd-b0eb11096498",
   "metadata": {},
   "source": [
    "### Load Quotebank data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6264bc75-8b74-44f3-9e45-c079a54bea3b",
   "metadata": {},
   "source": [
    "First, let's recover the quotations of interest : as our project is based on the caracterisation of speakers, we decide to pre-select the quotations that are related to a speaker (i.e speaker value is different from 'None'). \n",
    "Moreover, we select the quotations whose subject is related to climate change : to do so we will recover a list of keyword related to climate subject by analyzing wwith NLP the dataset train_climate.tcsv. Then, we select quotes that contains at least one of these words(cf chunk_filtering method)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ee82b-a84e-4d40-ab45-136506d70769",
   "metadata": {},
   "source": [
    "> #### A/ Recovering of the keyword list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32930eb4-8b96-40a5-973f-a5f0531ae128",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('data/Wiki_train.tsv', sep='\\t')\n",
    "data2=pd.read_csv('data/train_1.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40bcd013-2233-44fe-84db-20398f37bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.drop(labels = ['id', 'paragraph', 'title'], axis=1, inplace=True)\n",
    "data2.drop(labels = ['id', 'paragraph', 'title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb439466-7a67-4d03-aee0-a5ac5f6ed6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdata = pd.concat([data1, data2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d119a-8b82-4e7b-b465-702a0318b573",
   "metadata": {},
   "source": [
    "> ##### Creation of our bag of word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a20ae06-31fe-499d-917e-3794919d1735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 6000\n",
      "Number of features: 75261\n",
      "(6000,)\n",
      "(6000, 75261)\n"
     ]
    }
   ],
   "source": [
    "#Convert the collection of text documents to a matrix of token counts.\n",
    "#remove stop_word, and select n_gram of maximum size (1,2), lowercase = False bcause we ay recover some name's organisation. \n",
    "vectorizer = CountVectorizer(stop_words = 'english',ngram_range=(1, 2),lowercase=False)\n",
    "\n",
    "\n",
    "#create bag of words features\n",
    "X = vectorizer.fit_transform(subdata.sentence)\n",
    "\n",
    "\n",
    "print('Number of samples:',X.toarray().shape[0])\n",
    "print('Number of features:',X.toarray().shape[1])\n",
    "\n",
    "#mask and convert to int climate\n",
    "Y = np.array(subdata.label)\n",
    "\n",
    "print(Y.shape)\n",
    "print(X.shape)\n",
    "\n",
    "#shuffle the data\n",
    "\n",
    "X, Y = shuffle(X, Y, random_state=0)\n",
    "\n",
    "#split into training and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e92de-9008-4567-a9db-64855dd1c302",
   "metadata": {},
   "source": [
    "TF-IDF is a popular approach used to weigh terms for NLP tasks because it assigns a value to a term according to its importance in a document scaled by its importance across all documents in your corpus. Let's transform our bag-of-word with tf-idf and see if we get better result with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ffa172c-ac3f-45a8-bda2-ab3c1530d96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 75261)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "#transform the count matrix X_train and X_test to a normalized tf-idf representation\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train)\n",
    "X_test_tfidf=tfidf_transformer.fit_transform(X_test)\n",
    "\n",
    "\n",
    "X_train_tfidf.shape \n",
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "258e00ae-4b2d-4a68-838b-8f8681d8565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [X_train, X_train_tfidf]\n",
    "test = [X_test, X_test_tfidf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60db89a-1dd5-4b36-863f-21d1491ce21b",
   "metadata": {},
   "source": [
    "> Train a supervised classifier based on the labeled docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53466862-2efb-4303-a54b-a2abc1edb705",
   "metadata": {},
   "source": [
    "We will train logistic regression for the classification task and find the keyword related to climate. As we see previoulsy we get more feature than documents, so we need to regularized our method : we will try l2 regularization for basic logistic regression. \n",
    "We will use cross validation to hypertun our parameter and as logistic regression by default uses Gradient Descent, we will compare it to SGD Classifier which use which gradient descent making it faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43365c60-d65e-4f22-be91-708088660b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n",
      "Best Score:  0.9394273127753303\n",
      "Best Params:  {'C': 0.1}\n",
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n",
      "Best Score:  0.9443832599118943\n",
      "Best Params:  {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "C = [0.01, 0.1, 1, 10, 100, 1000, 10000] \n",
    "\n",
    "\n",
    "param_grid = dict(C=C) \n",
    "\n",
    "logistic = LogisticRegression(solver = 'lbfgs', penalty = 'l2') \n",
    "\n",
    "grid = GridSearchCV(estimator=logistic, param_grid=param_grid, scoring='roc_auc', verbose=1, n_jobs=-1, cv = 10) \n",
    "\n",
    "for features in (train) : \n",
    "    grid_result = grid.fit(features, Y_train) \n",
    "    print('Best Score: ', grid_result.best_score_) \n",
    "    print('Best Params: ', grid_result.best_params_) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc360cde-7843-40ab-9a26-bff26e72675d",
   "metadata": {},
   "source": [
    "> C = 10, and tf-idf train data gives us the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd1d1f70-d88e-42f8-84f1-aa10d9c31da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best Score:  0.9302736360555744\n",
      "Best Params:  {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000, 'n_jobs': -1, 'penalty': 'l2'}\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Best Score:  0.9419518807184005\n",
      "Best Params:  {'alpha': 0.0001, 'loss': 'log', 'max_iter': 100000, 'n_jobs': -1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "penalty = ['l1', 'l2', 'elasticnet'] \n",
    "alpha = [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 10]\n",
    "loss=['log', 'hinge']\n",
    "max_iter=[1000, 10000, 100000, 1e6]\n",
    "n_jobs = [-1]\n",
    "\n",
    "\n",
    "param_grid = dict(penalty=penalty, \n",
    "alpha=alpha,loss=loss,max_iter=max_iter, n_jobs=n_jobs) \n",
    "\n",
    "logistic = SGDClassifier() \n",
    "\n",
    "grid = GridSearchCV(estimator=logistic, param_grid=param_grid, scoring='roc_auc', verbose=1, n_jobs=-1, cv = 10) \n",
    "\n",
    "for features in (train) : \n",
    "    grid_result = grid.fit(features, Y_train) \n",
    "    print('Best Score: ', grid_result.best_score_) \n",
    "    print('Best Params: ', grid_result.best_params_) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e718d190-f486-431f-aa47-b90c76994158",
   "metadata": {},
   "source": [
    "> SDG with logistic regression (loss = 'log'), and tf-idf train data give us approximatly the same score as for basic logitic regression. Let's use both and see which keyword we prefere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acfee99b-0708-41af-8c37-30ab0df9ab5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9508333333333333\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs',C = 10, penalty='l2').fit(X_train_tfidf, Y_train)\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "print('Accuracy:{}'.format(np.mean(predicted == Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcf6f2e2-b317-41aa-89ea-b2225e1e8fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gases' 'fuels' 'diesel' 'greenhouse gases' 'levels' 'increase' 'gas'\n",
      " 'warmer' 'carbon tax' '2010' 'climate change' 'precipitation' 'emission'\n",
      " 'change' 'glaciers' 'policy' 'GHG' 'global warming' 'global' 'greenhouse'\n",
      " 'cap' 'temperatures' 'Glacier' 'warming' 'increased' 'fuel' 'carbon'\n",
      " 'climate' 'Climate' 'emissions']\n"
     ]
    }
   ],
   "source": [
    "coefs=clf.coef_[0] #recover coeffiction from the training\n",
    "top_three = np.argpartition(coefs, -30)[-30:] # rearrange coefficient, and select the 30th first one\n",
    "print(np.array(vectorizer.get_feature_names_out())[top_three])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eda2d28-78b7-421a-8768-1e59aa003f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.95\n"
     ]
    }
   ],
   "source": [
    "clf_sdg = SGDClassifier(loss=\"log\", penalty=\"l2\", alpha = 0.0001,   max_iter=1e6, n_jobs=-1).fit(X_train_tfidf, Y_train)\n",
    "predicted = clf_sdg.predict(X_test_tfidf)\n",
    "print('Accuracy:{}'.format(np.mean(predicted == Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcb05b20-7ce8-4814-9a49-972bd42954f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['increase' 'CO' '2010' 'precipitation' 'global warming' 'global'\n",
      " 'glaciers' 'diesel' 'change' 'warming' 'warmer' 'levels' 'carbon'\n",
      " 'Climate' 'climate' 'gases' 'policy' 'fuels' 'greenhouse gases' 'gas'\n",
      " 'GHG' 'emissions' 'greenhouse' 'emission' 'temperatures' 'temperature'\n",
      " 'Glacier' 'increased' 'cap' 'fuel']\n"
     ]
    }
   ],
   "source": [
    "coefs_sdg=clf_sdg.coef_[0]\n",
    "top_three_sdg = np.argpartition(coefs_sdg, -30)[-30:]\n",
    "\n",
    "print(np.array(vectorizer.get_feature_names_out())[top_three_sdg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4170c-9c9a-446d-ad83-a0e1c9f6d67b",
   "metadata": {},
   "source": [
    "> Both list seems resonable, let's use the one from basic logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f3931d-329a-43da-9d41-c425d6d718ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = np.array(vectorizer.get_feature_names_out())[top_three]\n",
    "keywords=np.delete(keywords, [4, 5, 9,13,  15, 18, 21, 24]) #remove unwanted words that can induce confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28c9603d-1216-4489-ab78-13bfb242a152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gases', 'fuels', 'diesel', 'greenhouse gases', 'gas', 'warmer',\n",
       "       'carbon tax', 'climate change', 'precipitation', 'emission',\n",
       "       'glaciers', 'GHG', 'global warming', 'greenhouse', 'cap',\n",
       "       'Glacier', 'warming', 'fuel', 'carbon', 'climate', 'Climate',\n",
       "       'emissions'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see our final list\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cda5565-556e-48cc-b50a-e75d4015575e",
   "metadata": {},
   "source": [
    "> #### B/ Recover climate quotation from Quotebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b031381d-12de-49d0-beb2-11debbae3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_filtering(chunk, lst):\n",
    "    template=[] #Creation of an empty list :it's always cheaper to append to a list and create a DataFrame than append on a empty dataframe.\n",
    "    for i in lst: \n",
    "        template.append(chunk.loc[(chunk[\"quotation\"].apply(lambda x : i in str(x).split(' ')) )& \n",
    "                                  (chunk[\"speaker\"].apply(lambda x: x!= \"None\"))&\n",
    "                                  (chunk[\"qids\"].apply(lambda x: len(np.array(x))==1))].drop(['phase', 'urls', 'probas'], axis=1))\n",
    "        #Select quotations with value in speaker column different from 'None' and \n",
    "        #quotations containing the key word and drop phase, urls and probas  column. \n",
    "        #As the speaker is identified by their name and not their QID, we select the ones that have a unique QID to facilitate our analysis.\n",
    "        \n",
    "    return (pd.concat(template, ignore_index=True))# return a dataframe with our data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fcbcd14-ca03-4df4-983f-ad2b844a5d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico={} #We create a dictonary to loop over our years. \n",
    "for date in [2020, 2019, 2018, 2017, 2016, 2015]:\n",
    "    dico[date] = pd.read_json(f'data/quotes-{date}.json.bz2', lines=True, compression='bz2', chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56c63b5f-2507-43c7-8085-7b864e7766e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['gases', 'fuels', 'diesel', 'greenhouse gases', 'gas', 'warmer',\n",
    "       'carbon tax', 'climate change', 'precipitation', 'emission',\n",
    "       'glaciers', 'GHG', 'global warming', 'greenhouse', \n",
    "       'Glacier', 'warming', 'fuel', 'carbon', 'climate', 'Climate',\n",
    "       'emissions']\n",
    "\n",
    "\n",
    "for date, df in dico.items() : \n",
    "    for i, chunk in enumerate(df) : \n",
    "        chunk_clean=chunk_filtering(chunk, keywords) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "        chunk_clean.to_csv(path_or_buf=f\"data/clean_quotes-{date}.bz2\",compression='bz2',header=header, mode=mode, index = False ) #Load to CSV.    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "139e7ea8-90f5-46df-9dbf-141297edba9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dico_clean={} \n",
    "length = 0\n",
    "for date in [2020, 2019, 2018, 2017, 2016, 2015]:\n",
    "    clean = pd.read_csv(f'data/clean_quotes-{date}.bz2', compression='bz2')\n",
    "    clean.drop_duplicates(subset=['quotation']) #make sure there's no duplicate\n",
    "    dico_clean[date]=clean #add to the dico\n",
    "    length += len(dico_clean[date]) #The length is used here to obtain the total number of quotes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12781cd5-f83d-4297-b58a-1e06a212bca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " At result, we extracted 333004 quotes fromes quotebank data\n"
     ]
    }
   ],
   "source": [
    "print(\" At result, we extracted {} quotes fromes quotebank data\".format(length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ebf7f-c01e-443b-980a-354e326d4b9c",
   "metadata": {},
   "source": [
    "Even with key_word selection we success to extract a satisfying quantity of data from the Quotebank data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
