{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6630819-7845-4bfb-b746-6a7e780e0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b3b89-46e1-4377-96ab-830501273244",
   "metadata": {},
   "source": [
    "# I- Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8fff96-1cf0-4d89-84d8-d2e0d780c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question : garder  le phase quand quotation ? index à retirer ? si oui :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2274bf8-bcfc-4df4-aba5-f737aa52cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_filtering(chunk, lst):\n",
    "    template=[] #creation of an empty list :it's always cheaper to append to a list and create a DataFrame than append on a empty dataframe.\n",
    "    for i in lst: \n",
    "        template.append(chunk.loc[chunk[\"quotation\"].apply(lambda x : i in x) & \n",
    "                                  chunk[\"speaker\"].apply(lambda x: x!= \"None\")].drop(['phase'], axis=1)#select the quotation with value in speaker column different from 'None' \n",
    "                                                                                #and quotations containing the key word\n",
    "        \n",
    "    return (pd.concat(template, ignore_index=True))# return a dataframe with our data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e047636-a586-4d61-b478-4278fd53e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reader = pd.read_json('data/quotes-2020.json.bz2', lines=True, compression='bz2', chunksize=1000)\n",
    "for i, chunk in enumerate(df_reader):\n",
    "        chunk_clean=chunk_filtering(chunk, key_word) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf=\"data/clean_quotes-2020.bz2\",compression='bz2',header=header, mode=mode, index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edcfe19-c424-4435-86bd-b0eb11096498",
   "metadata": {},
   "source": [
    "### Load Quotebank data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6264bc75-8b74-44f3-9e45-c079a54bea3b",
   "metadata": {},
   "source": [
    "First, let's recover the quotation of interest : as project is based on the caracterisation of the speaker, we decide to pre-select the quotations that are related to a speaker (i.e speaker value is different from 'None'). \n",
    "Moreover, we select the quotations whose subject is related to climate change : to do so we create a list of key word based on https://www.climaterealityproject.org/blog/key-terms-you-need-understand-climate-change and select quotes that contains at least one of these word.  (cf chunk_filtering method) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36cf40e0-63d6-4ca6-a98e-f167ebcc24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaration of a key_world list\n",
    "key_word = [\"carbon dioxide\", \"greenhouse gas\", \"global warming\",\n",
    "             \"climate change\",  \"fossil fuels\", \"sea-level rise\",\n",
    "             \"renewable energy\", \"CO2\",\"methane\",\"PPM\",\"COP\",\"GIEC\", \n",
    "             \"biofuels\",\"business as usual\", \"carbon footprint\", \"carbon neutral\", \"carbon sequestration\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b031381d-12de-49d0-beb2-11debbae3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_filtering(chunk, lst):\n",
    "    template=[] #creation of an empty list :it's always cheaper to append to a list and create a DataFrame than append on a empty dataframe.\n",
    "    for i in lst: \n",
    "        template.append(chunk.loc[chunk[\"quotation\"].apply(lambda x : i in x) & \n",
    "                                  chunk[\"speaker\"].apply(lambda x: x!= \"None\")].drop ()#select the quotation with value in speaker column different from 'None' \n",
    "                                                                                #and quotations containing the key word\n",
    "        \n",
    "    return (pd.concat(template, ignore_index=True))# return a dataframe with our data of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd22b34b-ce66-41f4-82ba-a234b2327cba",
   "metadata": {},
   "source": [
    "##### *2020 quotes extractions*\n",
    "The original dataset is of 792,3 Mo, so we decided to divide the dataset into chucks of 1000 rows and process each of them (by using the chunck_filtering). \n",
    "Then we load the process chunck into a new csv compressed bz2 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28d4a71f-a51d-4a0b-a5c8-3fd15c6fa15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe index = False ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54006733-37d4-49a3-b0b2-a72f200b825b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "with pd.read_json('data/quotes-2020.json.bz2', lines=True, compression='bz2', chunksize=1000) as df_reader : \n",
    "    for chunk in df_reader:\n",
    "        chunk_clean=chunk_filtering(chunk, key_word) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf=\"data/clean_quotes-2020.bz2\",compression='bz2',header=header, mode=mode)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9edd5dc6-4e47-4744-94cc-5d0428f06a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2020= pd.read_csv('data/clean_quotes-2020.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f4e2620-72c8-4778-8767-4d6f46facabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We extract 11091 quotes from the 2020 files\n"
     ]
    }
   ],
   "source": [
    "print( \" We extract {} quotes from the 2020 files\".format(len(quotes_2020)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae309716-2b59-4d84-8cac-259f2b256a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-24-013709</td>\n",
       "      <td>For every doubling of carbon dioxide concentra...</td>\n",
       "      <td>E. Calvin Beisner</td>\n",
       "      <td>['Q19877395']</td>\n",
       "      <td>2020-02-24 16:02:23</td>\n",
       "      <td>1</td>\n",
       "      <td>[['E. Calvin Beisner', '0.677'], ['None', '0.3...</td>\n",
       "      <td>['https://www.heartland.org/news-opinion/news/...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-24-028340</td>\n",
       "      <td>If you're a doctor that cares about the wellbe...</td>\n",
       "      <td>Fiona Stanley</td>\n",
       "      <td>['Q1653736']</td>\n",
       "      <td>2020-02-24 12:45:00</td>\n",
       "      <td>4</td>\n",
       "      <td>[['Fiona Stanley', '0.9473'], ['None', '0.0527']]</td>\n",
       "      <td>['http://watoday.com.au/business/banking-and-f...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-24-004182</td>\n",
       "      <td>Also, spoke about a range of emerging sectors ...</td>\n",
       "      <td>Piyush Goyal</td>\n",
       "      <td>['Q7199798']</td>\n",
       "      <td>2020-01-24 19:02:14</td>\n",
       "      <td>2</td>\n",
       "      <td>[['Piyush Goyal', '0.6385'], ['Peter Voser', '...</td>\n",
       "      <td>['http://aninews.in/news/world/europe/piyush-g...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-29-062975</td>\n",
       "      <td>Many make the link today between their experie...</td>\n",
       "      <td>Peter Maurer</td>\n",
       "      <td>['Q117796', 'Q42426597']</td>\n",
       "      <td>2020-01-29 09:04:36</td>\n",
       "      <td>5</td>\n",
       "      <td>[['Peter Maurer', '0.8787'], ['None', '0.1213']]</td>\n",
       "      <td>['http://whbl.com/news/articles/2020/jan/29/hu...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-10-076321</td>\n",
       "      <td>the National Energy and Climate Plans are how ...</td>\n",
       "      <td>Kadri Simson</td>\n",
       "      <td>['Q13570003']</td>\n",
       "      <td>2020-02-10 05:51:51</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Kadri Simson', '0.9269'], ['None', '0.0504'...</td>\n",
       "      <td>['https://www.politico.eu/newsletter/brussels-...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            quoteID  \\\n",
       "0           0  2020-02-24-013709   \n",
       "1           1  2020-02-24-028340   \n",
       "2           2  2020-01-24-004182   \n",
       "3           0  2020-01-29-062975   \n",
       "4           1  2020-02-10-076321   \n",
       "\n",
       "                                           quotation            speaker  \\\n",
       "0  For every doubling of carbon dioxide concentra...  E. Calvin Beisner   \n",
       "1  If you're a doctor that cares about the wellbe...      Fiona Stanley   \n",
       "2  Also, spoke about a range of emerging sectors ...       Piyush Goyal   \n",
       "3  Many make the link today between their experie...       Peter Maurer   \n",
       "4  the National Energy and Climate Plans are how ...       Kadri Simson   \n",
       "\n",
       "                       qids                 date  numOccurrences  \\\n",
       "0             ['Q19877395']  2020-02-24 16:02:23               1   \n",
       "1              ['Q1653736']  2020-02-24 12:45:00               4   \n",
       "2              ['Q7199798']  2020-01-24 19:02:14               2   \n",
       "3  ['Q117796', 'Q42426597']  2020-01-29 09:04:36               5   \n",
       "4             ['Q13570003']  2020-02-10 05:51:51               1   \n",
       "\n",
       "                                              probas  \\\n",
       "0  [['E. Calvin Beisner', '0.677'], ['None', '0.3...   \n",
       "1  [['Fiona Stanley', '0.9473'], ['None', '0.0527']]   \n",
       "2  [['Piyush Goyal', '0.6385'], ['Peter Voser', '...   \n",
       "3   [['Peter Maurer', '0.8787'], ['None', '0.1213']]   \n",
       "4  [['Kadri Simson', '0.9269'], ['None', '0.0504'...   \n",
       "\n",
       "                                                urls phase  \n",
       "0  ['https://www.heartland.org/news-opinion/news/...     E  \n",
       "1  ['http://watoday.com.au/business/banking-and-f...     E  \n",
       "2  ['http://aninews.in/news/world/europe/piyush-g...     E  \n",
       "3  ['http://whbl.com/news/articles/2020/jan/29/hu...     E  \n",
       "4  ['https://www.politico.eu/newsletter/brussels-...     E  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_2020.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea50135-f229-42c6-91ce-52b28ec43bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ae4e97a-4d31-4c3f-a9ce-0c710073745d",
   "metadata": {},
   "source": [
    "##### *2019 quotes extractions*\n",
    "The original dataset is of 3.32 Go, so we decided to divide the dataset into chucks of 1000 rows and process each of them (by using the chunck_filtering). Then we load the process chunck into a new csv compressed bz2 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d516035-0364-44b3-b0c0-89a39d738e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "with pd.read_json('data/quotes-2019.json.bz2', lines=True, compression='bz2', chunksize=1000) as df_reader:\n",
    "    for chunk in df_reader:\n",
    "        chunk_clean=chunk_filtering(chunk, key_word) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf='data/clean_quotes-2019.bz2', compression='bz2', mode = mode, header=header) # create a new csv files compress with bz2 containing all the dataframe recover from the chunk; \n",
    "        i+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4947d82f-97dd-4d82-95ed-cd580d10f6c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/clean_quotes-2019.bz2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dp/xm3y4vf11sd5mzn0yd618jhm0000gn/T/ipykernel_3385/1836899081.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquotes_2019\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/clean_quotes-2019.bz2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bz2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;31m# BZ Compression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bz2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             handle = bz2.BZ2File(\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;31m# Argument 1 to \"BZ2File\" has incompatible type \"Union[str,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                 \u001b[0;31m# Union[IO[Any], RawIOBase, BufferedIOBase, TextIOBase, TextIOWrapper,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.8/bz2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, buffering, compresslevel)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closefp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/clean_quotes-2019.bz2'"
     ]
    }
   ],
   "source": [
    "quotes_2019= pd.read_csv('data/clean_quotes-2019.bz2', compression='bz2') # load into the quotes_2019 df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93186176-a9be-4635-a87b-35816d8a7f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47280, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( \" We extracted {} quotes from the 2019 files\".format(len(quotes_2019)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e8ab3-00a4-4dc9-b89f-e3958ed2bc84",
   "metadata": {},
   "source": [
    "##### *2018 quotes extractions*\n",
    "The original dataset is of 4.48 Go, so we decided to divide the dataset into chucks of 1000 rows and process each of them ((by using the chunck_filtering). Then we load the process chunck into a new csv compressed bz2 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84914c33-8155-49ac-8d6a-d06d3f904e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "with pd.read_json('data/quotes-2018.json.bz2', lines=True, compression='bz2', chunksize=1000) as df_reader:\n",
    "    for chunk in df_reader:\n",
    "        \n",
    "        chunk_clean=chunk_filtering(chunk, key_word) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf='data/clean_quotes-2018.bz2', compression='bz2', mode = mode, header=header)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca002f8c-56f4-4940-b198-a214ce2951f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2018= pd.read_csv('data/clean_quotes-2018.bz2', compression='bz2') #load the data to quotes_2018 df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f4203a5-49de-42f8-9168-6e97ef3b2602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We extracted 35847 quotes from the 2018 files\n"
     ]
    }
   ],
   "source": [
    "print( \" We extracted {} quotes from the 2018 files\".format(len(quotes_2018)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8650499-8b64-4279-8cec-22c294b1f67c",
   "metadata": {},
   "source": [
    "##### *2017 quotes extractions*\n",
    "The original dataset is of 4.84 Go, so we decided to divide the dataset into chucks of 1000 rows and process each of them (by using the chunck_filtering). Then we load the process chunck into a new csv compressed bz2 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0c3dec8-5fa1-474c-9141-ea4e2fc85608",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "with pd.read_json('data/quotes-2017.json.bz2', lines=True, compression='bz2', chunksize=1000) as df_reader:\n",
    "    for chunk in df_reader:\n",
    "        chunk_clean=chunk_filtering(chunk, key_word) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf='data/clean_quotes-2017.bz2', compression='bz2', mode = 'a') # create a new csv files compress with bz2 containing all the dataframe recover from the chunk;\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fc42032-a525-4e90-9247-3a2e591aa26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2017= pd.read_csv('data/clean_quotes-2017.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c46c386-4866-431c-8fea-20707695e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We extracted 35324 quotes from the 2017 files\n"
     ]
    }
   ],
   "source": [
    "print( \" We extracted {} quotes from the 2017 files\".format(len(quotes_2017)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3274154-6ca0-4d95-a254-92ee85f4fd9a",
   "metadata": {},
   "source": [
    "##### *2016 quotes extractions*\n",
    "The original dataset is of 2.16 Go, so we decided to divide the dataset into chucks of 1000 rows and process each of them(by using the chunck_filtering). Then we load the process chunck into a new csv compressed bz2 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dec2729-c0b5-419a-be2a-e39df7639e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "with pd.read_json('data/quotes-2016.json.bz2', lines=True, compression='bz2', chunksize=1000) as df_reader:\n",
    "    for chunk in df_reader:\n",
    "        chunk_clean=chunk_filtering(chunk, key_word) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf='data/clean_quotes-2016.bz2', compression='bz2', mode = 'a') # create a new csv files compress with bz2 containing all the dataframe recover from the chunk;\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31fc23d3-9713-4206-a126-54882bc6fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2016= pd.read_csv('data/clean_quotes-2016.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "418d9ef6-3d36-42a4-a7ee-845d030cba7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We extracted 18344 quotes from the 2016 files\n"
     ]
    }
   ],
   "source": [
    "print( \" We extracted {} quotes from the 2016 files\".format(len(quotes_2016)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf4b6c0-579e-49e4-ae1f-8096fdbf0821",
   "metadata": {},
   "source": [
    "##### *2015 quotes extractions*\n",
    "The original dataset is of 3.11 Go, so we decided to divide the dataset into chucks of 1000 rows and process each of them(by using the chunck_filtering). Then we load the process chunck into a new csv compressed bz2 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8131f70-68ac-4126-a31d-f37d8944f444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13829, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "with pd.read_json('data/quotes-2015.json.bz2', lines=True, compression='bz2', chunksize=1000) as df_reader:\n",
    "    for chunk in df_reader:\n",
    "        chunk_clean=chunk_filtering(chunk, key_word) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf='data/clean_quotes-2015.bz2', compression='bz2', mode = 'a') # create a new csv files compress with bz2 containing all the dataframe recover from the chunk;\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba7620dc-490e-4311-b0cd-b188027133f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2015= pd.read_csv('data/clean_quotes-2015.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9150b06c-7c29-44e2-94e3-cecb975ac80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We extracted 35176 quotes from the 2015 files\n"
     ]
    }
   ],
   "source": [
    "print( \" We extracted {} quotes from the 2015 files\".format(len(quotes_2015)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "12781cd5-f83d-4297-b58a-1e06a212bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" At result, we extracted {} quotes fromes quotebank data\".format((len(quotes_2015)+len(quotes_2016)+len(quotes_2017)\n",
    "                                                                         +len(quotes_2018)+len(quotes_2019)+len(quotes_2020)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ebf7f-c01e-443b-980a-354e326d4b9c",
   "metadata": {},
   "source": [
    "Now that we extracted the interesting data from the Quotebank data, let's add another dataset that will give us characteristic information about the speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a6a56-c643-4f00-8e53-72611156d0f5",
   "metadata": {},
   "source": [
    "## Load additional data Relative to speakers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5adca85-ec46-4904-b3c5-0395e659767a",
   "metadata": {},
   "source": [
    "The provided speaker_attributes.parquet file contains attributes in terms of QIDs, thereby being uninterpretable by humans (df_qid).\n",
    "To map the QIDs to meaningful labels, we used the provied wikidata_labels_descriptions_quotebank.csv.bz2 containg the labels and value fo the respective QID containing the df_qid (df_label_qid)\n",
    "By combaning the information of both we can obtained usefule information about speakers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "280f0f07-1673-4e62-a70f-81296b7db81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qid = pd.read_parquet(\"speaker_attributes.parquet\",engine= \"pyarrow\" )\n",
    "df_label_qid = pd.read_csv('data/wikidata_labels_descriptions_quotebank.csv.bz2', compression='bz2', index_col='QID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2db133-e8c3-43aa-ae20-07ded9ad40a7",
   "metadata": {},
   "source": [
    "Before extract the label of qid, let's check which column we want to keep in frame with our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "34b98c8e-74a1-44c5-bc6e-395b22c4440b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aliases</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>lastrevid</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>US_congress_bio_ID</th>\n",
       "      <th>occupation</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>candidacy</th>\n",
       "      <th>type</th>\n",
       "      <th>religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Washington, President Washington, G. Washingt...</td>\n",
       "      <td>[+1732-02-22T00:00:00Z]</td>\n",
       "      <td>[Q161885, Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1395141751</td>\n",
       "      <td>None</td>\n",
       "      <td>W000178</td>\n",
       "      <td>[Q82955, Q189290, Q131512, Q1734662, Q294126, ...</td>\n",
       "      <td>[Q327591]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q23</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>[Q698073, Q697949]</td>\n",
       "      <td>item</td>\n",
       "      <td>[Q682443]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Douglas Noel Adams, Douglas Noël Adams, Dougl...</td>\n",
       "      <td>[+1952-03-11T00:00:00Z]</td>\n",
       "      <td>[Q145]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1395737157</td>\n",
       "      <td>[Q7994501]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q214917, Q28389, Q6625963, Q4853732, Q1884422...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q42</td>\n",
       "      <td>Douglas Adams</td>\n",
       "      <td>None</td>\n",
       "      <td>item</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Paul Marie Ghislain Otlet, Paul Marie Otlet]</td>\n",
       "      <td>[+1868-08-23T00:00:00Z]</td>\n",
       "      <td>[Q31]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1380367296</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q36180, Q40348, Q182436, Q1265807, Q205375, Q...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q1868</td>\n",
       "      <td>Paul Otlet</td>\n",
       "      <td>None</td>\n",
       "      <td>item</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             aliases            date_of_birth  \\\n",
       "0  [Washington, President Washington, G. Washingt...  [+1732-02-22T00:00:00Z]   \n",
       "1  [Douglas Noel Adams, Douglas Noël Adams, Dougl...  [+1952-03-11T00:00:00Z]   \n",
       "2      [Paul Marie Ghislain Otlet, Paul Marie Otlet]  [+1868-08-23T00:00:00Z]   \n",
       "\n",
       "      nationality      gender   lastrevid ethnic_group US_congress_bio_ID  \\\n",
       "0  [Q161885, Q30]  [Q6581097]  1395141751         None            W000178   \n",
       "1          [Q145]  [Q6581097]  1395737157   [Q7994501]               None   \n",
       "2           [Q31]  [Q6581097]  1380367296         None               None   \n",
       "\n",
       "                                          occupation      party  \\\n",
       "0  [Q82955, Q189290, Q131512, Q1734662, Q294126, ...  [Q327591]   \n",
       "1  [Q214917, Q28389, Q6625963, Q4853732, Q1884422...       None   \n",
       "2  [Q36180, Q40348, Q182436, Q1265807, Q205375, Q...       None   \n",
       "\n",
       "  academic_degree     id              label           candidacy  type  \\\n",
       "0            None    Q23  George Washington  [Q698073, Q697949]  item   \n",
       "1            None    Q42      Douglas Adams                None  item   \n",
       "2            None  Q1868         Paul Otlet                None  item   \n",
       "\n",
       "    religion  \n",
       "0  [Q682443]  \n",
       "1       None  \n",
       "2       None  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qid.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a524d4e3-29a4-49eb-b646-c6fc63e54220",
   "metadata": {},
   "source": [
    "Let's verify that academic_degree has revelant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "293730b9-06ea-4bfd-909e-ab8a7cb806a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's no academic degree revelant value ? False\n"
     ]
    }
   ],
   "source": [
    "print(\"There's no academic degree revelant value ? {}\".format(all(df_qid.academic_degree.isna())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573efeb6-dd9b-4121-8e10-d926f222795d",
   "metadata": {},
   "source": [
    "We decided to drop lastrevid, US_congress_bio_ID, type. Moreover, it's seems that academic_degree value are rare, let's check that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "677d65e5-50ff-480a-b5ae-6f7d18551117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aliases</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>occupation</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>candidacy</th>\n",
       "      <th>religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Washington, President Washington, G. Washingt...</td>\n",
       "      <td>[+1732-02-22T00:00:00Z]</td>\n",
       "      <td>[Q161885, Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q82955, Q189290, Q131512, Q1734662, Q294126, ...</td>\n",
       "      <td>[Q327591]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q23</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>[Q698073, Q697949]</td>\n",
       "      <td>[Q682443]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Douglas Noel Adams, Douglas Noël Adams, Dougl...</td>\n",
       "      <td>[+1952-03-11T00:00:00Z]</td>\n",
       "      <td>[Q145]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>[Q7994501]</td>\n",
       "      <td>[Q214917, Q28389, Q6625963, Q4853732, Q1884422...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q42</td>\n",
       "      <td>Douglas Adams</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Paul Marie Ghislain Otlet, Paul Marie Otlet]</td>\n",
       "      <td>[+1868-08-23T00:00:00Z]</td>\n",
       "      <td>[Q31]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q36180, Q40348, Q182436, Q1265807, Q205375, Q...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q1868</td>\n",
       "      <td>Paul Otlet</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[George Walker Bush, Bush Jr., Dubya, GWB, Bus...</td>\n",
       "      <td>[+1946-07-06T00:00:00Z]</td>\n",
       "      <td>[Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q82955, Q15982858, Q18814623, Q1028181, Q1408...</td>\n",
       "      <td>[Q29468]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q207</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>[Q327959, Q464075, Q3586276, Q4450587]</td>\n",
       "      <td>[Q329646, Q682443, Q33203]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Velázquez, Diego Rodríguez de Silva y Velázqu...</td>\n",
       "      <td>[+1599-06-06T00:00:00Z]</td>\n",
       "      <td>[Q29]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q1028181]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q297</td>\n",
       "      <td>Diego Velázquez</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9055976</th>\n",
       "      <td>[Barker Howard]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q82955]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q106406560</td>\n",
       "      <td>Barker B. Howard</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9055977</th>\n",
       "      <td>[Charles Macomber]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q82955]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q106406571</td>\n",
       "      <td>Charles H. Macomber</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9055978</th>\n",
       "      <td>None</td>\n",
       "      <td>[+1848-04-01T00:00:00Z]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q6581072]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q106406588</td>\n",
       "      <td>Dina David</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9055979</th>\n",
       "      <td>None</td>\n",
       "      <td>[+1899-03-18T00:00:00Z]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q6581072]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q106406593</td>\n",
       "      <td>Irma Dexinger</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9055980</th>\n",
       "      <td>[Fred Trull]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q82955]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q106406643</td>\n",
       "      <td>Fred F. Trull</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9055981 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   aliases  \\\n",
       "0        [Washington, President Washington, G. Washingt...   \n",
       "1        [Douglas Noel Adams, Douglas Noël Adams, Dougl...   \n",
       "2            [Paul Marie Ghislain Otlet, Paul Marie Otlet]   \n",
       "3        [George Walker Bush, Bush Jr., Dubya, GWB, Bus...   \n",
       "4        [Velázquez, Diego Rodríguez de Silva y Velázqu...   \n",
       "...                                                    ...   \n",
       "9055976                                    [Barker Howard]   \n",
       "9055977                                 [Charles Macomber]   \n",
       "9055978                                               None   \n",
       "9055979                                               None   \n",
       "9055980                                       [Fred Trull]   \n",
       "\n",
       "                   date_of_birth     nationality      gender ethnic_group  \\\n",
       "0        [+1732-02-22T00:00:00Z]  [Q161885, Q30]  [Q6581097]         None   \n",
       "1        [+1952-03-11T00:00:00Z]          [Q145]  [Q6581097]   [Q7994501]   \n",
       "2        [+1868-08-23T00:00:00Z]           [Q31]  [Q6581097]         None   \n",
       "3        [+1946-07-06T00:00:00Z]           [Q30]  [Q6581097]         None   \n",
       "4        [+1599-06-06T00:00:00Z]           [Q29]  [Q6581097]         None   \n",
       "...                          ...             ...         ...          ...   \n",
       "9055976                     None           [Q30]  [Q6581097]         None   \n",
       "9055977                     None           [Q30]  [Q6581097]         None   \n",
       "9055978  [+1848-04-01T00:00:00Z]            None  [Q6581072]         None   \n",
       "9055979  [+1899-03-18T00:00:00Z]            None  [Q6581072]         None   \n",
       "9055980                     None           [Q30]  [Q6581097]         None   \n",
       "\n",
       "                                                occupation      party  \\\n",
       "0        [Q82955, Q189290, Q131512, Q1734662, Q294126, ...  [Q327591]   \n",
       "1        [Q214917, Q28389, Q6625963, Q4853732, Q1884422...       None   \n",
       "2        [Q36180, Q40348, Q182436, Q1265807, Q205375, Q...       None   \n",
       "3        [Q82955, Q15982858, Q18814623, Q1028181, Q1408...   [Q29468]   \n",
       "4                                               [Q1028181]       None   \n",
       "...                                                    ...        ...   \n",
       "9055976                                           [Q82955]       None   \n",
       "9055977                                           [Q82955]       None   \n",
       "9055978                                               None       None   \n",
       "9055979                                               None       None   \n",
       "9055980                                           [Q82955]       None   \n",
       "\n",
       "        academic_degree          id                label  \\\n",
       "0                  None         Q23    George Washington   \n",
       "1                  None         Q42        Douglas Adams   \n",
       "2                  None       Q1868           Paul Otlet   \n",
       "3                  None        Q207       George W. Bush   \n",
       "4                  None        Q297      Diego Velázquez   \n",
       "...                 ...         ...                  ...   \n",
       "9055976            None  Q106406560     Barker B. Howard   \n",
       "9055977            None  Q106406571  Charles H. Macomber   \n",
       "9055978            None  Q106406588           Dina David   \n",
       "9055979            None  Q106406593        Irma Dexinger   \n",
       "9055980            None  Q106406643        Fred F. Trull   \n",
       "\n",
       "                                      candidacy                    religion  \n",
       "0                            [Q698073, Q697949]                   [Q682443]  \n",
       "1                                          None                        None  \n",
       "2                                          None                        None  \n",
       "3        [Q327959, Q464075, Q3586276, Q4450587]  [Q329646, Q682443, Q33203]  \n",
       "4                                          None                        None  \n",
       "...                                         ...                         ...  \n",
       "9055976                                    None                        None  \n",
       "9055977                                    None                        None  \n",
       "9055978                                    None                        None  \n",
       "9055979                                    None                        None  \n",
       "9055980                                    None                        None  \n",
       "\n",
       "[9055981 rows x 12 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qid.drop(['lastrevid', 'US_congress_bio_ID', 'type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d2fb167-abb0-48cb-83fd-e9a514e60b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q31</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>country in western Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q45</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>country in southwestern Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q75</th>\n",
       "      <td>Internet</td>\n",
       "      <td>global system of connected computer networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q148</th>\n",
       "      <td>People's Republic of China</td>\n",
       "      <td>sovereign state in East Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q155</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>country in South America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Label                                   Description\n",
       "QID                                                                           \n",
       "Q31                      Belgium                     country in western Europe\n",
       "Q45                     Portugal                country in southwestern Europe\n",
       "Q75                     Internet  global system of connected computer networks\n",
       "Q148  People's Republic of China                  sovereign state in East Asia\n",
       "Q155                      Brazil                      country in South America"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_qid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6b7ee1f-81ec-4b1d-b038-7e89c44d3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We found out that some of the QIDs used in the speaker attribute file are actually redirection from an original QID. \n",
    "#We will manulally add their corresponding information using the orginal QID. We found the corespondance manualy between the two. \n",
    "#Here, there are in order, respectively the redirection QID, and its corresponding original one. One of he QID was only present \n",
    "#as a redirection, so we manually added this one (Q3186984), and its corresponding info. \n",
    "\n",
    "redirect_QID=['Q3268166', 'Q11815360', 'Q12014399', 'Q16287483',\n",
    "              'Q20432251', 'Q21550646', 'Q13365117', 'Q13424794',\n",
    "             'Q1248362', 'Q6859927', 'Q15145782',\n",
    "             'Q15991263', 'Q12455619', 'Q5568256', \n",
    "             'Q6363085', 'Q11819457', 'Q12334852', 'Q15145783']\n",
    "actual_QID=['Q1113899', 'Q1919436', 'Q250867', 'Q6051619',\n",
    "             'Q26934816', 'Q18431816', 'Q12840545', 'Q5157338',\n",
    "            'Q3455803', 'Q715222', 'Q1052281',\n",
    "            'Q2743689', 'Q7019111', 'Q3738699', \n",
    "            'Q380075', 'Q3391743', 'Q476246', 'Q2449503']\n",
    "\n",
    "#There is a QID that was deleted from Wikidata, Q99753484, so we will remove this QID later \n",
    "\n",
    "lst=[['Journalist', 'monthly magazine of the United Kingdom‘s National Union of Journalists (NUJ)']]\n",
    "indexes=['Q3186984']\n",
    "col=['Label', 'Description']\n",
    "for i in range(len(redirect_QID)):\n",
    "    lst.append([df_label_qid.loc[actual_QID[i]]['Label'], \n",
    "                df_label_qid.loc[actual_QID[i]]['Description']])\n",
    "    indexes.append(redirect_QID[i])\n",
    "\n",
    "additional_df= pd.DataFrame(lst, columns= col, index=indexes)\n",
    "df_label_qid_co=df_label_qid.append(additional_df, ignore_index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17875fab-7cbe-44b9-b911-2c7298b827e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that loops through a column to replace QID with their label, and skip None values. We will deal with them later, \n",
    "#when we will use the different data.\n",
    "def l(df) : \n",
    "    liste=[]\n",
    "    for row  in df: \n",
    "        if row is None: \n",
    "            continue #skip None values\n",
    "        template=[]\n",
    "        for value in row: #iterating over the values of a cell, as there are multiple QIDs in some of them.\n",
    "            if value == 'Q99753484': #To filter the deleted QID\n",
    "                continue\n",
    "            template.append(df_label_qid_co.loc[value]['Label']) #Map the QID to its corresponding label. \n",
    "        liste.append(template)\n",
    "    return pd.Series(liste)\n",
    "#Applying the function to every column containing QIDs. \n",
    "df_qid [['nationality', 'gender', 'ethnic_group','occupation', 'party', 'academic_degree', 'candidacy', 'religion']] = df_qid[['nationality', 'gender', 'ethnic_group','occupation', 'party', 'academic_degree', 'candidacy', 'religion']].apply(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8a1db0-542d-4b9f-a27b-c780e2a03267",
   "metadata": {},
   "source": [
    "# II- Filter the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1547a11-c37a-42a7-bc86-8abc812ef6e7",
   "metadata": {},
   "source": [
    "As a good data scientist, the first thing to do is to clean up the data : we need to filtered missing and duplicates rows if there are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534141a-105f-48ba-9e87-daa98425ca57",
   "metadata": {},
   "source": [
    "*check for missing row*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a824dab5-3740-49b3-b29e-0f0b401546a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there some missing rows ? False \n"
     ]
    }
   ],
   "source": [
    "print(\"Is there some missing rows ? {} \".format(np.array([quotes_2020.isnull().any(axis=1)]).all()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751443c-4cb1-4ee9-9866-aaee5fde6d4c",
   "metadata": {},
   "source": [
    "##### *check for duplicate*\n",
    "\n",
    "We define a function that receive a dataframe (quotes_2020 ... quotes_2015) and remove their duplicates rows according to duplicate quotation;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28e24b9c-41ef-4760-b305-4def17cb6faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates (df): \n",
    "    \n",
    "    if df[\"quotation\"].is_unique == False : \n",
    "        df.drop_duplicates(['quotation'], keep='first', inplace=True) #remove the duplicate rows directly on the df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b75326db-260f-4ffa-ac6f-abcf76c54eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We still get 10486 quotes from the 2020 dataset\n"
     ]
    }
   ],
   "source": [
    "check_duplicates(quotes_2020)\n",
    "check_duplicates(quotes_2019)\n",
    "check_duplicates(quotes_2018)\n",
    "check_duplicates(quotes_2017)\n",
    "check_duplicates(quotes_2016)\n",
    "check_duplicates(quotes_2017)\n",
    "check_duplicates(quotes_2015)\n",
    "print( \"We still get {} quotes from the 2020 dataset\".format(len(quotes_2020)))\n",
    "print( \"We still get {} quotes from the 2020 dataset\".format(len(quotes_2019)))\n",
    "print( \"We still get {} quotes from the 2020 dataset\".format(len(quotes_2018)))\n",
    "print( \"We still get {} quotes from the 2020 dataset\".format(len(quotes_2017)))\n",
    "print( \"We still get {} quotes from the 2020 dataset\".format(len(quotes_2016)))\n",
    "print( \"We still get {} quotes from the 2020 dataset\".format(len(quotes_2015)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a57f9-a272-442e-8ed4-90f744832cfb",
   "metadata": {},
   "source": [
    "### Merge quotebank extracted data and caracteristics of the speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4d753065-e3b6-4d26-be5f-e9a87b870fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7a85b60a-0362-42a1-b04e-5d6de53f2e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "      <th>...</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>occupation</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>candidacy</th>\n",
       "      <th>religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-24-013709</td>\n",
       "      <td>For every doubling of carbon dioxide concentra...</td>\n",
       "      <td>E. Calvin Beisner</td>\n",
       "      <td>['Q19877395']</td>\n",
       "      <td>2020-02-24 16:02:23</td>\n",
       "      <td>1</td>\n",
       "      <td>[['E. Calvin Beisner', '0.677'], ['None', '0.3...</td>\n",
       "      <td>['https://www.heartland.org/news-opinion/news/...</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>[Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q1607826]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q19877395</td>\n",
       "      <td>E. Calvin Beisner</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-24-010293</td>\n",
       "      <td>Crops also improve their fruit-to-fiber ratio ...</td>\n",
       "      <td>E. Calvin Beisner</td>\n",
       "      <td>['Q19877395']</td>\n",
       "      <td>2020-02-24 16:02:23</td>\n",
       "      <td>1</td>\n",
       "      <td>[['E. Calvin Beisner', '0.7538'], ['None', '0....</td>\n",
       "      <td>['https://www.heartland.org/news-opinion/news/...</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>[Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q1607826]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q19877395</td>\n",
       "      <td>E. Calvin Beisner</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-24-028340</td>\n",
       "      <td>If you're a doctor that cares about the wellbe...</td>\n",
       "      <td>Fiona Stanley</td>\n",
       "      <td>['Q1653736']</td>\n",
       "      <td>2020-02-24 12:45:00</td>\n",
       "      <td>4</td>\n",
       "      <td>[['Fiona Stanley', '0.9473'], ['None', '0.0527']]</td>\n",
       "      <td>['http://watoday.com.au/business/banking-and-f...</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>[Q408]</td>\n",
       "      <td>[Q6581072]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q13416803]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q1653736</td>\n",
       "      <td>Fiona Stanley</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q6423963]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-24-004182</td>\n",
       "      <td>Also, spoke about a range of emerging sectors ...</td>\n",
       "      <td>Piyush Goyal</td>\n",
       "      <td>['Q7199798']</td>\n",
       "      <td>2020-01-24 19:02:14</td>\n",
       "      <td>2</td>\n",
       "      <td>[['Piyush Goyal', '0.6385'], ['Peter Voser', '...</td>\n",
       "      <td>['http://aninews.in/news/world/europe/piyush-g...</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>[Q668]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q82955]</td>\n",
       "      <td>[Q10230]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q7199798</td>\n",
       "      <td>Piyush Goyal</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q9089]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-21-092711</td>\n",
       "      <td>We are like a pivot for the Indian Ocean and w...</td>\n",
       "      <td>Piyush Goyal</td>\n",
       "      <td>['Q7199798']</td>\n",
       "      <td>2020-01-21 13:07:20</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Piyush Goyal', '0.9241'], ['None', '0.0759']]</td>\n",
       "      <td>['https://www.newindianexpress.com/world/2020/...</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>[Q668]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q82955]</td>\n",
       "      <td>[Q10230]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q7199798</td>\n",
       "      <td>Piyush Goyal</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q9089]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46645</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-21-082953</td>\n",
       "      <td>Where these sorts of things can be very useful...</td>\n",
       "      <td>David Farrell</td>\n",
       "      <td>['Q18921713', 'Q21931971', 'Q46829026', 'Q5233...</td>\n",
       "      <td>2020-02-21 21:38:09</td>\n",
       "      <td>1</td>\n",
       "      <td>[['David Farrell', '0.8397'], ['None', '0.1603']]</td>\n",
       "      <td>['https://inews.co.uk/news/environment/climate...</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>[Q27, Q145]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q1238570]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q18921713</td>\n",
       "      <td>David Farrell</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46646</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-07-040598</td>\n",
       "      <td>It will simulate adverse weather conditions; i...</td>\n",
       "      <td>Satoshi Matsuoka</td>\n",
       "      <td>['Q11530057']</td>\n",
       "      <td>2020-01-07 13:03:19</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Satoshi Matsuoka', '0.8561'], ['None', '0.1...</td>\n",
       "      <td>['http://www.sciencebusiness.net/international...</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q1650915]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q89726452</td>\n",
       "      <td>Satoshi Matsuoka</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46647</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-07-040598</td>\n",
       "      <td>It will simulate adverse weather conditions; i...</td>\n",
       "      <td>Satoshi Matsuoka</td>\n",
       "      <td>['Q11530057']</td>\n",
       "      <td>2020-01-07 13:03:19</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Satoshi Matsuoka', '0.8561'], ['None', '0.1...</td>\n",
       "      <td>['http://www.sciencebusiness.net/international...</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q82594]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q11530057</td>\n",
       "      <td>Satoshi Matsuoka</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46648</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-07-040598</td>\n",
       "      <td>It will simulate adverse weather conditions; i...</td>\n",
       "      <td>Satoshi Matsuoka</td>\n",
       "      <td>['Q11530057']</td>\n",
       "      <td>2020-01-07 13:03:19</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Satoshi Matsuoka', '0.8561'], ['None', '0.1...</td>\n",
       "      <td>['http://www.sciencebusiness.net/international...</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q1650915]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q99365468</td>\n",
       "      <td>Satoshi Matsuoka</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46649</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-02-06-089077</td>\n",
       "      <td>The expected increase in severe weather due to...</td>\n",
       "      <td>Deb Gardner</td>\n",
       "      <td>['Q5247771']</td>\n",
       "      <td>2020-02-06 22:38:10</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Deb Gardner', '0.7816'], ['None', '0.1879']...</td>\n",
       "      <td>['https://www.eptrail.com/2020/02/06/congressm...</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>[Q30]</td>\n",
       "      <td>[Q6581072]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q82955]</td>\n",
       "      <td>[Q29552]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q5247771</td>\n",
       "      <td>Deb Gardner</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46650 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0            quoteID  \\\n",
       "0               0  2020-02-24-013709   \n",
       "1               0  2020-02-24-010293   \n",
       "2               1  2020-02-24-028340   \n",
       "3               2  2020-01-24-004182   \n",
       "4               0  2020-01-21-092711   \n",
       "...           ...                ...   \n",
       "46645           1  2020-02-21-082953   \n",
       "46646           0  2020-01-07-040598   \n",
       "46647           0  2020-01-07-040598   \n",
       "46648           0  2020-01-07-040598   \n",
       "46649           4  2020-02-06-089077   \n",
       "\n",
       "                                               quotation            speaker  \\\n",
       "0      For every doubling of carbon dioxide concentra...  E. Calvin Beisner   \n",
       "1      Crops also improve their fruit-to-fiber ratio ...  E. Calvin Beisner   \n",
       "2      If you're a doctor that cares about the wellbe...      Fiona Stanley   \n",
       "3      Also, spoke about a range of emerging sectors ...       Piyush Goyal   \n",
       "4      We are like a pivot for the Indian Ocean and w...       Piyush Goyal   \n",
       "...                                                  ...                ...   \n",
       "46645  Where these sorts of things can be very useful...      David Farrell   \n",
       "46646  It will simulate adverse weather conditions; i...   Satoshi Matsuoka   \n",
       "46647  It will simulate adverse weather conditions; i...   Satoshi Matsuoka   \n",
       "46648  It will simulate adverse weather conditions; i...   Satoshi Matsuoka   \n",
       "46649  The expected increase in severe weather due to...        Deb Gardner   \n",
       "\n",
       "                                                    qids                 date  \\\n",
       "0                                          ['Q19877395']  2020-02-24 16:02:23   \n",
       "1                                          ['Q19877395']  2020-02-24 16:02:23   \n",
       "2                                           ['Q1653736']  2020-02-24 12:45:00   \n",
       "3                                           ['Q7199798']  2020-01-24 19:02:14   \n",
       "4                                           ['Q7199798']  2020-01-21 13:07:20   \n",
       "...                                                  ...                  ...   \n",
       "46645  ['Q18921713', 'Q21931971', 'Q46829026', 'Q5233...  2020-02-21 21:38:09   \n",
       "46646                                      ['Q11530057']  2020-01-07 13:03:19   \n",
       "46647                                      ['Q11530057']  2020-01-07 13:03:19   \n",
       "46648                                      ['Q11530057']  2020-01-07 13:03:19   \n",
       "46649                                       ['Q5247771']  2020-02-06 22:38:10   \n",
       "\n",
       "       numOccurrences                                             probas  \\\n",
       "0                   1  [['E. Calvin Beisner', '0.677'], ['None', '0.3...   \n",
       "1                   1  [['E. Calvin Beisner', '0.7538'], ['None', '0....   \n",
       "2                   4  [['Fiona Stanley', '0.9473'], ['None', '0.0527']]   \n",
       "3                   2  [['Piyush Goyal', '0.6385'], ['Peter Voser', '...   \n",
       "4                   1   [['Piyush Goyal', '0.9241'], ['None', '0.0759']]   \n",
       "...               ...                                                ...   \n",
       "46645               1  [['David Farrell', '0.8397'], ['None', '0.1603']]   \n",
       "46646               1  [['Satoshi Matsuoka', '0.8561'], ['None', '0.1...   \n",
       "46647               1  [['Satoshi Matsuoka', '0.8561'], ['None', '0.1...   \n",
       "46648               1  [['Satoshi Matsuoka', '0.8561'], ['None', '0.1...   \n",
       "46649               1  [['Deb Gardner', '0.7816'], ['None', '0.1879']...   \n",
       "\n",
       "                                                    urls phase  ...  \\\n",
       "0      ['https://www.heartland.org/news-opinion/news/...     E  ...   \n",
       "1      ['https://www.heartland.org/news-opinion/news/...     E  ...   \n",
       "2      ['http://watoday.com.au/business/banking-and-f...     E  ...   \n",
       "3      ['http://aninews.in/news/world/europe/piyush-g...     E  ...   \n",
       "4      ['https://www.newindianexpress.com/world/2020/...     E  ...   \n",
       "...                                                  ...   ...  ...   \n",
       "46645  ['https://inews.co.uk/news/environment/climate...     E  ...   \n",
       "46646  ['http://www.sciencebusiness.net/international...     E  ...   \n",
       "46647  ['http://www.sciencebusiness.net/international...     E  ...   \n",
       "46648  ['http://www.sciencebusiness.net/international...     E  ...   \n",
       "46649  ['https://www.eptrail.com/2020/02/06/congressm...     E  ...   \n",
       "\n",
       "       nationality      gender ethnic_group   occupation     party  \\\n",
       "0            [Q30]  [Q6581097]         None   [Q1607826]      None   \n",
       "1            [Q30]  [Q6581097]         None   [Q1607826]      None   \n",
       "2           [Q408]  [Q6581072]         None  [Q13416803]      None   \n",
       "3           [Q668]  [Q6581097]         None     [Q82955]  [Q10230]   \n",
       "4           [Q668]  [Q6581097]         None     [Q82955]  [Q10230]   \n",
       "...            ...         ...          ...          ...       ...   \n",
       "46645  [Q27, Q145]  [Q6581097]         None   [Q1238570]      None   \n",
       "46646         None        None         None   [Q1650915]      None   \n",
       "46647         None  [Q6581097]         None     [Q82594]      None   \n",
       "46648         None        None         None   [Q1650915]      None   \n",
       "46649        [Q30]  [Q6581072]         None     [Q82955]  [Q29552]   \n",
       "\n",
       "      academic_degree         id              label candidacy    religion  \n",
       "0                None  Q19877395  E. Calvin Beisner      None        None  \n",
       "1                None  Q19877395  E. Calvin Beisner      None        None  \n",
       "2                None   Q1653736      Fiona Stanley      None  [Q6423963]  \n",
       "3                None   Q7199798       Piyush Goyal      None     [Q9089]  \n",
       "4                None   Q7199798       Piyush Goyal      None     [Q9089]  \n",
       "...               ...        ...                ...       ...         ...  \n",
       "46645            None  Q18921713      David Farrell      None        None  \n",
       "46646            None  Q89726452   Satoshi Matsuoka      None        None  \n",
       "46647            None  Q11530057   Satoshi Matsuoka      None        None  \n",
       "46648            None  Q99365468   Satoshi Matsuoka      None        None  \n",
       "46649            None   Q5247771        Deb Gardner      None        None  \n",
       "\n",
       "[46650 rows x 22 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_2020.merge(df_qid, left_on = 'speaker' ,right_on = 'label' , how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a8f58c-5c08-44d5-81fc-151fdec345a0",
   "metadata": {},
   "source": [
    "## I-Exploration of our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5271ef-c0c5-480c-adb8-f79a0d822615",
   "metadata": {},
   "source": [
    "Let's see some distribution and statitics: \n",
    " - aged people vs yound people \n",
    " - party politics  \n",
    "ect... \n",
    "\n",
    "stat : correlation coeff ; m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5756638-5cba-49a1-82a2-9c06b7363eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
