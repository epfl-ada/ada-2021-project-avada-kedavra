{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6630819-7845-4bfb-b746-6a7e780e0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import sqlite3\n",
    "import string\n",
    "\n",
    "#load the statistical libraries\n",
    "from statsmodels.stats import diagnostic\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1981b18-a20b-4b10-b585-0b15563a9d26",
   "metadata": {},
   "source": [
    "# General information Remark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9c90b-4fd4-4d09-8163-7c2b7021c9b3",
   "metadata": {},
   "source": [
    "### In the loading part we will recover data from 2015 to 2020, however, first visulation (part III) will only be on the data from 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b3b89-46e1-4377-96ab-830501273244",
   "metadata": {},
   "source": [
    "# I- Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edcfe19-c424-4435-86bd-b0eb11096498",
   "metadata": {},
   "source": [
    "### Load Quotebank data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6264bc75-8b74-44f3-9e45-c079a54bea3b",
   "metadata": {},
   "source": [
    "First, let's recover the quotation of interest : as project is based on the caracterisation of the speaker, we decide to pre-select the quotations that are related to a speaker (i.e speaker value is different from 'None'). \n",
    "Moreover, we select the quotations whose subject is related to climate change : to do so we create a list of key word based on https://www.climaterealityproject.org/blog/key-terms-you-need-understand-climate-change and select quotes that contains at least one of these word.  (cf chunk_filtering method) . We are aware that this methode incude biais,and we thought to later utlise NPL in order to filter quotation related to climate from other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab1771f-d38f-4add-a80e-769218de77d9",
   "metadata": {},
   "source": [
    "> ##### A/ Select data representative for climate interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36cf40e0-63d6-4ca6-a98e-f167ebcc24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaration of a key_world list\n",
    "key_word = [\"carbon dioxide\", \"greenhouse gas\", \"global warming\",\n",
    "             \"climate change\",  \"fossil fuels\", \"sea-level rise\",\n",
    "             \"renewable energy\", \"CO2\",\"methane\",\"PPM\",\"COP\",\"GIEC\", \n",
    "             \"biofuels\",\"business as usual\", \"carbon footprint\", \"carbon neutral\", \"carbon sequestration\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b031381d-12de-49d0-beb2-11debbae3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_filtering(chunk, lst):\n",
    "    template=[] #creation of an empty list :it's always cheaper to append to a list and create a DataFrame than append on a empty dataframe.\n",
    "    for i in lst: \n",
    "        template.append(chunk.loc[chunk[\"quotation\"].apply(lambda x : i in x) & \n",
    "                                  chunk[\"speaker\"].apply(lambda x: x!= \"None\")&chunk[\"qids\"].apply(lambda x: len(np.array(x))==1)].drop(['phase'], axis=1))#select the quotation with value in speaker column different from 'None' \n",
    "                                                                                #and quotations containing the key word and drop Phase column\n",
    "        \n",
    "    return (pd.concat(template, ignore_index=True))# return a dataframe with our data of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd22b34b-ce66-41f4-82ba-a234b2327cba",
   "metadata": {},
   "source": [
    "##### *2020 quotes extractions*\n",
    " > The original dataset is of 792,3 Mo, so we decided to divide the dataset into chucks of 1000 rows and process each of them (by using the chunck_filtering). \n",
    "Then we load the process chunck into a new csv compressed bz2 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28d4a71f-a51d-4a0b-a5c8-3fd15c6fa15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reader = pd.read_json('data/quotes-2020.json.bz2', lines=True, compression='bz2', chunksize=1000)\n",
    "for i, chunk in enumerate(df_reader):\n",
    "        chunk_clean=chunk_filtering(chunk, key_word) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf=\"data/clean_quotes-2020.bz2\",compression='bz2',header=header, mode=mode, index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9edd5dc6-4e47-4744-94cc-5d0428f06a49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-24-013709</td>\n",
       "      <td>For every doubling of carbon dioxide concentra...</td>\n",
       "      <td>E. Calvin Beisner</td>\n",
       "      <td>['Q19877395']</td>\n",
       "      <td>2020-02-24 16:02:23</td>\n",
       "      <td>1</td>\n",
       "      <td>[['E. Calvin Beisner', '0.677'], ['None', '0.3...</td>\n",
       "      <td>['https://www.heartland.org/news-opinion/news/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-24-028340</td>\n",
       "      <td>If you're a doctor that cares about the wellbe...</td>\n",
       "      <td>Fiona Stanley</td>\n",
       "      <td>['Q1653736']</td>\n",
       "      <td>2020-02-24 12:45:00</td>\n",
       "      <td>4</td>\n",
       "      <td>[['Fiona Stanley', '0.9473'], ['None', '0.0527']]</td>\n",
       "      <td>['http://watoday.com.au/business/banking-and-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-24-004182</td>\n",
       "      <td>Also, spoke about a range of emerging sectors ...</td>\n",
       "      <td>Piyush Goyal</td>\n",
       "      <td>['Q7199798']</td>\n",
       "      <td>2020-01-24 19:02:14</td>\n",
       "      <td>2</td>\n",
       "      <td>[['Piyush Goyal', '0.6385'], ['Peter Voser', '...</td>\n",
       "      <td>['http://aninews.in/news/world/europe/piyush-g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-10-076321</td>\n",
       "      <td>the National Energy and Climate Plans are how ...</td>\n",
       "      <td>Kadri Simson</td>\n",
       "      <td>['Q13570003']</td>\n",
       "      <td>2020-02-10 05:51:51</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Kadri Simson', '0.9269'], ['None', '0.0504'...</td>\n",
       "      <td>['https://www.politico.eu/newsletter/brussels-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-24-110153</td>\n",
       "      <td>When we're talking about... trying to promote ...</td>\n",
       "      <td>Stephen Poloz</td>\n",
       "      <td>['Q15127111']</td>\n",
       "      <td>2020-01-24 01:50:08</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Stephen Poloz', '0.5145'], ['None', '0.4855']]</td>\n",
       "      <td>['http://thestar.com/politics/federal/2020/01/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>2020-01-22-057467</td>\n",
       "      <td>Last year Formula 1 launched its first-ever su...</td>\n",
       "      <td>Chase Carey</td>\n",
       "      <td>['Q5087105']</td>\n",
       "      <td>2020-01-22 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>[['Chase Carey', '0.7369'], ['Jean Todt', '0.1...</td>\n",
       "      <td>['http://formula1.com/en/latest/article.formul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7756</th>\n",
       "      <td>2020-02-05-114487</td>\n",
       "      <td>We will be an energetic champion of free trade...</td>\n",
       "      <td>Dominic Raab</td>\n",
       "      <td>['Q268584']</td>\n",
       "      <td>2020-02-05 16:30:31</td>\n",
       "      <td>2</td>\n",
       "      <td>[['Dominic Raab', '0.8813'], ['None', '0.0998'...</td>\n",
       "      <td>['http://forbesadvocate.com.au/story/6616761/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7757</th>\n",
       "      <td>2020-02-10-057505</td>\n",
       "      <td>Obama got health care, Trump got his tax cut, ...</td>\n",
       "      <td>Tom Steyer</td>\n",
       "      <td>['Q16189531']</td>\n",
       "      <td>2020-02-10 11:00:08</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Tom Steyer', '0.8143'], ['None', '0.1857']]</td>\n",
       "      <td>['https://thebulletin.org/2020/02/on-the-new-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7758</th>\n",
       "      <td>2020-02-19-061285</td>\n",
       "      <td>Our colleagues will also continue to work toge...</td>\n",
       "      <td>Markus Dohle</td>\n",
       "      <td>['Q1901431']</td>\n",
       "      <td>2020-02-19 08:37:21</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Markus Dohle', '0.7837'], ['None', '0.2163']]</td>\n",
       "      <td>['http://thebookseller.com/news/dohle-prh-well...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7759</th>\n",
       "      <td>2020-02-23-041538</td>\n",
       "      <td>We've been writing about climate change being ...</td>\n",
       "      <td>Lesley Hughes</td>\n",
       "      <td>['Q53473786']</td>\n",
       "      <td>2020-02-23 22:38:42</td>\n",
       "      <td>2</td>\n",
       "      <td>[['Lesley Hughes', '0.9023'], ['None', '0.0978']]</td>\n",
       "      <td>['https://www.nytimes.com/2020/02/23/world/aus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7760 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                quoteID                                          quotation  \\\n",
       "0     2020-02-24-013709  For every doubling of carbon dioxide concentra...   \n",
       "1     2020-02-24-028340  If you're a doctor that cares about the wellbe...   \n",
       "2     2020-01-24-004182  Also, spoke about a range of emerging sectors ...   \n",
       "3     2020-02-10-076321  the National Energy and Climate Plans are how ...   \n",
       "4     2020-01-24-110153  When we're talking about... trying to promote ...   \n",
       "...                 ...                                                ...   \n",
       "7755  2020-01-22-057467  Last year Formula 1 launched its first-ever su...   \n",
       "7756  2020-02-05-114487  We will be an energetic champion of free trade...   \n",
       "7757  2020-02-10-057505  Obama got health care, Trump got his tax cut, ...   \n",
       "7758  2020-02-19-061285  Our colleagues will also continue to work toge...   \n",
       "7759  2020-02-23-041538  We've been writing about climate change being ...   \n",
       "\n",
       "                speaker           qids                 date  numOccurrences  \\\n",
       "0     E. Calvin Beisner  ['Q19877395']  2020-02-24 16:02:23               1   \n",
       "1         Fiona Stanley   ['Q1653736']  2020-02-24 12:45:00               4   \n",
       "2          Piyush Goyal   ['Q7199798']  2020-01-24 19:02:14               2   \n",
       "3          Kadri Simson  ['Q13570003']  2020-02-10 05:51:51               1   \n",
       "4         Stephen Poloz  ['Q15127111']  2020-01-24 01:50:08               1   \n",
       "...                 ...            ...                  ...             ...   \n",
       "7755        Chase Carey   ['Q5087105']  2020-01-22 00:00:00               3   \n",
       "7756       Dominic Raab    ['Q268584']  2020-02-05 16:30:31               2   \n",
       "7757         Tom Steyer  ['Q16189531']  2020-02-10 11:00:08               1   \n",
       "7758       Markus Dohle   ['Q1901431']  2020-02-19 08:37:21               1   \n",
       "7759      Lesley Hughes  ['Q53473786']  2020-02-23 22:38:42               2   \n",
       "\n",
       "                                                 probas  \\\n",
       "0     [['E. Calvin Beisner', '0.677'], ['None', '0.3...   \n",
       "1     [['Fiona Stanley', '0.9473'], ['None', '0.0527']]   \n",
       "2     [['Piyush Goyal', '0.6385'], ['Peter Voser', '...   \n",
       "3     [['Kadri Simson', '0.9269'], ['None', '0.0504'...   \n",
       "4     [['Stephen Poloz', '0.5145'], ['None', '0.4855']]   \n",
       "...                                                 ...   \n",
       "7755  [['Chase Carey', '0.7369'], ['Jean Todt', '0.1...   \n",
       "7756  [['Dominic Raab', '0.8813'], ['None', '0.0998'...   \n",
       "7757     [['Tom Steyer', '0.8143'], ['None', '0.1857']]   \n",
       "7758   [['Markus Dohle', '0.7837'], ['None', '0.2163']]   \n",
       "7759  [['Lesley Hughes', '0.9023'], ['None', '0.0978']]   \n",
       "\n",
       "                                                   urls  \n",
       "0     ['https://www.heartland.org/news-opinion/news/...  \n",
       "1     ['http://watoday.com.au/business/banking-and-f...  \n",
       "2     ['http://aninews.in/news/world/europe/piyush-g...  \n",
       "3     ['https://www.politico.eu/newsletter/brussels-...  \n",
       "4     ['http://thestar.com/politics/federal/2020/01/...  \n",
       "...                                                 ...  \n",
       "7755  ['http://formula1.com/en/latest/article.formul...  \n",
       "7756  ['http://forbesadvocate.com.au/story/6616761/a...  \n",
       "7757  ['https://thebulletin.org/2020/02/on-the-new-h...  \n",
       "7758  ['http://thebookseller.com/news/dohle-prh-well...  \n",
       "7759  ['https://www.nytimes.com/2020/02/23/world/aus...  \n",
       "\n",
       "[7760 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_2020= pd.read_csv('data/clean_quotes-2020.bz2', compression='bz2')\n",
    "quotes_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51dae993-3c81-4cf4-9cc4-d2b9b2b11b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-24-013709</td>\n",
       "      <td>For every doubling of carbon dioxide concentra...</td>\n",
       "      <td>E. Calvin Beisner</td>\n",
       "      <td>['Q19877395']</td>\n",
       "      <td>2020-02-24 16:02:23</td>\n",
       "      <td>1</td>\n",
       "      <td>[['E. Calvin Beisner', '0.677'], ['None', '0.3...</td>\n",
       "      <td>['https://www.heartland.org/news-opinion/news/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-24-028340</td>\n",
       "      <td>If you're a doctor that cares about the wellbe...</td>\n",
       "      <td>Fiona Stanley</td>\n",
       "      <td>['Q1653736']</td>\n",
       "      <td>2020-02-24 12:45:00</td>\n",
       "      <td>4</td>\n",
       "      <td>[['Fiona Stanley', '0.9473'], ['None', '0.0527']]</td>\n",
       "      <td>['http://watoday.com.au/business/banking-and-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-24-004182</td>\n",
       "      <td>Also, spoke about a range of emerging sectors ...</td>\n",
       "      <td>Piyush Goyal</td>\n",
       "      <td>['Q7199798']</td>\n",
       "      <td>2020-01-24 19:02:14</td>\n",
       "      <td>2</td>\n",
       "      <td>[['Piyush Goyal', '0.6385'], ['Peter Voser', '...</td>\n",
       "      <td>['http://aninews.in/news/world/europe/piyush-g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-10-076321</td>\n",
       "      <td>the National Energy and Climate Plans are how ...</td>\n",
       "      <td>Kadri Simson</td>\n",
       "      <td>['Q13570003']</td>\n",
       "      <td>2020-02-10 05:51:51</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Kadri Simson', '0.9269'], ['None', '0.0504'...</td>\n",
       "      <td>['https://www.politico.eu/newsletter/brussels-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-24-110153</td>\n",
       "      <td>When we're talking about... trying to promote ...</td>\n",
       "      <td>Stephen Poloz</td>\n",
       "      <td>['Q15127111']</td>\n",
       "      <td>2020-01-24 01:50:08</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Stephen Poloz', '0.5145'], ['None', '0.4855']]</td>\n",
       "      <td>['http://thestar.com/politics/federal/2020/01/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11086</th>\n",
       "      <td>2020-01-22-057467</td>\n",
       "      <td>Last year Formula 1 launched its first-ever su...</td>\n",
       "      <td>Chase Carey</td>\n",
       "      <td>['Q5087105']</td>\n",
       "      <td>2020-01-22 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>[['Chase Carey', '0.7369'], ['Jean Todt', '0.1...</td>\n",
       "      <td>['http://formula1.com/en/latest/article.formul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11087</th>\n",
       "      <td>2020-02-05-114487</td>\n",
       "      <td>We will be an energetic champion of free trade...</td>\n",
       "      <td>Dominic Raab</td>\n",
       "      <td>['Q268584']</td>\n",
       "      <td>2020-02-05 16:30:31</td>\n",
       "      <td>2</td>\n",
       "      <td>[['Dominic Raab', '0.8813'], ['None', '0.0998'...</td>\n",
       "      <td>['http://forbesadvocate.com.au/story/6616761/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>2020-02-10-057505</td>\n",
       "      <td>Obama got health care, Trump got his tax cut, ...</td>\n",
       "      <td>Tom Steyer</td>\n",
       "      <td>['Q16189531']</td>\n",
       "      <td>2020-02-10 11:00:08</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Tom Steyer', '0.8143'], ['None', '0.1857']]</td>\n",
       "      <td>['https://thebulletin.org/2020/02/on-the-new-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>2020-02-19-061285</td>\n",
       "      <td>Our colleagues will also continue to work toge...</td>\n",
       "      <td>Markus Dohle</td>\n",
       "      <td>['Q1901431']</td>\n",
       "      <td>2020-02-19 08:37:21</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Markus Dohle', '0.7837'], ['None', '0.2163']]</td>\n",
       "      <td>['http://thebookseller.com/news/dohle-prh-well...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11090</th>\n",
       "      <td>2020-02-23-041538</td>\n",
       "      <td>We've been writing about climate change being ...</td>\n",
       "      <td>Lesley Hughes</td>\n",
       "      <td>['Q53473786']</td>\n",
       "      <td>2020-02-23 22:38:42</td>\n",
       "      <td>2</td>\n",
       "      <td>[['Lesley Hughes', '0.9023'], ['None', '0.0978']]</td>\n",
       "      <td>['https://www.nytimes.com/2020/02/23/world/aus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7760 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 quoteID                                          quotation  \\\n",
       "0      2020-02-24-013709  For every doubling of carbon dioxide concentra...   \n",
       "1      2020-02-24-028340  If you're a doctor that cares about the wellbe...   \n",
       "2      2020-01-24-004182  Also, spoke about a range of emerging sectors ...   \n",
       "4      2020-02-10-076321  the National Energy and Climate Plans are how ...   \n",
       "9      2020-01-24-110153  When we're talking about... trying to promote ...   \n",
       "...                  ...                                                ...   \n",
       "11086  2020-01-22-057467  Last year Formula 1 launched its first-ever su...   \n",
       "11087  2020-02-05-114487  We will be an energetic champion of free trade...   \n",
       "11088  2020-02-10-057505  Obama got health care, Trump got his tax cut, ...   \n",
       "11089  2020-02-19-061285  Our colleagues will also continue to work toge...   \n",
       "11090  2020-02-23-041538  We've been writing about climate change being ...   \n",
       "\n",
       "                 speaker           qids                 date  numOccurrences  \\\n",
       "0      E. Calvin Beisner  ['Q19877395']  2020-02-24 16:02:23               1   \n",
       "1          Fiona Stanley   ['Q1653736']  2020-02-24 12:45:00               4   \n",
       "2           Piyush Goyal   ['Q7199798']  2020-01-24 19:02:14               2   \n",
       "4           Kadri Simson  ['Q13570003']  2020-02-10 05:51:51               1   \n",
       "9          Stephen Poloz  ['Q15127111']  2020-01-24 01:50:08               1   \n",
       "...                  ...            ...                  ...             ...   \n",
       "11086        Chase Carey   ['Q5087105']  2020-01-22 00:00:00               3   \n",
       "11087       Dominic Raab    ['Q268584']  2020-02-05 16:30:31               2   \n",
       "11088         Tom Steyer  ['Q16189531']  2020-02-10 11:00:08               1   \n",
       "11089       Markus Dohle   ['Q1901431']  2020-02-19 08:37:21               1   \n",
       "11090      Lesley Hughes  ['Q53473786']  2020-02-23 22:38:42               2   \n",
       "\n",
       "                                                  probas  \\\n",
       "0      [['E. Calvin Beisner', '0.677'], ['None', '0.3...   \n",
       "1      [['Fiona Stanley', '0.9473'], ['None', '0.0527']]   \n",
       "2      [['Piyush Goyal', '0.6385'], ['Peter Voser', '...   \n",
       "4      [['Kadri Simson', '0.9269'], ['None', '0.0504'...   \n",
       "9      [['Stephen Poloz', '0.5145'], ['None', '0.4855']]   \n",
       "...                                                  ...   \n",
       "11086  [['Chase Carey', '0.7369'], ['Jean Todt', '0.1...   \n",
       "11087  [['Dominic Raab', '0.8813'], ['None', '0.0998'...   \n",
       "11088     [['Tom Steyer', '0.8143'], ['None', '0.1857']]   \n",
       "11089   [['Markus Dohle', '0.7837'], ['None', '0.2163']]   \n",
       "11090  [['Lesley Hughes', '0.9023'], ['None', '0.0978']]   \n",
       "\n",
       "                                                    urls  \n",
       "0      ['https://www.heartland.org/news-opinion/news/...  \n",
       "1      ['http://watoday.com.au/business/banking-and-f...  \n",
       "2      ['http://aninews.in/news/world/europe/piyush-g...  \n",
       "4      ['https://www.politico.eu/newsletter/brussels-...  \n",
       "9      ['http://thestar.com/politics/federal/2020/01/...  \n",
       "...                                                  ...  \n",
       "11086  ['http://formula1.com/en/latest/article.formul...  \n",
       "11087  ['http://forbesadvocate.com.au/story/6616761/a...  \n",
       "11088  ['https://thebulletin.org/2020/02/on-the-new-h...  \n",
       "11089  ['http://thebookseller.com/news/dohle-prh-well...  \n",
       "11090  ['https://www.nytimes.com/2020/02/23/world/aus...  \n",
       "\n",
       "[7760 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quotes_2020[quotes_2020['qids'].apply(lambda x : len(x.split())==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f4e2620-72c8-4778-8767-4d6f46facabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We extract 11091 quotes from the 2020 files\n"
     ]
    }
   ],
   "source": [
    "print( \" We extract {} quotes from the 2020 files\".format(len(quotes_2020)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae309716-2b59-4d84-8cac-259f2b256a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-24-013709</td>\n",
       "      <td>For every doubling of carbon dioxide concentra...</td>\n",
       "      <td>E. Calvin Beisner</td>\n",
       "      <td>['Q19877395']</td>\n",
       "      <td>2020-02-24 16:02:23</td>\n",
       "      <td>1</td>\n",
       "      <td>[['E. Calvin Beisner', '0.677'], ['None', '0.3...</td>\n",
       "      <td>['https://www.heartland.org/news-opinion/news/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-24-028340</td>\n",
       "      <td>If you're a doctor that cares about the wellbe...</td>\n",
       "      <td>Fiona Stanley</td>\n",
       "      <td>['Q1653736']</td>\n",
       "      <td>2020-02-24 12:45:00</td>\n",
       "      <td>4</td>\n",
       "      <td>[['Fiona Stanley', '0.9473'], ['None', '0.0527']]</td>\n",
       "      <td>['http://watoday.com.au/business/banking-and-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-24-004182</td>\n",
       "      <td>Also, spoke about a range of emerging sectors ...</td>\n",
       "      <td>Piyush Goyal</td>\n",
       "      <td>['Q7199798']</td>\n",
       "      <td>2020-01-24 19:02:14</td>\n",
       "      <td>2</td>\n",
       "      <td>[['Piyush Goyal', '0.6385'], ['Peter Voser', '...</td>\n",
       "      <td>['http://aninews.in/news/world/europe/piyush-g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-29-062975</td>\n",
       "      <td>Many make the link today between their experie...</td>\n",
       "      <td>Peter Maurer</td>\n",
       "      <td>['Q117796', 'Q42426597']</td>\n",
       "      <td>2020-01-29 09:04:36</td>\n",
       "      <td>5</td>\n",
       "      <td>[['Peter Maurer', '0.8787'], ['None', '0.1213']]</td>\n",
       "      <td>['http://whbl.com/news/articles/2020/jan/29/hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-10-076321</td>\n",
       "      <td>the National Energy and Climate Plans are how ...</td>\n",
       "      <td>Kadri Simson</td>\n",
       "      <td>['Q13570003']</td>\n",
       "      <td>2020-02-10 05:51:51</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Kadri Simson', '0.9269'], ['None', '0.0504'...</td>\n",
       "      <td>['https://www.politico.eu/newsletter/brussels-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-06-069057</td>\n",
       "      <td>This budget also allows us to earmark £ 500,00...</td>\n",
       "      <td>John Whitehead</td>\n",
       "      <td>['Q55436000', 'Q58150131', 'Q6263827', 'Q62638...</td>\n",
       "      <td>2020-01-06 11:49:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[['John Whitehead', '0.7971'], ['None', '0.202...</td>\n",
       "      <td>['https://www.buryfreepress.co.uk/news/draft-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-06-069057</td>\n",
       "      <td>This budget also allows us to earmark £ 500,00...</td>\n",
       "      <td>John Whitehead</td>\n",
       "      <td>['Q55436000', 'Q58150131', 'Q6263827', 'Q62638...</td>\n",
       "      <td>2020-01-06 11:49:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[['John Whitehead', '0.7971'], ['None', '0.202...</td>\n",
       "      <td>['https://www.buryfreepress.co.uk/news/draft-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-22-106994</td>\n",
       "      <td>We have seen years with extremely high carbon ...</td>\n",
       "      <td>Rob Jackson</td>\n",
       "      <td>['Q7340237', 'Q7340238']</td>\n",
       "      <td>2020-01-22 18:57:00</td>\n",
       "      <td>3</td>\n",
       "      <td>[['Rob Jackson', '0.622'], ['None', '0.378']]</td>\n",
       "      <td>['https://www.nbcnews.com/science/environment/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-03-10-005294</td>\n",
       "      <td>As a state, we will pursue every option availa...</td>\n",
       "      <td>Kate Brown</td>\n",
       "      <td>['Q16727692', 'Q6375399']</td>\n",
       "      <td>2020-03-10 20:47:28</td>\n",
       "      <td>2</td>\n",
       "      <td>[['Kate Brown', '0.7275'], ['None', '0.2726']]</td>\n",
       "      <td>['http://www.courthousenews.com/oregon-governo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-24-110153</td>\n",
       "      <td>When we're talking about... trying to promote ...</td>\n",
       "      <td>Stephen Poloz</td>\n",
       "      <td>['Q15127111']</td>\n",
       "      <td>2020-01-24 01:50:08</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Stephen Poloz', '0.5145'], ['None', '0.4855']]</td>\n",
       "      <td>['http://thestar.com/politics/federal/2020/01/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             quoteID                                          quotation  \\\n",
       "0  2020-02-24-013709  For every doubling of carbon dioxide concentra...   \n",
       "1  2020-02-24-028340  If you're a doctor that cares about the wellbe...   \n",
       "2  2020-01-24-004182  Also, spoke about a range of emerging sectors ...   \n",
       "3  2020-01-29-062975  Many make the link today between their experie...   \n",
       "4  2020-02-10-076321  the National Energy and Climate Plans are how ...   \n",
       "5  2020-01-06-069057  This budget also allows us to earmark £ 500,00...   \n",
       "6  2020-01-06-069057  This budget also allows us to earmark £ 500,00...   \n",
       "7  2020-01-22-106994  We have seen years with extremely high carbon ...   \n",
       "8  2020-03-10-005294  As a state, we will pursue every option availa...   \n",
       "9  2020-01-24-110153  When we're talking about... trying to promote ...   \n",
       "\n",
       "             speaker                                               qids  \\\n",
       "0  E. Calvin Beisner                                      ['Q19877395']   \n",
       "1      Fiona Stanley                                       ['Q1653736']   \n",
       "2       Piyush Goyal                                       ['Q7199798']   \n",
       "3       Peter Maurer                           ['Q117796', 'Q42426597']   \n",
       "4       Kadri Simson                                      ['Q13570003']   \n",
       "5     John Whitehead  ['Q55436000', 'Q58150131', 'Q6263827', 'Q62638...   \n",
       "6     John Whitehead  ['Q55436000', 'Q58150131', 'Q6263827', 'Q62638...   \n",
       "7        Rob Jackson                           ['Q7340237', 'Q7340238']   \n",
       "8         Kate Brown                          ['Q16727692', 'Q6375399']   \n",
       "9      Stephen Poloz                                      ['Q15127111']   \n",
       "\n",
       "                  date  numOccurrences  \\\n",
       "0  2020-02-24 16:02:23               1   \n",
       "1  2020-02-24 12:45:00               4   \n",
       "2  2020-01-24 19:02:14               2   \n",
       "3  2020-01-29 09:04:36               5   \n",
       "4  2020-02-10 05:51:51               1   \n",
       "5  2020-01-06 11:49:00               1   \n",
       "6  2020-01-06 11:49:00               1   \n",
       "7  2020-01-22 18:57:00               3   \n",
       "8  2020-03-10 20:47:28               2   \n",
       "9  2020-01-24 01:50:08               1   \n",
       "\n",
       "                                              probas  \\\n",
       "0  [['E. Calvin Beisner', '0.677'], ['None', '0.3...   \n",
       "1  [['Fiona Stanley', '0.9473'], ['None', '0.0527']]   \n",
       "2  [['Piyush Goyal', '0.6385'], ['Peter Voser', '...   \n",
       "3   [['Peter Maurer', '0.8787'], ['None', '0.1213']]   \n",
       "4  [['Kadri Simson', '0.9269'], ['None', '0.0504'...   \n",
       "5  [['John Whitehead', '0.7971'], ['None', '0.202...   \n",
       "6  [['John Whitehead', '0.7971'], ['None', '0.202...   \n",
       "7      [['Rob Jackson', '0.622'], ['None', '0.378']]   \n",
       "8     [['Kate Brown', '0.7275'], ['None', '0.2726']]   \n",
       "9  [['Stephen Poloz', '0.5145'], ['None', '0.4855']]   \n",
       "\n",
       "                                                urls  \n",
       "0  ['https://www.heartland.org/news-opinion/news/...  \n",
       "1  ['http://watoday.com.au/business/banking-and-f...  \n",
       "2  ['http://aninews.in/news/world/europe/piyush-g...  \n",
       "3  ['http://whbl.com/news/articles/2020/jan/29/hu...  \n",
       "4  ['https://www.politico.eu/newsletter/brussels-...  \n",
       "5  ['https://www.buryfreepress.co.uk/news/draft-b...  \n",
       "6  ['https://www.buryfreepress.co.uk/news/draft-b...  \n",
       "7  ['https://www.nbcnews.com/science/environment/...  \n",
       "8  ['http://www.courthousenews.com/oregon-governo...  \n",
       "9  ['http://thestar.com/politics/federal/2020/01/...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_2020.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea50135-f229-42c6-91ce-52b28ec43bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ae4e97a-4d31-4c3f-a9ce-0c710073745d",
   "metadata": {},
   "source": [
    "##### *2019 quotes extractions*\n",
    "> The original dataset is of 3.32 Go, so we decided to divide the dataset into chucks of 1000 rows and process each of them (by using the chunck_filtering). Then we load the process chunck into a new csv compressed bz2 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d516035-0364-44b3-b0c0-89a39d738e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reader = pd.read_json('data/quotes-2019.json.bz2', lines=True, compression='bz2', chunksize=1000)\n",
    "for i, chunk in enumerate(df_reader):\n",
    "        chunk_clean=chunk_filtering(chunk, key_word) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf=\"data/clean_quotes-2019.bz2\",compression='bz2',header=header, mode=mode, index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4947d82f-97dd-4d82-95ed-cd580d10f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2019= pd.read_csv('data/clean_quotes-2019.bz2', compression='bz2') # load into the quotes_2019 df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93186176-a9be-4635-a87b-35816d8a7f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47280, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( \" We extracted {} quotes from the 2019 files\".format(len(quotes_2019)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e8ab3-00a4-4dc9-b89f-e3958ed2bc84",
   "metadata": {},
   "source": [
    "##### *2018 quotes extractions*\n",
    "> The original dataset is of 4.48 Go, so we decided to divide the dataset into chucks of 1000 rows and process each of them ((by using the chunck_filtering). Then we load the process chunck into a new csv compressed bz2 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84914c33-8155-49ac-8d6a-d06d3f904e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reader = pd.read_json('data/quotes-2018.json.bz2', lines=True, compression='bz2', chunksize=1000)\n",
    "for i, chunk in enumerate(df_reader):\n",
    "        chunk_clean=chunk_filtering(chunk, key_word) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf=\"data/clean_quotes-2018.bz2\",compression='bz2',header=header, mode=mode, index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca002f8c-56f4-4940-b198-a214ce2951f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2018= pd.read_csv('data/clean_quotes-2018.bz2', compression='bz2') #load the data to quotes_2018 df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f4203a5-49de-42f8-9168-6e97ef3b2602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We extracted 35847 quotes from the 2018 files\n"
     ]
    }
   ],
   "source": [
    "print( \" We extracted {} quotes from the 2018 files\".format(len(quotes_2018)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8650499-8b64-4279-8cec-22c294b1f67c",
   "metadata": {},
   "source": [
    "##### *2017 quotes extractions*\n",
    "> The original dataset is of 4.84 Go, so we decided to divide the dataset into chucks of 1000 rows and process each of them (by using the chunck_filtering). Then we load the process chunck into a new csv compressed bz2 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0c3dec8-5fa1-474c-9141-ea4e2fc85608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reader = pd.read_json('data/quotes-2017.json.bz2', lines=True, compression='bz2', chunksize=1000)\n",
    "for i, chunk in enumerate(df_reader):\n",
    "        chunk_clean=chunk_filtering(chunk, key_word) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf=\"data/clean_quotes-2017.bz2\",compression='bz2',header=header, mode=mode, index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fc42032-a525-4e90-9247-3a2e591aa26c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quotes_2017= pd.read_csv('data/clean_quotes-2017.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c46c386-4866-431c-8fea-20707695e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We extracted 35324 quotes from the 2017 files\n"
     ]
    }
   ],
   "source": [
    "print( \" We extracted {} quotes from the 2017 files\".format(len(quotes_2017)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3274154-6ca0-4d95-a254-92ee85f4fd9a",
   "metadata": {},
   "source": [
    "##### *2016 quotes extractions*\n",
    " > The original dataset is of 2.16 Go, so we decided to divide the dataset into chucks of 1000 rows and process each of them(by using the chunck_filtering). Then we load the process chunck into a new csv compressed bz2 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dec2729-c0b5-419a-be2a-e39df7639e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reader = pd.read_json('data/quotes-2016.json.bz2', lines=True, compression='bz2', chunksize=1000)\n",
    "for i, chunk in enumerate(df_reader):\n",
    "        chunk_clean=chunk_filtering(chunk, key_word) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf=\"data/clean_quotes-2016.bz2\",compression='bz2',header=header, mode=mode, index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31fc23d3-9713-4206-a126-54882bc6fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2016= pd.read_csv('data/clean_quotes-2016.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "418d9ef6-3d36-42a4-a7ee-845d030cba7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We extracted 18344 quotes from the 2016 files\n"
     ]
    }
   ],
   "source": [
    "print( \" We extracted {} quotes from the 2016 files\".format(len(quotes_2016)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf4b6c0-579e-49e4-ae1f-8096fdbf0821",
   "metadata": {},
   "source": [
    "##### *2015 quotes extractions*\n",
    "> The original dataset is of 3.11 Go, so we decided to divide the dataset into chucks of 1000 rows and process each of them(by using the chunck_filtering). Then we load the process chunck into a new csv compressed bz2 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8131f70-68ac-4126-a31d-f37d8944f444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13829, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reader = pd.read_json('data/quotes-2015.json.bz2', lines=True, compression='bz2', chunksize=1000)\n",
    "for i, chunk in enumerate(df_reader):\n",
    "        chunk_clean=chunk_filtering(chunk, key_word) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf=\"data/clean_quotes-2015.bz2\",compression='bz2',header=header, mode=mode, index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba7620dc-490e-4311-b0cd-b188027133f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quotes_2015= pd.read_csv('data/clean_quotes-2015.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9150b06c-7c29-44e2-94e3-cecb975ac80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We extracted 35176 quotes from the 2015 files\n"
     ]
    }
   ],
   "source": [
    "print( \" We extracted {} quotes from the 2015 files\".format(len(quotes_2015)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "12781cd5-f83d-4297-b58a-1e06a212bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" At result, we extracted {} quotes fromes quotebank data\".format((len(quotes_2015)+len(quotes_2016)+len(quotes_2017)\n",
    "                                                                         +len(quotes_2018)+len(quotes_2019)+len(quotes_2020)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ebf7f-c01e-443b-980a-354e326d4b9c",
   "metadata": {},
   "source": [
    "Even with key_word selection we success to extrat interesting data from the Quotebank data with a sufficient size. Let's add another dataset that will give us characteristic information about the speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bae988-491b-4a10-bf08-0f1e6e076c22",
   "metadata": {},
   "source": [
    "> ##### B/ Select data representative for climate septic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4572fa-ffe1-4abc-8bc0-f911d039ad5c",
   "metadata": {},
   "source": [
    "We want to asses climate scepticism among our speakers. We selected 10 speakers that are said to be climate sceptic according to https://www.businessinsider.com/the-ten-most-important-climate-change-skeptics-2009-7?IR=T#dont-miss-11. We want to find our list of keywords from their quotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dde1b1e3-28b0-49e3-a1ca-9723b945ecea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lst = ['Freeman Dyson', 'Bjorn Lomborg', 'Myron Ebell', 'Kiminori Itoh', 'Ivar Giaever', \n",
    "       'Will Happer', 'Ian Plimer', 'Michael Chrichton', 'Alan Carlin', 'Patrick Michaels'] #list of the name taken from the article\n",
    "#iteration in the list of name in order to find if our people of interest are in our quotes list and \n",
    "#we then create one df per year with their correspondings quotes\n",
    "\n",
    "template = []\n",
    "\n",
    "for i in lst:\n",
    "      template.append(quotes_2020.loc[quotes_2020['speaker'].apply(lambda x : i == x)])  \n",
    "        \n",
    "df_2020 = pd.concat(template, ignore_index=True)\n",
    "\n",
    "template = []\n",
    "\n",
    "for i in lst:\n",
    "      template.append(quotes_2019.loc[quotes_2019['speaker'].apply(lambda x : i == x)])  \n",
    "        \n",
    "df_2019 = pd.concat(template, ignore_index=True)\n",
    "\n",
    "template = []\n",
    "\n",
    "for i in lst:\n",
    "      template.append(quotes_2018.loc[quotes_2018['speaker'].apply(lambda x : i == x)])  \n",
    "        \n",
    "df_2018 = pd.concat(template, ignore_index=True)\n",
    "\n",
    "template = []\n",
    "\n",
    "for i in lst:\n",
    "      template.append(quotes_2017.loc[quotes_2017['speaker'].apply(lambda x : i == x)])  \n",
    "        \n",
    "df_2017 = pd.concat(template, ignore_index=True)\n",
    "\n",
    "template = []\n",
    "\n",
    "for i in lst:\n",
    "      template.append(quotes_2016.loc[quotes_2016['speaker'].apply(lambda x : i == x)])  \n",
    "        \n",
    "df_2016 = pd.concat(template, ignore_index=True)\n",
    "\n",
    "template = []\n",
    "\n",
    "for i in lst:\n",
    "      template.append(quotes_2015.loc[quotes_2015['speaker'].apply(lambda x : i == x)])  \n",
    "        \n",
    "df_2015 = pd.concat(template, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47dc7cac-a9da-4586-a7dc-da6aca32d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['Freeman Dyson', 'Bjorn Lomborg', 'Myron Ebell', 'Kiminori Itoh', 'Ivar Giaever', \n",
    "       'Will Happer', 'Ian Plimer', 'Michael Chrichton', 'Alan Carlin', 'Patrick Michaels'] #list of the name taken from the article\n",
    "#iteration in the list of name in order to find if our people of interest are in our quotes list and \n",
    "#we then create one df per year with their correspondings quotes\n",
    "\n",
    "template = []\n",
    "\n",
    "for i in lst:\n",
    "      template.append(quotes_2020.loc[quotes_2020['speaker'].apply(lambda x : i == x)])  \n",
    "        \n",
    "df_2020 = pd.concat(template, ignore_index=True)\n",
    "quotations_2020 = df_2020['quotation'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27423a0e-3826-4503-8dfe-81c3326f4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will now construct a list with the quotations only\n",
    "quotations_2020 = df_2020['quotation'].tolist()\n",
    "quotations_2019 = df_2019['quotation'].tolist()\n",
    "quotations_2018 = df_2018['quotation'].tolist()\n",
    "quotations_2017 = df_2017['quotation'].tolist()\n",
    "quotations_2016 = df_2016['quotation'].tolist()\n",
    "quotations_2015 = df_2015['quotation'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "281bc0e0-c082-413f-9fc9-0e6f3c02e370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/maria/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/maria/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#we imported these librairies in order to handle language expression and word counting \n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize \n",
    "nltk.download('punkt')\n",
    "from nltk.probability import FreqDist\n",
    "nltk.download('words')\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fd5e9f0-3951-46a8-838f-34f4548f150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two functions\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "a = set(stopwords.words('english'))\n",
    "\n",
    "def remov_punc(lst): #removes the punctuations from a sentence\n",
    "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_°~''' #list of punctuations \n",
    "    remov_punc = []\n",
    "    t = 0\n",
    "    \n",
    "    for i in lst :\n",
    "        t=t+1\n",
    "        for d in i:\n",
    "            if d in punc:\n",
    "                i = i.replace(d, \" \")\n",
    "        remov_punc.append(i)\n",
    "    return remov_punc\n",
    "    \n",
    "def words_freq(lst): #calculate each word frequency\n",
    "    ls=[]\n",
    "    for i in lst: \n",
    "        text = i\n",
    "        text1 = word_tokenize(text.lower())\n",
    "        imp_words = [x for x in text1 if x not in a]\n",
    "        ls.append(imp_words)\n",
    "    return ls\n",
    "\n",
    "def words__highest_freq(lst): #return the highest word frequency\n",
    "    ls_freq = []\n",
    "    for i in lst: \n",
    "        fdist = FreqDist(i)\n",
    "        fdist1 = fdist.most_common(1)\n",
    "        ls_freq.append(fdist1)\n",
    "    return ls_freq #this is a list with the highest frequency for each most written words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78c5a5d9-8fcf-48dd-8c69-f7b2dc2aec91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['science',\n",
       " 'increasing',\n",
       " 'local',\n",
       " 'demonstration',\n",
       " 'climate',\n",
       " 'energy',\n",
       " 'emissions',\n",
       " 'power',\n",
       " 'degrees',\n",
       " 'percent',\n",
       " 'c',\n",
       " 'silly',\n",
       " 'paris',\n",
       " 'co2',\n",
       " 'consensus',\n",
       " 'global',\n",
       " 'effects',\n",
       " 'models',\n",
       " 'r',\n",
       " 'ipcc',\n",
       " 'years',\n",
       " 'year']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_freq_2020 = words_freq(remov_punc(quotations_2020))\n",
    "words_freq_2019 = words_freq(remov_punc(quotations_2019))\n",
    "words_freq_2018 = words_freq(remov_punc(quotations_2018))\n",
    "words_freq_2017 = words_freq(remov_punc(quotations_2017))\n",
    "words_freq_2016 = words_freq(remov_punc(quotations_2016))\n",
    "words_freq_2015 = words_freq(remov_punc(quotations_2015))\n",
    "\n",
    "w_freq = words_freq_2020 + words_freq_2019 + words_freq_2018 + words_freq_2017 + words_freq_2016 + words_freq_2015\n",
    "w_h_freq = words__highest_freq(w_freq)\n",
    "w_h_freq\n",
    "\n",
    "keywords_sceptic = []\n",
    "\n",
    "for i in w_h_freq:\n",
    "    for d in i: \n",
    "        if d[1] >=3 : \n",
    "            if d[0] not in keywords_sceptic:\n",
    "                keywords_sceptic.append(d[0])\n",
    "        \n",
    "keywords_sceptic #our list of keywords according to their representation in the climate sceptic speaker quotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8788628-8a0b-4800-aeb7-f456beb3ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on 2020\n",
    "df_reader = pd.read_json('data/quotes-2020.json.bz2', lines=True, compression='bz2', chunksize=1000)\n",
    "for i, chunk in enumerate(df_reader):\n",
    "        chunk_clean=chunk_filtering(chunk, keywords_sceptic  ) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf=\"data/clean_quotes_sceptic-2020.bz2\",compression='bz2',header=header, mode=mode, index = False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3af73b58-8ff4-4a2c-9007-85c0319832b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2020_sceptic= pd.read_csv('data/clean_quotes_sceptic-2020.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a6a56-c643-4f00-8e53-72611156d0f5",
   "metadata": {},
   "source": [
    "## Load additional data Relative to speakers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5adca85-ec46-4904-b3c5-0395e659767a",
   "metadata": {},
   "source": [
    "The provided speaker_attributes.parquet file contains attributes in terms of QIDs, thereby being uninterpretable by humans (df_qid).\n",
    "To map the QIDs to meaningful labels, we used the provied wikidata_labels_descriptions_quotebank.csv.bz2 containg the labels and value fo the respective QID containing the df_qid (df_label_qid)\n",
    "By combaning the information of both we can obtained usefule information about speakers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "280f0f07-1673-4e62-a70f-81296b7db81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qid = pd.read_parquet(\"speaker_attributes.parquet\",engine= \"pyarrow\" )\n",
    "df_label_qid = pd.read_csv('data/wikidata_labels_descriptions_quotebank.csv.bz2', compression='bz2', index_col='QID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2db133-e8c3-43aa-ae20-07ded9ad40a7",
   "metadata": {},
   "source": [
    "Before extract the label of qid, let's check which column we want to keep in frame with our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b98c8e-74a1-44c5-bc6e-395b22c4440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_qid.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a524d4e3-29a4-49eb-b646-c6fc63e54220",
   "metadata": {},
   "source": [
    "Let's verify that academic_degree has revelant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "293730b9-06ea-4bfd-909e-ab8a7cb806a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's no academic degree revelant value ? False\n"
     ]
    }
   ],
   "source": [
    "#print(\"There's no academic degree revelant value ? {}\".format(all(df_qid.academic_degree.isna())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573efeb6-dd9b-4121-8e10-d926f222795d",
   "metadata": {},
   "source": [
    "We decided to drop lastrevid, US_congress_bio_ID, type. Moreover, it's seems that academic_degree value are rare, let's check that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "677d65e5-50ff-480a-b5ae-6f7d18551117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qid.drop(['lastrevid', 'US_congress_bio_ID', 'type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b7ee1f-81ec-4b1d-b038-7e89c44d3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We found out that some of the QIDs used in the speaker attribute file are actually redirection from an original QID. \n",
    "#We will manulally add their corresponding information using the orginal QID. We found the corespondance manualy between the two. \n",
    "#Here, there are in order, respectively the redirection QID, and its corresponding original one. One of he QID was only present \n",
    "#as a redirection, so we manually added this one (Q3186984), and its corresponding info. \n",
    "\n",
    "redirect_QID=['Q3268166', 'Q11815360', 'Q12014399', 'Q16287483',\n",
    "              'Q20432251', 'Q21550646', 'Q13365117', 'Q13424794',\n",
    "             'Q1248362', 'Q6859927', 'Q15145782',\n",
    "             'Q15991263', 'Q12455619', 'Q5568256', \n",
    "             'Q6363085', 'Q11819457', 'Q12334852', 'Q15145783']\n",
    "actual_QID=['Q1113899', 'Q1919436', 'Q250867', 'Q6051619',\n",
    "             'Q26934816', 'Q18431816', 'Q12840545', 'Q5157338',\n",
    "            'Q3455803', 'Q715222', 'Q1052281',\n",
    "            'Q2743689', 'Q7019111', 'Q3738699', \n",
    "            'Q380075', 'Q3391743', 'Q476246', 'Q2449503']\n",
    "\n",
    "#There is a QID that was deleted from Wikidata, Q99753484, so we will remove this QID later \n",
    "\n",
    "lst=[['Journalist', 'monthly magazine of the United Kingdom‘s National Union of Journalists (NUJ)']]\n",
    "indexes=['Q3186984']\n",
    "col=['Label', 'Description']\n",
    "for i in range(len(redirect_QID)):\n",
    "    lst.append([df_label_qid.loc[actual_QID[i]]['Label'], \n",
    "                df_label_qid.loc[actual_QID[i]]['Description']])\n",
    "    indexes.append(redirect_QID[i])\n",
    "\n",
    "additional_df= pd.DataFrame(lst, columns= col, index=indexes)\n",
    "df_label_qid_co=df_label_qid.append(additional_df, ignore_index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a97b9e-3b81-4c2f-a117-5af59e5bb691",
   "metadata": {},
   "source": [
    "As this function make several minute (more than 20 min) to run, we decided to create a compressed csv files in order to run these cells once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd7bb80b-736d-4e85-9e96-0d913a335b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column (df_climate, df_septic) : \n",
    "    for i, skr in enumerate(df_qid.label) : \n",
    "        if (df_climate['speaker'].isin([skr]).any() & df_septic['speaker'].isin([skr]).any()) : \n",
    "            df_qid.loc[i, 'climate']='None'\n",
    "        else if (df_climate['speaker'].isin([skr]).any()) :\n",
    "            df_qid.loc[i, 'climate']='climate'\n",
    "        else if (df_septic['speaker'].isin([skr]).any()) : \n",
    "            df_qid.loc[i, 'climate']='climate_septic'\n",
    "        else : df_qid.loc[i, 'climate']='None'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17875fab-7cbe-44b9-b911-2c7298b827e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that loops through a column to replace QID with their label, and skip None values. We will deal with them later, \n",
    "#when we will use the different data.\n",
    "def extraction_label(df) : \n",
    "    liste=[]\n",
    "    for row  in df: \n",
    "        if row is None: \n",
    "            continue #skip None values\n",
    "        template=[]\n",
    "        for value in row: #iterating over the values of a cell, as there are multiple QIDs in some of them.\n",
    "            if value == 'Q99753484': #To filter the deleted QID\n",
    "                continue\n",
    "            template.append(df_label_qid_co.loc[value]['Label']) #Map the QID to its corresponding label. \n",
    "        liste.append(template)    \n",
    "    return pd.Series(liste)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea4a52b-ac98-496c-bd3d-b6a238f46a16",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dp/xm3y4vf11sd5mzn0yd618jhm0000gn/T/ipykernel_13175/1015064285.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Applying the function to every column containing QIDs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_qid\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nationality'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gender'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ethnic_group'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'occupation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'party'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'academic_degree'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'candidacy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'religion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_qid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nationality'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gender'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ethnic_group'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'occupation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'party'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'academic_degree'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'candidacy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'religion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextraction_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0madd_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquotes_2020\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotes_2020_septic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_qid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data/speaker_attribute.bz2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bz2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/dp/xm3y4vf11sd5mzn0yd618jhm0000gn/T/ipykernel_13175/4168448170.py\u001b[0m in \u001b[0;36madd_column\u001b[0;34m(df_climate, df_septic)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_column\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_climate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_septic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_qid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_climate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speaker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mskr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mdf_septic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speaker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mskr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0mdf_qid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'climate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'None'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_climate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speaker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mskr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36misin\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   5023\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5024\u001b[0m         \"\"\"\n\u001b[0;32m-> 5025\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5026\u001b[0m         return self._constructor(result, index=self.index).__finalize__(\n\u001b[1;32m   5027\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"isin\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ada/lib/python3.8/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36misin\u001b[0;34m(comps, values)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismember\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Applying the function to every column containing QIDs. \n",
    "df_qid [['nationality', 'gender', 'ethnic_group','occupation', 'party', 'academic_degree', 'candidacy', 'religion']] = df_qid[['nationality', 'gender', 'ethnic_group','occupation', 'party', 'academic_degree', 'candidacy', 'religion']].apply(extraction_label)\n",
    "add_column(quotes_2020, quotes_2020_septic)\n",
    "df_qid.to_csv(path_or_buf=\"data/speaker_attribute.bz2\", compression = 'bz2', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cb4094a-b48b-4837-a1f3-933d6dffa411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ada/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (3,4,5,6,7,8,11,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>aliases</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>occupation</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>candidacy</th>\n",
       "      <th>religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['Washington' 'President Washington' 'G. Washi...</td>\n",
       "      <td>['+1732-02-22T00:00:00Z']</td>\n",
       "      <td>['Great Britain', 'United States of America']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['White British']</td>\n",
       "      <td>['politician', 'military officer', 'farmer', '...</td>\n",
       "      <td>['independent politician']</td>\n",
       "      <td>['Doctor of Sciences in Physics and Mathematics']</td>\n",
       "      <td>Q23</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>['1792 United States presidential election', '...</td>\n",
       "      <td>['Episcopal Church']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['Douglas Noel Adams' 'Douglas Noël Adams' 'Do...</td>\n",
       "      <td>['+1952-03-11T00:00:00Z']</td>\n",
       "      <td>['United Kingdom']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['French']</td>\n",
       "      <td>['playwright', 'screenwriter', 'novelist', \"ch...</td>\n",
       "      <td>['Republican Party']</td>\n",
       "      <td>['laurea']</td>\n",
       "      <td>Q42</td>\n",
       "      <td>Douglas Adams</td>\n",
       "      <td>['2000 United States presidential election', '...</td>\n",
       "      <td>['United Methodist Church', 'Episcopal Church'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['Paul Marie Ghislain Otlet' 'Paul Marie Otlet']</td>\n",
       "      <td>['+1868-08-23T00:00:00Z']</td>\n",
       "      <td>['Belgium']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['Poles']</td>\n",
       "      <td>['writer', 'lawyer', 'librarian', 'information...</td>\n",
       "      <td>['independent politician']</td>\n",
       "      <td>['doctorate']</td>\n",
       "      <td>Q1868</td>\n",
       "      <td>Paul Otlet</td>\n",
       "      <td>['1946 Chilean presidential election']</td>\n",
       "      <td>['Catholicism']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['George Walker Bush' 'Bush Jr.' 'Dubya' 'GWB'...</td>\n",
       "      <td>['+1946-07-06T00:00:00Z']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['French']</td>\n",
       "      <td>['politician', 'motivational speaker', 'autobi...</td>\n",
       "      <td>['Radical Party']</td>\n",
       "      <td>['Doktor Nauk in Juridical Science']</td>\n",
       "      <td>Q207</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>['2005 Polish presidential election']</td>\n",
       "      <td>['Catholicism']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['Velázquez' 'Diego Rodríguez de Silva y Veláz...</td>\n",
       "      <td>['+1599-06-06T00:00:00Z']</td>\n",
       "      <td>['Spain']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['Greeks']</td>\n",
       "      <td>['painter']</td>\n",
       "      <td>['Democratic Party']</td>\n",
       "      <td>['Bachelor of Arts', 'Master of Business Admin...</td>\n",
       "      <td>Q297</td>\n",
       "      <td>Diego Velázquez</td>\n",
       "      <td>['2014 Indian general election in Vadodara Lok...</td>\n",
       "      <td>['Catholicism']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            aliases  \\\n",
       "0           0  ['Washington' 'President Washington' 'G. Washi...   \n",
       "1           1  ['Douglas Noel Adams' 'Douglas Noël Adams' 'Do...   \n",
       "2           2   ['Paul Marie Ghislain Otlet' 'Paul Marie Otlet']   \n",
       "3           3  ['George Walker Bush' 'Bush Jr.' 'Dubya' 'GWB'...   \n",
       "4           4  ['Velázquez' 'Diego Rodríguez de Silva y Veláz...   \n",
       "\n",
       "               date_of_birth                                    nationality  \\\n",
       "0  ['+1732-02-22T00:00:00Z']  ['Great Britain', 'United States of America']   \n",
       "1  ['+1952-03-11T00:00:00Z']                             ['United Kingdom']   \n",
       "2  ['+1868-08-23T00:00:00Z']                                    ['Belgium']   \n",
       "3  ['+1946-07-06T00:00:00Z']                   ['United States of America']   \n",
       "4  ['+1599-06-06T00:00:00Z']                                      ['Spain']   \n",
       "\n",
       "     gender       ethnic_group  \\\n",
       "0  ['male']  ['White British']   \n",
       "1  ['male']         ['French']   \n",
       "2  ['male']          ['Poles']   \n",
       "3  ['male']         ['French']   \n",
       "4  ['male']         ['Greeks']   \n",
       "\n",
       "                                          occupation  \\\n",
       "0  ['politician', 'military officer', 'farmer', '...   \n",
       "1  ['playwright', 'screenwriter', 'novelist', \"ch...   \n",
       "2  ['writer', 'lawyer', 'librarian', 'information...   \n",
       "3  ['politician', 'motivational speaker', 'autobi...   \n",
       "4                                        ['painter']   \n",
       "\n",
       "                        party  \\\n",
       "0  ['independent politician']   \n",
       "1        ['Republican Party']   \n",
       "2  ['independent politician']   \n",
       "3           ['Radical Party']   \n",
       "4        ['Democratic Party']   \n",
       "\n",
       "                                     academic_degree     id  \\\n",
       "0  ['Doctor of Sciences in Physics and Mathematics']    Q23   \n",
       "1                                         ['laurea']    Q42   \n",
       "2                                      ['doctorate']  Q1868   \n",
       "3               ['Doktor Nauk in Juridical Science']   Q207   \n",
       "4  ['Bachelor of Arts', 'Master of Business Admin...   Q297   \n",
       "\n",
       "               label                                          candidacy  \\\n",
       "0  George Washington  ['1792 United States presidential election', '...   \n",
       "1      Douglas Adams  ['2000 United States presidential election', '...   \n",
       "2         Paul Otlet             ['1946 Chilean presidential election']   \n",
       "3     George W. Bush              ['2005 Polish presidential election']   \n",
       "4    Diego Velázquez  ['2014 Indian general election in Vadodara Lok...   \n",
       "\n",
       "                                            religion  \n",
       "0                               ['Episcopal Church']  \n",
       "1  ['United Methodist Church', 'Episcopal Church'...  \n",
       "2                                    ['Catholicism']  \n",
       "3                                    ['Catholicism']  \n",
       "4                                    ['Catholicism']  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv('data/speaker-2020.bz2', compression = 'bz2')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d491fb97-dc85-42ef-848c-144ec5109428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Q19877395\n",
       "1        Q1653736\n",
       "2        Q7199798\n",
       "3       Q13570003\n",
       "4       Q15127111\n",
       "          ...    \n",
       "7734     Q5106681\n",
       "7741     Q5489500\n",
       "7747      Q512051\n",
       "7752    Q11530057\n",
       "7754     Q5247771\n",
       "Name: qids, Length: 3378, dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "test2=quotes_2020.drop_duplicates(['qids'], keep = 'first')['qids']\n",
    "test['climate'] = 0\n",
    "test2.map(lambda y : ast.literal_eval(y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5ab226e6-54a1-46b4-a5c1-fbc4f4f744d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test2.map(lambda y : ast.literal_eval(y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "31f5242f-2966-4601-bbf3-e909c23ae52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                                                                                                                                                                                                                                                                                                                                                                                                                         (18, '['Namo' 'Modi' 'Narendra Bhai' 'Narendra Damodardas Modi'\\n 'Narendrabhai Damodardas Modi' 'Narendrabhai']', '['+1950-09-17T00:00:00Z']', '['India']', '['male']', '['Japanese people']', '['politician', 'writer', 'social worker', 'bibliographer']', '['Communist Party of Germany', 'Socialist Unity Party of Germany']', '['Doctor in Engineering']', 'Q1058', 'Narendra Modi', '['2013 Austrian legislative election']', '['agnosticism']', 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       (22, '['Ban Kimoon' 'Ban Ki Moon']', '['+1944-06-13T00:00:00Z']', '['South Korea']', '['male']', '['African Americans']', '['politician', 'diplomat']', '['Democratic Party']', '['Doctor of Philosophy']', 'Q1253', 'Ban Ki-moon', '['2007 Hong Kong Chief Executive election', '2005 Hong Kong Chief Executive election']', '['Lutheranism']', 0),\n",
       "                                                                                                                                                                                                                                                                                                                                             (486, '['Taylor Alison Swift' 'Nils Sjöberg']', '['+1989-12-13T00:00:00Z']', '['United States of America']', '['female']', '['Spaniards']', '['actor', 'model', 'television actor', 'film actor']', '['Christian Democratic Union', 'Christian Democratic Union', 'Social Democratic Party of Germany']', '['Doctor of Historical Sciences']', 'Q26876', 'Taylor Swift', '['February 1974 United Kingdom general election', 'October 1974 United Kingdom general election', '1992 United Kingdom general election']', '['Protestantism']', 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                 (664, '['Recep Tayyip Erdogan' 'Tayyip Erdoğan' 'Tayyip Erdogan' 'Erdoğan'\\n 'Erdogan']', '['+1954-02-26T00:00:00Z']', '['Kingdom of the Netherlands']', '['male']', '['African Americans']', '['sovereign']', '[\"National Socialist German Workers' Party\"]', '['PhD in Law']', 'Q39259', 'Recep Tayyip Erdoğan', '['February 1974 United Kingdom general election', '1979 United Kingdom general election', 'October 1974 United Kingdom general election']', '['Catholic Church']', 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               (1133, nan, '['+1952-02-19T00:00:00Z']', '['Gabon']', '['male']', '['African Americans']', '['politician', 'athletics competitor', 'javelin thrower']', '['Democratic Party']', '['doctorate']', 'Q57329', 'Danilo Türk', '['1950 United Kingdom general election', '1945 United Kingdom general election', '1951 United Kingdom general election']', '['Catholicism']', 0),\n",
       "       (1925, '['John Richard Kasich' 'John R. Kasich' 'John Richard Kasich Jr.'\\n 'John R. Kasich Jr.' 'John Kasich Jr.' 'Governor John Richard Kasich Jr.'\\n 'Governor John R. Kasich Jr.' 'Governor John Richard Kasich'\\n 'Governor John Kasich Jr.' 'Governor John R. Kasich'\\n 'Governor John Kasich' 'Gov. John Richard Kasich Jr.'\\n 'Gov. John Richard Kasich' 'Gov. John R. Kasich Jr.'\\n 'Gov. John Kasich Jr.' 'Gov. John Kasich']', '['+1952-05-13T00:00:00Z']', '['Germany']', '['male']', '['Swedish-speaking population of Finland']', '['military physician', 'university teacher', 'anatomist']', '['Democratic-Republican Party']', '['doctorate']', 'Q69319', 'John Kasich', '['1886 United Kingdom general election', '1892 United Kingdom general election', '1900 United Kingdom general election', '1880 United Kingdom general election']', '['Catholicism']', 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    (2759, nan, '['+1949-07-08T00:00:00Z']', '['ancient Rome']', '['male']', '['Russians']', '['association football player']', '['Forward']', '['Candidate of Technical Sciences']', 'Q78893', 'Wolfgang Puck', '['1826 United Kingdom general election', '1831 United Kingdom general election']', '['Anglicanism']', 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          (2826, nan, '['+1942-07-13T00:00:00Z']', '['Austria']', '['male']', '['Armenians']', '['poet', 'writer']', '['Republican Party']', '['Candidate of Theology']', 'Q81328', 'Harrison Ford', '['1922 United Kingdom general election']', '['Catholic Church']', 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               (6400, '['Simonetta Myriam Sommaruga']', '['+1960-05-14T00:00:00Z']', '['Germany']', '['male']', '['Serbs']', '['conductor']', '[\"Evangelical People's Party of Switzerland\"]', '['jinshi']', 'Q122991', 'Simonetta Sommaruga', '['2014 Indian general election in Palamau Lok Sabha constituency']', '['Catholicism']', 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               (6646, nan, '['+1990-02-27T00:00:00Z']', '['France']', '['male']', '['Han Chinese people']', '['military leader']', '['Social Democratic Party of Germany']', '['laurea']', 'Q125885', 'Anna Fedorova', '[nan]', '['Palmarian Church']', 0),\n",
       "       ...\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       (8506974, nan, '['+1962-08-04T00:00:00Z']', nan, nan, nan, nan, nan, nan, 'Q58494532', 'Jim Hagedorn', nan, nan, 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     (8506978, '['Jonathan M. Nez']', '['+1975-05-26T00:00:00Z']', nan, nan, nan, nan, nan, nan, 'Q58494679', 'Jonathan Nez', nan, nan, 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   (8506982, nan, nan, nan, nan, nan, nan, nan, nan, 'Q58494749', 'Mona Das', nan, nan, 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         (8508898, '['Kelly Magsamen']', nan, nan, nan, nan, nan, nan, nan, 'Q58880887', 'Kelly E. Magsamen', nan, nan, 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               (8510384, nan, '['+1981-00-00T00:00:00Z']', nan, nan, nan, nan, nan, nan, 'Q59160125', 'Kotchakorn Voraakhom', nan, nan, 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               (8511284, nan, nan, nan, nan, nan, nan, nan, nan, 'Q59227645', 'Keith Prufer', nan, nan, 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            (8511576, nan, nan, nan, nan, nan, nan, nan, nan, 'Q59265059', 'Benjamin Kilian', nan, nan, 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     (8512237, nan, '['+1958-07-30T00:00:00Z']', nan, nan, nan, nan, nan, nan, 'Q59387188', 'Steve Strongin', nan, nan, 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            (8512887, nan, nan, nan, nan, nan, nan, nan, nan, 'Q59490378', 'Muhammad Naseem', nan, nan, 0),\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               (8515261, nan, nan, nan, nan, nan, nan, nan, nan, 'Q59601322', 'Zaheer Ahmed', nan, nan, 0)],\n",
       "      dtype='object', length=3349)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test[pd.Index(test.id).isin(pd.Index(test2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "53273bb9-fb2a-44a8-9f20-67100da975dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>aliases</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>occupation</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>candidacy</th>\n",
       "      <th>religion</th>\n",
       "      <th>climate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, aliases, date_of_birth, nationality, gender, ethnic_group, occupation, party, academic_degree, id, label, candidacy, religion, climate]\n",
       "Index: []"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b336f667-367a-47f7-ba81-a27e76cfd91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test.id[0])\n",
    "type(('\"'+\"[\" + \"'\" + \"Q19877395\" +\"'\"  + \"]\" + '\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "590349af-8ad7-4e42-a342-3cb788e14f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dl/g00fh9c91cddhts4q0y5fnmc0000gq/T/ipykernel_12746/97481898.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test2[idx] = p[2:-2].strip()\n"
     ]
    }
   ],
   "source": [
    "print(('\"'+\"[\" + \"'\" + \"Q19877395\" +\"'\"  + \"]\" + '\"') == test2[0]  )\n",
    "for idx, p in enumerate(test2):\n",
    "    test2[idx] = p[2:-2].strip()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "534b701b-1c9b-4a21-a6c6-27b67f478b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.to_string of 0       Q19877395\n",
       "1        Q1653736\n",
       "2        Q7199798\n",
       "3       Q13570003\n",
       "4       Q15127111\n",
       "          ...    \n",
       "3367    Q27967852\n",
       "3370     Q1086748\n",
       "3373     Q5106681\n",
       "3376    Q11530057\n",
       "3377     Q5247771\n",
       "Name: qids, Length: 4854, dtype: object>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c2fcb528-8567-4bff-b72e-887e98fdff70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "739af41e-fc8b-445b-9f58-79fcd6bff5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (test.id[0].strip()  in test2) :\n",
    "    print(\"stp\")\n",
    "    \n",
    "            #test.loc[0, 'climate']='climate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c3f5411a-0011-4322-adaf-899f0d9b5373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>aliases</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>occupation</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>candidacy</th>\n",
       "      <th>religion</th>\n",
       "      <th>climate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['Washington' 'President Washington' 'G. Washi...</td>\n",
       "      <td>['+1732-02-22T00:00:00Z']</td>\n",
       "      <td>['Great Britain', 'United States of America']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['White British']</td>\n",
       "      <td>['politician', 'military officer', 'farmer', '...</td>\n",
       "      <td>['independent politician']</td>\n",
       "      <td>['Doctor of Sciences in Physics and Mathematics']</td>\n",
       "      <td>Q23</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>['1792 United States presidential election', '...</td>\n",
       "      <td>['Episcopal Church']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['Douglas Noel Adams' 'Douglas Noël Adams' 'Do...</td>\n",
       "      <td>['+1952-03-11T00:00:00Z']</td>\n",
       "      <td>['United Kingdom']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['French']</td>\n",
       "      <td>['playwright', 'screenwriter', 'novelist', \"ch...</td>\n",
       "      <td>['Republican Party']</td>\n",
       "      <td>['laurea']</td>\n",
       "      <td>Q42</td>\n",
       "      <td>Douglas Adams</td>\n",
       "      <td>['2000 United States presidential election', '...</td>\n",
       "      <td>['United Methodist Church', 'Episcopal Church'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['Paul Marie Ghislain Otlet' 'Paul Marie Otlet']</td>\n",
       "      <td>['+1868-08-23T00:00:00Z']</td>\n",
       "      <td>['Belgium']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['Poles']</td>\n",
       "      <td>['writer', 'lawyer', 'librarian', 'information...</td>\n",
       "      <td>['independent politician']</td>\n",
       "      <td>['doctorate']</td>\n",
       "      <td>Q1868</td>\n",
       "      <td>Paul Otlet</td>\n",
       "      <td>['1946 Chilean presidential election']</td>\n",
       "      <td>['Catholicism']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['George Walker Bush' 'Bush Jr.' 'Dubya' 'GWB'...</td>\n",
       "      <td>['+1946-07-06T00:00:00Z']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['French']</td>\n",
       "      <td>['politician', 'motivational speaker', 'autobi...</td>\n",
       "      <td>['Radical Party']</td>\n",
       "      <td>['Doktor Nauk in Juridical Science']</td>\n",
       "      <td>Q207</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>['2005 Polish presidential election']</td>\n",
       "      <td>['Catholicism']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['Velázquez' 'Diego Rodríguez de Silva y Veláz...</td>\n",
       "      <td>['+1599-06-06T00:00:00Z']</td>\n",
       "      <td>['Spain']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['Greeks']</td>\n",
       "      <td>['painter']</td>\n",
       "      <td>['Democratic Party']</td>\n",
       "      <td>['Bachelor of Arts', 'Master of Business Admin...</td>\n",
       "      <td>Q297</td>\n",
       "      <td>Diego Velázquez</td>\n",
       "      <td>['2014 Indian general election in Vadodara Lok...</td>\n",
       "      <td>['Catholicism']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            aliases  \\\n",
       "0           0  ['Washington' 'President Washington' 'G. Washi...   \n",
       "1           1  ['Douglas Noel Adams' 'Douglas Noël Adams' 'Do...   \n",
       "2           2   ['Paul Marie Ghislain Otlet' 'Paul Marie Otlet']   \n",
       "3           3  ['George Walker Bush' 'Bush Jr.' 'Dubya' 'GWB'...   \n",
       "4           4  ['Velázquez' 'Diego Rodríguez de Silva y Veláz...   \n",
       "\n",
       "               date_of_birth                                    nationality  \\\n",
       "0  ['+1732-02-22T00:00:00Z']  ['Great Britain', 'United States of America']   \n",
       "1  ['+1952-03-11T00:00:00Z']                             ['United Kingdom']   \n",
       "2  ['+1868-08-23T00:00:00Z']                                    ['Belgium']   \n",
       "3  ['+1946-07-06T00:00:00Z']                   ['United States of America']   \n",
       "4  ['+1599-06-06T00:00:00Z']                                      ['Spain']   \n",
       "\n",
       "     gender       ethnic_group  \\\n",
       "0  ['male']  ['White British']   \n",
       "1  ['male']         ['French']   \n",
       "2  ['male']          ['Poles']   \n",
       "3  ['male']         ['French']   \n",
       "4  ['male']         ['Greeks']   \n",
       "\n",
       "                                          occupation  \\\n",
       "0  ['politician', 'military officer', 'farmer', '...   \n",
       "1  ['playwright', 'screenwriter', 'novelist', \"ch...   \n",
       "2  ['writer', 'lawyer', 'librarian', 'information...   \n",
       "3  ['politician', 'motivational speaker', 'autobi...   \n",
       "4                                        ['painter']   \n",
       "\n",
       "                        party  \\\n",
       "0  ['independent politician']   \n",
       "1        ['Republican Party']   \n",
       "2  ['independent politician']   \n",
       "3           ['Radical Party']   \n",
       "4        ['Democratic Party']   \n",
       "\n",
       "                                     academic_degree     id  \\\n",
       "0  ['Doctor of Sciences in Physics and Mathematics']    Q23   \n",
       "1                                         ['laurea']    Q42   \n",
       "2                                      ['doctorate']  Q1868   \n",
       "3               ['Doktor Nauk in Juridical Science']   Q207   \n",
       "4  ['Bachelor of Arts', 'Master of Business Admin...   Q297   \n",
       "\n",
       "               label                                          candidacy  \\\n",
       "0  George Washington  ['1792 United States presidential election', '...   \n",
       "1      Douglas Adams  ['2000 United States presidential election', '...   \n",
       "2         Paul Otlet             ['1946 Chilean presidential election']   \n",
       "3     George W. Bush              ['2005 Polish presidential election']   \n",
       "4    Diego Velázquez  ['2014 Indian general election in Vadodara Lok...   \n",
       "\n",
       "                                            religion  climate  \n",
       "0                               ['Episcopal Church']        0  \n",
       "1  ['United Methodist Church', 'Episcopal Church'...        0  \n",
       "2                                    ['Catholicism']        0  \n",
       "3                                    ['Catholicism']        0  \n",
       "4                                    ['Catholicism']        0  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfa7c4bb-3877-4601-9323-9500ab0761a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column (ls_climate, ls_skeptic, chunk) : \n",
    "    chunk['climate']='None'\n",
    "    for i, skr in enumerate(chunk.id) :   \n",
    "        if (ls_climate.isin([skr]).any()) :\n",
    "            chunk.loc[i, 'climate']='climate'\n",
    "        if (ls_skeptic.isin([skr]).any()) : \n",
    "            chunk.loc[i, 'climate']='climate_skeptic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f80975-19d4-4025-8605-c6e1ac5608d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reader = pd.read_csv('data/speaker-2020.bz2',  compression='bz2', chunksize=1000)\n",
    "for i, chunk in enumerate(df_reader):\n",
    "        add_column(quotes_2020.drop_duplicates(['qids'], keep = 'first')['qids'],quotes_2020_sceptic.drop_duplicates(['qids'], keep = 'first')['qids'],chunk)\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk.to_csv(path_or_buf=\"data/clean_quotes_clim.bz2\",compression='bz2',header=header, mode=mode, index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27445a9-1291-43ef-82a2-d1c93a6799a6",
   "metadata": {},
   "source": [
    "## Load data about natural disasters and important political event\n",
    "\n",
    "We would like to compare how climate change speech change in media relatively to the important events occuring in the world. To do so we would like to have a list of important natural disasters that have occured between 2015 and 2020 as well as a list of political and diplomatic events more or less related to climate.\n",
    "\n",
    "The final goal would be the create these lists from Wikipedia scraping data. For now, we made two non-exhaustive \"handmade\" ones :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826fd3a2-8d58-4c09-8715-6aec1b1f7996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Name        Date\n",
      "0                           Earthquake in Nepal   2015-4-25\n",
      "1                           Earthquake in Nepal   2015-5-12\n",
      "2               Heat waves in Inda and Pakistan    2015-4-1\n",
      "3                                Flood in India   2015-11-1\n",
      "4   Typhoon inundate Myanmar, Bangladesh, India    2015-7-1\n",
      "5       Massive floods in Malawi and Mozambique   2015-3-14\n",
      "6                           Drought in Ethiopia    2015-2-1\n",
      "7                            Hurricane in Haiti   2016-10-4\n",
      "8                         Earthquake in Ecuador   2016-4-16\n",
      "9                      Hurricane in Puerto Rico   2017-9-16\n",
      "10                   Hurricane season in the US    2016-6-1\n",
      "11                  Amazon rainforest wildfires    2019-6-1\n",
      "12                           Fires in Australia    2019-6-1\n",
      "13                            Covid-19 pandemic  2019-11-16\n",
      "14                              Floods in Nepal   2020-7-11\n",
      "15                              Fires in the US   2020-7-24\n",
      "                                                Name        Date\n",
      "0                                              COP21  2015-12-12\n",
      "1                                     Trump Election   2016-11-8\n",
      "2        Trump announce quitting \"l'Accord de Paris\"    2017-6-1\n",
      "3                    CLimate strikes begun in Sweden   2018-8-20\n",
      "4    Official letter for quitting\"l'Accord de Paris\"   2019-11-4\n",
      "5  Official retreat of the US from \"l'Accord de P...   2020-11-4\n",
      "6                                     Biden Election   2020-11-3\n"
     ]
    }
   ],
   "source": [
    "data = {'Name':['Earthquake in Nepal','Earthquake in Nepal','Heat waves in Inda and Pakistan','Flood in India','Typhoon inundate Myanmar, Bangladesh, India','Massive floods in Malawi and Mozambique','Drought in Ethiopia','Hurricane in Haiti','Earthquake in Ecuador','Hurricane in Puerto Rico','Hurricane season in the US','Amazon rainforest wildfires','Fires in Australia','Covid-19 pandemic','Floods in Nepal','Fires in the US'],'Date':['2015-4-25','2015-5-12','2015-4-1','2015-11-1','2015-7-1','2015-3-14','2015-2-1','2016-10-4','2016-4-16','2017-9-16','2016-6-1','2019-6-1','2019-6-1','2019-11-16','2020-7-11','2020-7-24']}\n",
    "natural_disasters = pd.DataFrame(data)\n",
    "print(natural_disasters)\n",
    "\n",
    "data = {'Name':['COP21','Trump Election','Trump announce quitting \\\"l\\'Accord de Paris\\\"','CLimate strikes begun in Sweden','Official letter for quitting\\\"l\\'Accord de Paris\\\"','Official retreat of the US from \\\"l\\'Accord de Paris\\\"','Biden Election'],'Date':['2015-12-12','2016-11-8','2017-6-1','2018-8-20','2019-11-4','2020-11-4','2020-11-3']}\n",
    "political_events = pd.DataFrame(data)\n",
    "print(political_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8a1db0-542d-4b9f-a27b-c780e2a03267",
   "metadata": {
    "tags": []
   },
   "source": [
    "# II- Filter the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1547a11-c37a-42a7-bc86-8abc812ef6e7",
   "metadata": {},
   "source": [
    "As a good data scientist, the first thing to do is to clean up the data : we need to filtered missing and duplicates rows if there are presented. We will only filter data from Quotebank extraction as we speakers_file is only ??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534141a-105f-48ba-9e87-daa98425ca57",
   "metadata": {},
   "source": [
    "> ##### *check for missing row*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a824dab5-3740-49b3-b29e-0f0b401546a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there some missing rows ? False \n"
     ]
    }
   ],
   "source": [
    "print(\"Is there some missing rows ? {} \".format(np.array([quotes_2020.isnull().any(axis=1)]).all()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751443c-4cb1-4ee9-9866-aaee5fde6d4c",
   "metadata": {},
   "source": [
    "> ##### *check for duplicate* \n",
    "We define a function that receive a dataframe (quotes_2020 ... quotes_2015) and remove their duplicates rows according to duplicate quotation if the speakers and the date is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28e24b9c-41ef-4760-b305-4def17cb6faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates (df): \n",
    "    \n",
    "    if df[\"quotation\"].is_unique  == False & df[\"speaker\"].is_unique == False & df[\"date\"].is_unique == False: \n",
    "        df.drop_duplicates(['quotation'], keep='first', inplace=True) #remove the duplicate rows directly on the df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b75326db-260f-4ffa-ac6f-abcf76c54eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We still get 10486 quotes from the 2020 dataset\n"
     ]
    }
   ],
   "source": [
    "check_duplicates(quotes_2020)\n",
    "#check_duplicates(quotes_2019)\n",
    "#check_duplicates(quotes_2018)\n",
    "#check_duplicates(quotes_2017)\n",
    "#check_duplicates(quotes_2016)\n",
    "#check_duplicates(quotes_2017)\n",
    "#check_duplicates(quotes_2015)\n",
    "print( \"We still get {} quotes from the 2020 dataset\".format(len(quotes_2020)))\n",
    "#print( \"We still get {} quotes from the 2020 dataset\".format(len(quotes_2019)))\n",
    "#print( \"We still get {} quotes from the 2020 dataset\".format(len(quotes_2018)))\n",
    "#print( \"We still get {} quotes from the 2020 dataset\".format(len(quotes_2017)))\n",
    "#print( \"We still get {} quotes from the 2020 dataset\".format(len(quotes_2016)))\n",
    "#print( \"We still get {} quotes from the 2020 dataset\".format(len(quotes_2015)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec081b-fd7c-4f5b-890a-d9b6f7bf5388",
   "metadata": {},
   "source": [
    "> ##### *check for correlations* \n",
    "We define a function that receive a dataframe (quotes_2020 ... quotes_2015) and remove their duplicates rows according to duplicate quotation if the speakers and the date is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe810cb-20ae-4641-8739-39b7bb7511c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creation of a dataframe containing speakers_attribute and there interest for the climat "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c5ad4-75a4-4dc2-a238-69389de26f45",
   "metadata": {},
   "source": [
    "As a primary analysis, we decided to only look at speaker cited from quotation (so interest to climate problematic) and seek if caracterstic might contribute to their interest. To do so, we simply decide to create a new column to the speakers dataframe which value is one if the label value correspond to a speakers in our defined quotes dataframe or 0 if not.\n",
    "> NB : we will only use the speakers extrated from 2020 for our first analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd50cb19-3e40-4d93-99f4-9faa357b9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's check if the label is unique\n",
    "speakers.label.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d777ef-b111-4165-8b90-c6f70b0822cb",
   "metadata": {},
   "source": [
    "We can observe that  'label' from the speaker dataframe  is non unique meaning that they are multiple personne with the same name that have different caracteristics. This cause us trouble cause we can't propely indentify one quotation with a unique personne with singular caracteristic, but instead one quotation can be attribute to different personne with different caracteristics. \n",
    "For this primary task we decide to non discrimate the label and attribute them the same climate interest (i.e if a speaker is named x in the quotes data, then all label named x in the speakers df will be considere as interest for climate change). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621b883-9ef3-401d-9062-80cb73d482e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4a8f58c-5c08-44d5-81fc-151fdec345a0",
   "metadata": {},
   "source": [
    "# III-Exploration of our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5271ef-c0c5-480c-adb8-f79a0d822615",
   "metadata": {},
   "source": [
    "Let's see some distribution and statitics: \n",
    " - aged people vs yound people \n",
    " - party politics  \n",
    " - confident intervals\n",
    "ect... \n",
    "\n",
    "stat : correlation coeff ; m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5756638-5cba-49a1-82a2-9c06b7363eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate['age'].hist(bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75937c-9a60-49aa-a30f-01c20162181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate['age'].hist(bins = 50).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1415150f-96b0-4c26-b118-53430195e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#does data comes from normal distribution ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72f330-1313-4e6d-ba37-9a9e13f262df",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic.kstest_normal(climate['age'].values, dist = 'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f9ce94-1a6b-4e4e-b573-b1519ec14bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#does data comes from exponential distribution ?\n",
    "#how about exponential?\n",
    "diagnostic.kstest_normal(climate['age'].values, dist = 'exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013eec79-8488-4ec1-afe3-c4c36683b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#is party politics is correlated to climate preocupation ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fc7a8-b7b6-4219-a46b-be40b7726d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(df['IncomePerCap'],df['Employed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee35e9d4-2475-4329-bdae-ffa80feff36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(lalonde_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e822d2b-4d7d-4f6b-8aab-399f8990117a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc8cb77a-4512-4c34-8881-fac754d1c9b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# IV-Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13dc17d-de2e-41ca-92f1-d7c0db2c980a",
   "metadata": {},
   "source": [
    "pour changer nos datas in order to have more robust and less biased dataset\n",
    "\n",
    "- bert pour trouver les climatos sceptics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f2749-749d-4571-a39f-14a47887eaff",
   "metadata": {},
   "source": [
    "to do on our final data set\n",
    "\n",
    "boot strapping pour avoir du train and test datas\n",
    "\n",
    "- matching climate vs scpetic / climate vs not climate via propensity score to predict who talks about climate without unobserved correlation\n",
    "\n",
    "-> categorization\n",
    "\n",
    "- tree \n",
    "- boosting \n",
    "- random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c06fb1-8e99-40e2-af6d-3bab629e952f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
