{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f6630819-7845-4bfb-b746-6a7e780e0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import sqlite3\n",
    "import string\n",
    "\n",
    "#load the statistical libraries\n",
    "from statsmodels.stats import diagnostic\n",
    "from scipy import stats\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1981b18-a20b-4b10-b585-0b15563a9d26",
   "metadata": {},
   "source": [
    "# General information Remark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9c90b-4fd4-4d09-8163-7c2b7021c9b3",
   "metadata": {},
   "source": [
    "### In the loading part we will recover data from 2015 to 2020, however, first visulation (part III) will only be on the data from 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b3b89-46e1-4377-96ab-830501273244",
   "metadata": {},
   "source": [
    "# I- Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edcfe19-c424-4435-86bd-b0eb11096498",
   "metadata": {},
   "source": [
    "### Load Quotebank data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6264bc75-8b74-44f3-9e45-c079a54bea3b",
   "metadata": {},
   "source": [
    "First, let's recover the quotation of interest : as project is based on the caracterisation of the speaker, we decide to pre-select the quotations that are related to a speaker (i.e speaker value is different from 'None'). \n",
    "Moreover, we select the quotations whose subject is related to climate change : to do so we create a list of key word based on https://www.climaterealityproject.org/blog/key-terms-you-need-understand-climate-change and select quotes that contains at least one of these word.  (cf chunk_filtering method) . We are aware that this methode incude biais,and we thought to later utlise NPL in order to filter quotation related to climate from other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab1771f-d38f-4add-a80e-769218de77d9",
   "metadata": {},
   "source": [
    "> ##### A/ Select data representative for climate interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "36cf40e0-63d6-4ca6-a98e-f167ebcc24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaration of a key_world list\n",
    "key_word = [\"carbon dioxide\", \"greenhouse gas\", \"global warming\",\n",
    "             \"climate change\",  \"fossil fuels\", \"sea-level rise\",\n",
    "             \"renewable energy\", \"CO2\",\"methane\",\"PPM\",\"COP\",\"GIEC\", \n",
    "             \"biofuels\",\"business as usual\", \"carbon footprint\", \"carbon neutral\", \"carbon sequestration\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b031381d-12de-49d0-beb2-11debbae3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_filtering(chunk, lst):\n",
    "    template=[] #creation of an empty list :it's always cheaper to append to a list and create a DataFrame than append on a empty dataframe.\n",
    "    for i in lst: \n",
    "        template.append(chunk.loc[chunk[\"quotation\"].apply(lambda x : i in x) & \n",
    "                                  chunk[\"speaker\"].apply(lambda x: x!= \"None\")&chunk[\"qids\"].apply(lambda x: len(np.array(x))==1)].drop(['phase'], axis=1))#select the quotation with value in speaker column different from 'None' \n",
    "                                                                                #and quotations containing the key word and drop Phase column\n",
    "        \n",
    "    return (pd.concat(template, ignore_index=True))# return a dataframe with our data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcbcd14-ca03-4df4-983f-ad2b844a5d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico={}\n",
    "for date in [2020, 2019, 2018, 2017, 2016, 2015]:\n",
    "    dico[date] = pd.read_json(f'data/quotes-{date}.json.bz2', lines=True, compression='bz2', chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7904c1b3-2210-480c-9f6c-ee5576e8330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date, df in dico.items() : \n",
    "    for i, chunk in enumerate(df) : \n",
    "        chunk_clean=chunk_filtering(chunk, keywords_sceptic) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf=f\"data/clean_quotes-{date}.bz2\",compression='bz2',header=header, mode=mode, index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aace3d9-1574-4d2d-9fa7-52c37c0e6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico={}\n",
    "for date in [2020, 2019, 2018, 2017, 2016, 2015]:\n",
    "    dico[date]=[f\"quotes_{date}\",pd.read_csv(f'data/clean_quotes-{date}.bz2', compression='bz2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e7ea8-90f5-46df-9dbf-141297edba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2020= pd.read_csv('data/clean_quotes_sceptic-2020.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "12781cd5-f83d-4297-b58a-1e06a212bca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " At result, we extracted 131472 quotes fromes quotebank data\n"
     ]
    }
   ],
   "source": [
    "print(\" At result, we extracted {} quotes fromes quotebank data\".format((len(quotes_2015)+len(quotes_2016)+len(quotes_2017)\n",
    "                                                                         +len(quotes_2018)+len(quotes_2019)+len(quotes_2020))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ebf7f-c01e-443b-980a-354e326d4b9c",
   "metadata": {},
   "source": [
    "Even with key_word selection we success to extrat interesting data from the Quotebank data with a sufficient size. Let's add another dataset that will give us characteristic information about the speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bae988-491b-4a10-bf08-0f1e6e076c22",
   "metadata": {},
   "source": [
    "> ##### B/ Select data representative for climate septic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4572fa-ffe1-4abc-8bc0-f911d039ad5c",
   "metadata": {},
   "source": [
    "We want to asses climate scepticism among our speakers. We selected 10 speakers that are said to be climate sceptic according to https://www.businessinsider.com/the-ten-most-important-climate-change-skeptics-2009-7?IR=T#dont-miss-11. We want to find our list of keywords from their quotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "dde1b1e3-28b0-49e3-a1ca-9723b945ecea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lst = ['Freeman Dyson', 'Bjorn Lomborg', 'Myron Ebell', 'Kiminori Itoh', 'Ivar Giaever', \n",
    "       'Will Happer', 'Ian Plimer', 'Michael Chrichton', 'Alan Carlin', 'Patrick Michaels'] #list of the name taken from the article\n",
    "#iteration in the list of name in order to find if our people of interest are in our quotes list and \n",
    "#we then create one df per year with their correspondings quotes\n",
    "\n",
    "template = []\n",
    "dico={2020 : quotes_2020, 2019 : quotes_2019, 2018 : quotes_2018, 2017 : quotes_2017, 2016 : quotes_2016, 2015 : quotes_2015}\n",
    "\n",
    "for key, quotes in dico.items():\n",
    "    for i in lst:\n",
    "        template.append(quotes.loc[quotes['speaker'].apply(lambda x : i == x)])  \n",
    "    df_quotes= pd.concat(template, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "281bc0e0-c082-413f-9fc9-0e6f3c02e370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/maria/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/maria/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#we imported these librairies in order to handle language expression and words counting \n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize \n",
    "nltk.download('punkt')\n",
    "from nltk.probability import FreqDist\n",
    "nltk.download('words')\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "1fd5e9f0-3951-46a8-838f-34f4548f150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two functions to asses the highest frequency of word appearance\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "a = set(stopwords.words('english'))\n",
    "\n",
    "def remov_punc(lst): #removes the punctuations from a sentence\n",
    "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_Â°~''' #list of punctuations \n",
    "    remov_punc = []\n",
    "    t = 0\n",
    "    \n",
    "    for i in lst :\n",
    "        t=t+1\n",
    "        for d in i:\n",
    "            if d in punc:\n",
    "                i = i.replace(d, \" \")\n",
    "        remov_punc.append(i)\n",
    "    return remov_punc\n",
    "    \n",
    "def words_freq(lst): #calculate each word frequency\n",
    "    ls=[]\n",
    "    for i in lst: \n",
    "        text = i\n",
    "        text1 = word_tokenize(text.lower())\n",
    "        imp_words = [x for x in text1 if x not in a]\n",
    "        ls.append(imp_words)\n",
    "    return ls\n",
    "\n",
    "def words__highest_freq(lst): #return the highest word frequency\n",
    "    ls_freq = []\n",
    "    for i in lst: \n",
    "        fdist = FreqDist(i)\n",
    "        fdist1 = fdist.most_common(1)\n",
    "        ls_freq.append(fdist1)\n",
    "    return ls_freq #this is a list with the highest frequency for each most written words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "94c81450-6037-4894-a765-89897fcf2c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_quotes=df_quotes['quotation'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "78c5a5d9-8fcf-48dd-8c69-f7b2dc2aec91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['science',\n",
       " 'increasing',\n",
       " 'local',\n",
       " 'demonstration',\n",
       " 'climate',\n",
       " 'energy',\n",
       " 'emissions',\n",
       " 'power',\n",
       " 'degrees',\n",
       " 'percent',\n",
       " 'c',\n",
       " 'silly',\n",
       " 'paris',\n",
       " 'co2',\n",
       " 'consensus',\n",
       " 'global',\n",
       " 'effects',\n",
       " 'models',\n",
       " 'r',\n",
       " 'ipcc',\n",
       " 'years',\n",
       " 'year']"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#construct lists with all the words frquency \n",
    "w_freq= words_freq(remov_punc(list_quotes))\n",
    "w_h_freq = words__highest_freq(w_freq)\n",
    "w_h_freq\n",
    "\n",
    "keywords_sceptic = []\n",
    "\n",
    "for i in w_h_freq: #keep the highest frequency \n",
    "    for d in i: \n",
    "        if d[1] >=3 : \n",
    "            if d[0] not in keywords_sceptic:\n",
    "                keywords_sceptic.append(d[0])\n",
    "        \n",
    "keywords_sceptic #our list of keywords according to their representation in the climate sceptic speaker quotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a2698d07-0a2b-4f17-8b72-5cde0a3383cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_sceptic.remove('c')\n",
    "keywords_sceptic.remove('r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ca98375d-34f2-4c77-853e-14759094fb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['science',\n",
       " 'increasing',\n",
       " 'local',\n",
       " 'demonstration',\n",
       " 'climate',\n",
       " 'energy',\n",
       " 'emissions',\n",
       " 'power',\n",
       " 'degrees',\n",
       " 'percent',\n",
       " 'silly',\n",
       " 'paris',\n",
       " 'co2',\n",
       " 'consensus',\n",
       " 'global',\n",
       " 'effects',\n",
       " 'models',\n",
       " 'ipcc',\n",
       " 'years',\n",
       " 'year']"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_sceptic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "be3d1d13-7047-4866-a783-c66e35b235de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico={}\n",
    "for date in [2020, 2019, 2018, 2017, 2016, 2015]:\n",
    "    dico[date] = pd.read_json(f'data/quotes-{date}.json.bz2', lines=True, compression='bz2', chunksize=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3935b063-adaa-433f-bd3f-61c379a1f083",
   "metadata": {},
   "source": [
    "Now we load our data with this new list of keywords. We use the same technique as above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8788628-8a0b-4800-aeb7-f456beb3ca37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for date, df in dico.items() : \n",
    "    for i, chunk in enumerate(df) : \n",
    "        chunk_clean=chunk_filtering(chunk, keywords_sceptic) #recover interested row of the chunk\n",
    "        header = i == 0 #we kept the name of the column only for the first chunk\n",
    "        mode = 'w' if i == 0 else 'a' # For appending data to an existing CSV file (so for every chunk exepct the first one), \n",
    "                                        #we can use mode = a\n",
    "            \n",
    "        chunk_clean.to_csv(path_or_buf=f\"data/clean_quotes_sceptic-{date}.bz2\",compression='bz2',header=header, mode=mode, index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d8f66b6d-613c-4373-a399-af77cfaddbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quotes_2020_sceptic= pd.read_csv('data/clean_quotes_sceptic-2020.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "907f77e5-f2c7-4cdf-8f8e-d59ef06e230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2019_sceptic= pd.read_csv('data/clean_quotes_sceptic-2019.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b980ac2-e0da-4e30-a85a-8128d9f7a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2018_sceptic= pd.read_csv('data/clean_quotes_sceptic-2018.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b037224-c38f-40b1-a1eb-e9a81307728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2017_sceptic= pd.read_csv('data/clean_quotes_sceptic-2017.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ffe2af-7225-4f0c-b6f0-9f413b340b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2016_sceptic= pd.read_csv('data/clean_quotes_sceptic-2016.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af73b58-8ff4-4a2c-9007-85c0319832b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2015_sceptic= pd.read_csv('data/clean_quotes_sceptic-2015.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a6a56-c643-4f00-8e53-72611156d0f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load additional data Relative to speakers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca79c6a1-b624-41a9-856b-5b5a014b9d0a",
   "metadata": {},
   "source": [
    "### Extracted labels from QID "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5adca85-ec46-4904-b3c5-0395e659767a",
   "metadata": {},
   "source": [
    "The provided speaker_attributes.parquet file contains attributes in terms of QIDs, thereby being uninterpretable by humans (df_qid).\n",
    "To map the QIDs to meaningful labels, we used the provied wikidata_labels_descriptions_quotebank.csv.bz2 containg the labels and value fo the respective QID containing the df_qid (df_label_qid)\n",
    "By combaning the information of both we can obtained usefule information about speakers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914c57ef-174f-4975-a837-4833ad5eb0da",
   "metadata": {},
   "source": [
    "#### *Load parquet file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "280f0f07-1673-4e62-a70f-81296b7db81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qid = pd.read_parquet(\"speaker_attributes.parquet\",engine= \"pyarrow\" )\n",
    "df_label_qid = pd.read_csv('data/wikidata_labels_descriptions_quotebank.csv.bz2', compression='bz2', index_col='QID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188fd90e-a183-4ade-aa7d-15ecb3026eb6",
   "metadata": {},
   "source": [
    "#### *Somes visualisation and sort of the parquet file*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6498a207-69dc-4988-82c2-7174093ea71f",
   "metadata": {},
   "source": [
    "First let's check if the identifier are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2170ea-6bf9-4df5-81e8-59ece97ad890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qid.id.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2db133-e8c3-43aa-ae20-07ded9ad40a7",
   "metadata": {},
   "source": [
    "Before extract the label of qid, let's check which column we want to keep in frame with our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b98c8e-74a1-44c5-bc6e-395b22c4440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qid.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a524d4e3-29a4-49eb-b646-c6fc63e54220",
   "metadata": {},
   "source": [
    "Let's verify that academic_degree has revelant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "293730b9-06ea-4bfd-909e-ab8a7cb806a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's no academic degree revelant value ? False\n"
     ]
    }
   ],
   "source": [
    "print(\"There's no academic degree revelant value ? {}\".format(all(df_qid.academic_degree.isna())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573efeb6-dd9b-4121-8e10-d926f222795d",
   "metadata": {},
   "source": [
    "It seems that academic degree value is revelant, we decided to trop lastrevid, US_congress_bio_ID, type, Alisiase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "677d65e5-50ff-480a-b5ae-6f7d18551117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qid.drop(['lastrevid', 'US_congress_bio_ID', 'type', 'Aliases'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c49349-c401-4036-820d-3e11bcd30e56",
   "metadata": {},
   "source": [
    "#### *Transformation of the df_qid with the label value from df_label_qid*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc78a55-e296-45f5-beb7-0bd02275b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(y):\n",
    "    if y is None: return None\n",
    "    x = set(y)\n",
    "    x.discard(\"Q99753484\")\n",
    "    return x\n",
    "    \n",
    "df_qid=df_qid['occupation'].apply(lambda y : transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b693da-56ee-4eaa-91a8-b6cd1a5e4201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We found out that some of the QIDs used in the speaker attribute file are actually redirection from an original QID. \n",
    "#We will manulally add their corresponding information using the orginal QID. We found the corespondance manualy between the two. \n",
    "#Here, there are in order, respectively the redirection QID, and its corresponding original one. One of he QID was only present \n",
    "#as a redirection, so we manually added this one (Q3186984), and its corresponding info. \n",
    "\n",
    "redirect_QID=['Q3268166', 'Q11815360', 'Q12014399', 'Q16287483',\n",
    "              'Q20432251', 'Q21550646', 'Q13365117', 'Q13424794',\n",
    "             'Q1248362', 'Q6859927', 'Q15145782',\n",
    "             'Q15991263', 'Q12455619', 'Q5568256', \n",
    "             'Q6363085', 'Q11819457', 'Q12334852', 'Q15145783']\n",
    "actual_QID=['Q1113899', 'Q1919436', 'Q250867', 'Q6051619',\n",
    "             'Q26934816', 'Q18431816', 'Q12840545', 'Q5157338',\n",
    "            'Q3455803', 'Q715222', 'Q1052281',\n",
    "            'Q2743689', 'Q7019111', 'Q3738699', \n",
    "            'Q380075', 'Q3391743', 'Q476246', 'Q2449503']\n",
    "\n",
    "#There is a QID that was deleted from Wikidata, Q99753484, so we will remove this QID:\n",
    "\n",
    "\n",
    "lst=[['Journalist', 'monthly magazine of the United Kingdomâs National Union of Journalists (NUJ)']]\n",
    "indexes=['Q3186984']\n",
    "col=['Label', 'Description']\n",
    "for i in range(len(redirect_QID)):\n",
    "    lst.append([df_label_qid.loc[actual_QID[i]]['Label'], \n",
    "                df_label_qid.loc[actual_QID[i]]['Description']])\n",
    "    indexes.append(redirect_QID[i])\n",
    "\n",
    "additional_df= pd.DataFrame(lst, columns= col, index=indexes)\n",
    "df_label=df_label_qid.append(additional_df, ignore_index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57de3a5-d299-46c2-b909-d7e2eda2a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the function to every column containing QIDs. \n",
    "cols=['nationality', 'gender', 'ethnic_group','occupation', 'party', 'academic_degree', 'candidacy', 'religion']\n",
    "\n",
    "df_qid[cols] = df_qid[cols].applymap(lambda d: d if d is not None else [])\n",
    "df_qid[cols] = df_qid[cols].applymap(lambda y: [df_label.loc[Q].Label for Q in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7983c6a-9c8e-4dce-b7a1-c1f64939199a",
   "metadata": {},
   "source": [
    "### Let's have additional data (skeptic/climate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeefadd-c452-4dae-b94d-b24b6aac0e9e",
   "metadata": {},
   "source": [
    "We will now match speaker from the df_qid with a value septic/climate. To do so, we will extracted 2 listes of qid from the quotes_years data : where the first one (qid_climate) contains qid related to speakers that talk about climate and the second list (qid_skeptic) contained qid related to speakers that seems climatospetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515d461-71da-4470-aa9c-7f0ee0f14ad0",
   "metadata": {},
   "source": [
    "#### *Qid_climate list*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cb4094a-b48b-4837-a1f3-933d6dffa411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ada/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (3,4,5,6,7,8,11,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>aliases</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>occupation</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>candidacy</th>\n",
       "      <th>religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['Washington' 'President Washington' 'G. Washi...</td>\n",
       "      <td>['+1732-02-22T00:00:00Z']</td>\n",
       "      <td>['Great Britain', 'United States of America']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['White British']</td>\n",
       "      <td>['politician', 'military officer', 'farmer', '...</td>\n",
       "      <td>['independent politician']</td>\n",
       "      <td>['Doctor of Sciences in Physics and Mathematics']</td>\n",
       "      <td>Q23</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>['1792 United States presidential election', '...</td>\n",
       "      <td>['Episcopal Church']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['Douglas Noel Adams' 'Douglas NoÃ«l Adams' 'Do...</td>\n",
       "      <td>['+1952-03-11T00:00:00Z']</td>\n",
       "      <td>['United Kingdom']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['French']</td>\n",
       "      <td>['playwright', 'screenwriter', 'novelist', \"ch...</td>\n",
       "      <td>['Republican Party']</td>\n",
       "      <td>['laurea']</td>\n",
       "      <td>Q42</td>\n",
       "      <td>Douglas Adams</td>\n",
       "      <td>['2000 United States presidential election', '...</td>\n",
       "      <td>['United Methodist Church', 'Episcopal Church'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['Paul Marie Ghislain Otlet' 'Paul Marie Otlet']</td>\n",
       "      <td>['+1868-08-23T00:00:00Z']</td>\n",
       "      <td>['Belgium']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['Poles']</td>\n",
       "      <td>['writer', 'lawyer', 'librarian', 'information...</td>\n",
       "      <td>['independent politician']</td>\n",
       "      <td>['doctorate']</td>\n",
       "      <td>Q1868</td>\n",
       "      <td>Paul Otlet</td>\n",
       "      <td>['1946 Chilean presidential election']</td>\n",
       "      <td>['Catholicism']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['George Walker Bush' 'Bush Jr.' 'Dubya' 'GWB'...</td>\n",
       "      <td>['+1946-07-06T00:00:00Z']</td>\n",
       "      <td>['United States of America']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['French']</td>\n",
       "      <td>['politician', 'motivational speaker', 'autobi...</td>\n",
       "      <td>['Radical Party']</td>\n",
       "      <td>['Doktor Nauk in Juridical Science']</td>\n",
       "      <td>Q207</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>['2005 Polish presidential election']</td>\n",
       "      <td>['Catholicism']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['VelÃ¡zquez' 'Diego RodrÃ­guez de Silva y VelÃ¡z...</td>\n",
       "      <td>['+1599-06-06T00:00:00Z']</td>\n",
       "      <td>['Spain']</td>\n",
       "      <td>['male']</td>\n",
       "      <td>['Greeks']</td>\n",
       "      <td>['painter']</td>\n",
       "      <td>['Democratic Party']</td>\n",
       "      <td>['Bachelor of Arts', 'Master of Business Admin...</td>\n",
       "      <td>Q297</td>\n",
       "      <td>Diego VelÃ¡zquez</td>\n",
       "      <td>['2014 Indian general election in Vadodara Lok...</td>\n",
       "      <td>['Catholicism']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            aliases  \\\n",
       "0           0  ['Washington' 'President Washington' 'G. Washi...   \n",
       "1           1  ['Douglas Noel Adams' 'Douglas NoÃ«l Adams' 'Do...   \n",
       "2           2   ['Paul Marie Ghislain Otlet' 'Paul Marie Otlet']   \n",
       "3           3  ['George Walker Bush' 'Bush Jr.' 'Dubya' 'GWB'...   \n",
       "4           4  ['VelÃ¡zquez' 'Diego RodrÃ­guez de Silva y VelÃ¡z...   \n",
       "\n",
       "               date_of_birth                                    nationality  \\\n",
       "0  ['+1732-02-22T00:00:00Z']  ['Great Britain', 'United States of America']   \n",
       "1  ['+1952-03-11T00:00:00Z']                             ['United Kingdom']   \n",
       "2  ['+1868-08-23T00:00:00Z']                                    ['Belgium']   \n",
       "3  ['+1946-07-06T00:00:00Z']                   ['United States of America']   \n",
       "4  ['+1599-06-06T00:00:00Z']                                      ['Spain']   \n",
       "\n",
       "     gender       ethnic_group  \\\n",
       "0  ['male']  ['White British']   \n",
       "1  ['male']         ['French']   \n",
       "2  ['male']          ['Poles']   \n",
       "3  ['male']         ['French']   \n",
       "4  ['male']         ['Greeks']   \n",
       "\n",
       "                                          occupation  \\\n",
       "0  ['politician', 'military officer', 'farmer', '...   \n",
       "1  ['playwright', 'screenwriter', 'novelist', \"ch...   \n",
       "2  ['writer', 'lawyer', 'librarian', 'information...   \n",
       "3  ['politician', 'motivational speaker', 'autobi...   \n",
       "4                                        ['painter']   \n",
       "\n",
       "                        party  \\\n",
       "0  ['independent politician']   \n",
       "1        ['Republican Party']   \n",
       "2  ['independent politician']   \n",
       "3           ['Radical Party']   \n",
       "4        ['Democratic Party']   \n",
       "\n",
       "                                     academic_degree     id  \\\n",
       "0  ['Doctor of Sciences in Physics and Mathematics']    Q23   \n",
       "1                                         ['laurea']    Q42   \n",
       "2                                      ['doctorate']  Q1868   \n",
       "3               ['Doktor Nauk in Juridical Science']   Q207   \n",
       "4  ['Bachelor of Arts', 'Master of Business Admin...   Q297   \n",
       "\n",
       "               label                                          candidacy  \\\n",
       "0  George Washington  ['1792 United States presidential election', '...   \n",
       "1      Douglas Adams  ['2000 United States presidential election', '...   \n",
       "2         Paul Otlet             ['1946 Chilean presidential election']   \n",
       "3     George W. Bush              ['2005 Polish presidential election']   \n",
       "4    Diego VelÃ¡zquez  ['2014 Indian general election in Vadodara Lok...   \n",
       "\n",
       "                                            religion  \n",
       "0                               ['Episcopal Church']  \n",
       "1  ['United Methodist Church', 'Episcopal Church'...  \n",
       "2                                    ['Catholicism']  \n",
       "3                                    ['Catholicism']  \n",
       "4                                    ['Catholicism']  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic={2020 : quotes_2020, 2019 : quotes_2019, 2018 : quotes_2018 , 2017 : quotes_2017, 2016 : quotes_2016, 2015 : quotes_2015}\n",
    "qid_climate=[]\n",
    "\n",
    "for key, file in dic.items() :\n",
    "    qid_climate.append(file.drop_duplicates(['qids'], keep='first')['qids'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc64190c-d286-46ea-a7d7-b7da92694c60",
   "metadata": {},
   "source": [
    "#### *Qid_skeptic list*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b36ec4-c280-4d08-9c2c-cfee1ba1d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={2020 : quotes_2020_sceptic, 2019 : quotes_2019_sceptic, 2018 : quotes_2018_sceptic , 2017 : quotes_2017_sceptic, 2016 : quotes_2016_sceptic, 2015 : quotes_2015_sceptic}\n",
    "qid_skeptic=[]\n",
    "\n",
    "for key, file in dic.items() :\n",
    "    qid_skeptic.append(file.drop_duplicates(['qids'], keep='first')['qids'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb6384-8a23-48f0-8c8d-d52393c89c6a",
   "metadata": {},
   "source": [
    "#### *Add an additional column to df_qid*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6409500f-8ac6-4871-99e6-9aa6af44ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qid['climate']='None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82fb65-5c53-40dd-842c-0a0bfa326078",
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_climate=qid_climate.map(lambda y : ast.literal_eval(y)[0])\n",
    "df_qid.at[df_qid[pd.Index(df_qid.id).isin(pd.Index(qid_climate))].index, 'climate']=='involved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce33b4-786b-417f-bb94-e0927fc6cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_skeptic=qid_skeptic.map(lambda y : ast.literal_eval(y)[0])\n",
    "df_qid.at[df_qid[pd.Index(df_qid.id).isin(pd.Index(qid_skeptic))].index, 'climate']=='skeptic'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1287ac-2d6a-4df4-b405-77866fda47bc",
   "metadata": {},
   "source": [
    "#### *Load resulting data into a csv compressed filled*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6792ede4-8efd-4481-a524-4e4d052299db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qid.to_csv(\"data/speaker_attribute.bz2\", compression = 'bz2', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6fd4c9-6c61-470e-a3fb-9ddd21b46b1d",
   "metadata": {},
   "source": [
    "Let's visualize !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5dfc0-74bc-481c-aa81-5ba788b220b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers=pd.read_csv(\"data/speaker_attribute.bz2\", compression='bz2', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc05e3e-5f41-425a-a1e4-16adf6473f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "test2=quotes_2020.drop_duplicates(['qids'], keep = 'first')['qids']\n",
    "test['climate'] = 0\n",
    "test2.map(lambda y : ast.literal_eval(y)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8a1db0-542d-4b9f-a27b-c780e2a03267",
   "metadata": {},
   "source": [
    "# II- Filter the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1547a11-c37a-42a7-bc86-8abc812ef6e7",
   "metadata": {},
   "source": [
    "As a good data scientist, the first thing to do is to clean up the data : first, we need to convert the value from the datafram into proper python string : we can use literal_eval to safely evaluating strings containing Python expressions from untrusted sources without the need to parse the values oneself. We also need to check for missing row and correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534141a-105f-48ba-9e87-daa98425ca57",
   "metadata": {},
   "source": [
    "> ##### *check for missing row*\n",
    "We consider that a row is missing if we don't have information about speakers attributes (i.e other than label, qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a824dab5-3740-49b3-b29e-0f0b401546a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there some missing rows ? False \n"
     ]
    }
   ],
   "source": [
    "print(\"Is there some missing rows ? {} \".format(np.array([speakers.drop(['label', 'id']).isnull().any(axis=1)]).all()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ed2c35-c9b6-4a22-8aba-55960c6662b5",
   "metadata": {},
   "source": [
    "> ##### *evaluating strings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e01007a-48a9-4990-b3c3-20f095de6226",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers=speakers.fillna(\"[]\").head(20)[['date_of_birth', 'nationality','gender','ethnic_group', \n",
    "                                       'occupation','party', 'academic_degree','candidacy', 'religion']].applymap(lambda y: ast.literal_eval(str(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ace1c-8fd7-4042-898e-6f743b956ffd",
   "metadata": {},
   "source": [
    "> ##### changes the date_of_birth \n",
    "we will juste recover year of the birth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0123c94-0206-461c-b248-907140872494",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers.date_of_birth=speakers.date_of_birth.map(lambda y : str(y).split(\"-\")[0][3:]).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec081b-fd7c-4f5b-890a-d9b6f7bf5388",
   "metadata": {},
   "source": [
    "> ##### *check for correlations* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb60e1-9c00-4be9-af9f-6cc9005f4c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers.corr()\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a8f58c-5c08-44d5-81fc-151fdec345a0",
   "metadata": {},
   "source": [
    "# III-Exploration of our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5271ef-c0c5-480c-adb8-f79a0d822615",
   "metadata": {},
   "source": [
    "Let's see some distribution and statitics: \n",
    " - aged people vs yound people \n",
    " - party politics  \n",
    " - confident intervals\n",
    "ect... \n",
    "\n",
    "stat : correlation coeff ; m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5756638-5cba-49a1-82a2-9c06b7363eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate['age'].hist(bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75937c-9a60-49aa-a30f-01c20162181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate['age'].hist(bins = 50).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1415150f-96b0-4c26-b118-53430195e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#does data comes from normal distribution ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72f330-1313-4e6d-ba37-9a9e13f262df",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic.kstest_normal(climate['age'].values, dist = 'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f9ce94-1a6b-4e4e-b573-b1519ec14bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#does data comes from exponential distribution ?\n",
    "#how about exponential?\n",
    "diagnostic.kstest_normal(climate['age'].values, dist = 'exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013eec79-8488-4ec1-afe3-c4c36683b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#is party politics is correlated to climate preocupation ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fc7a8-b7b6-4219-a46b-be40b7726d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(df['IncomePerCap'],df['Employed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee35e9d4-2475-4329-bdae-ffa80feff36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(lalonde_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e822d2b-4d7d-4f6b-8aab-399f8990117a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc8cb77a-4512-4c34-8881-fac754d1c9b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# IV-Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf735e7-bb59-4cd8-b362-6ed323af3280",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datas loading and treatment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff5f99-9f79-4246-8689-fd6cc0be409b",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa41f1d-1b6e-40c0-8698-5d068ef50f63",
   "metadata": {},
   "source": [
    "We would like to have an automatic classification of climate scepticism people. According to https://aclanthology.org/2021.naacl-main.175.pdf, neutralization is used in climate skepticism.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecd91f9-03a0-4a2f-b446-0160dd1cc63f",
   "metadata": {},
   "source": [
    "Naturalization example : \n",
    "\n",
    "- Sure, we should reduce greenhouse gases, but if our cli- mate policies hurt our ability to create more wealth and bring power to the worldâs poor, then we are ridding the patient of the disease, but only by killing him\n",
    "- Itâs very convenient for alarmist greens to blame the fires of Australia and California on global warming. In reality, global warming is just a natural cycle and the policies they themselves advocate are the culprits.\n",
    "- The IPCC falsely attributes natural warming and urban warming to greenhouse gas (GHG) emission warming. It ignores the compelling evidence of natural climate change before 1950 that correlates well with indicators of solar activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4432f4cb-4b34-49f8-9036-088f49bcf547",
   "metadata": {},
   "source": [
    "They could categorize these neutralization techniques arguments into two groups\n",
    "- Policy (cost, economy, carbon tax) -> blame alarmist green \n",
    "    - Condemnation of the Condemner (manipulation of poltics)\n",
    "    - Appeal to Higher Loyalties (progress is more important than taxes)\n",
    "    - Justification by Comparison (pollution comparison)\n",
    "- Science (ability of scientist) -> natural cycle\n",
    "    - Denial of responsability (natural cycle)\n",
    "    - Denial of injury1 (not significant)\n",
    "    - Denial of injury2 (increase of CO2 is good)\n",
    "    - Denial of victim "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa164e0c-172f-47ad-813f-236a029a3be7",
   "metadata": {},
   "source": [
    "We want to categorize our skeptic people in two subgroups, social and scientific. \n",
    "For the code part we will try to inspire ourself from https://arxiv.org/pdf/2110.12010.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51590d49-d2fe-47a8-a3af-6a2a37f47654",
   "metadata": {},
   "source": [
    "### Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d7a62f-1ca8-42d5-910b-7d9efa235f10",
   "metadata": {},
   "source": [
    "We would like to use the bootsrapping method in order to resample our datas and obtain a data_set_test and a data_set_train. This will able us to fit our model that we will construct in order to explore our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8347e-54ab-4529-a338-12bf6c4f6320",
   "metadata": {},
   "source": [
    "### Propensity score matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d357b7-eeb6-4ac4-aec5-7cc989c34adb",
   "metadata": {},
   "source": [
    "In order to avoid unobserved corelation, we want to use propensity score matching. And from this new dataset go furtherer in our project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06425ef8-96d0-4d64-a111-8505c9b1436c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb000282-2e75-4ca7-915b-5f5133e15c12",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a81d8be-03be-4f3c-a7e7-ee7be5e2da6f",
   "metadata": {},
   "source": [
    "We will first try to do some regression to see if we can predict some tendancy with accurancy. We will try to see if some attributs are predictable or if they are all relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac883f-8ddd-4343-8324-47b64ec64d96",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c079a55b-4c5d-44b6-968f-edce5e4f4638",
   "metadata": {},
   "source": [
    "We will try different type of tree categorization in order to have more robust methods to test our hypothesis. \n",
    "\n",
    "- boosting \n",
    "- random forest \n",
    "\n",
    "Based on these models we will try to have a better understanding on the climate tendancy in the population. (cf README) for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
